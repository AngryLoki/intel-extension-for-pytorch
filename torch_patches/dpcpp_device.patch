diff --git a/aten/src/ATen/SparseTensorImpl.cpp b/aten/src/ATen/SparseTensorImpl.cpp
index 6af4b57..b6144b3 100644
--- a/aten/src/ATen/SparseTensorImpl.cpp
+++ b/aten/src/ATen/SparseTensorImpl.cpp
@@ -11,6 +11,8 @@ namespace {
       return kCPU;
     } else if (type_set.has(TensorTypeId::SparseCUDATensorId)) {
       return kCUDA;
+    } else if (type_set.has(TensorTypeId::SparseDPCPPTensorId)) {
+      return kDPCPP;
     } else {
       AT_ERROR("Cannot construct SparseTensor with non-sparse tensor type ID ", type_set);
     }
diff --git a/aten/src/ATen/native/sparse/SparseTensor.cpp b/aten/src/ATen/native/sparse/SparseTensor.cpp
index a7d71a8..e6125ee 100644
--- a/aten/src/ATen/native/sparse/SparseTensor.cpp
+++ b/aten/src/ATen/native/sparse/SparseTensor.cpp
@@ -76,6 +76,8 @@ SparseTensor new_sparse(const TensorOptions& options) {
   TensorTypeId type_id;
   if (options.device().is_cuda()) {
     type_id = TensorTypeId::SparseCUDATensorId;
+  } else if (options.device().is_dpcpp()) {
+    type_id = TensorTypeId::SparseDPCPPTensorId;
   } else {
     type_id = TensorTypeId::SparseCPUTensorId;
   }
diff --git a/c10/core/Backend.h b/c10/core/Backend.h
index 26a2773..a37d76a 100644
--- a/c10/core/Backend.h
+++ b/c10/core/Backend.h
@@ -25,18 +25,22 @@ namespace c10 {
  * or "SparseCUDA"; backend in torch.backends is something like "MKL" or
  * "CUDNN".
  */
-enum class Backend { CPU, CUDA, HIP, SparseCPU, SparseCUDA, SparseHIP, MSNPU, XLA, QuantizedCPU, ComplexCPU, ComplexCUDA, Undefined, MkldnnCPU, NumOptions };
+enum class Backend { CPU, CUDA, HIP, SparseCPU, SparseCUDA, SparseHIP, MSNPU, XLA, QuantizedCPU, ComplexCPU, ComplexCUDA, Undefined, MkldnnCPU, DPCPP, SparseDPCPP, ComplexDPCPP, NumOptions };
 
 static inline Backend toSparse(Backend b) {
   switch (b) {
     case Backend::CPU:
       return Backend::SparseCPU;
+    case Backend::DPCPP:
+      return Backend::SparseDPCPP;
     case Backend::CUDA:
       return Backend::SparseCUDA;
     case Backend::HIP:
       return Backend::SparseHIP;
     case Backend::SparseCPU:
       return Backend::SparseCPU;
+    case Backend::SparseDPCPP:
+      return Backend::SparseDPCPP;
     case Backend::SparseCUDA:
       return Backend::SparseCUDA;
     case Backend::SparseHIP:
@@ -58,6 +62,10 @@ static inline Backend toDense(Backend b) {
       return Backend::MSNPU;
     case Backend::XLA:
       return Backend::XLA;
+    case Backend::DPCPP:
+      return Backend::DPCPP;
+    case Backend::SparseDPCPP:
+      return Backend::DPCPP;
     case Backend::SparseCPU:
       return Backend::CPU;
     case Backend::SparseCUDA:
@@ -86,6 +94,10 @@ static inline Backend tensorTypeIdToBackend(TensorTypeId t) {
     return Backend::MSNPU;
   } else if (t == TensorTypeId::XLATensorId) {
     return Backend::XLA;
+  } else if (t == TensorTypeId::DPCPPTensorId) {
+    return Backend::DPCPP;
+  } else if (t == TensorTypeId::SparseDPCPPTensorId) {
+    return Backend::SparseDPCPP;
   } else if (t == TensorTypeId::SparseCPUTensorId) {
     return Backend::SparseCPU;
   } else if (t == TensorTypeId::SparseCUDATensorId) {
@@ -119,6 +131,10 @@ static inline TensorTypeId backendToTensorTypeId(Backend b) {
       return TensorTypeId::MSNPUTensorId;
     case Backend::XLA:
       return TensorTypeId::XLATensorId;
+    case Backend::DPCPP:
+      return TensorTypeId::DPCPPTensorId;
+    case Backend::SparseDPCPP:
+      return TensorTypeId::SparseDPCPPTensorId;
     case Backend::SparseCPU:
       return TensorTypeId::SparseCPUTensorId;
     case Backend::SparseCUDA:
@@ -158,6 +174,9 @@ static inline DeviceType backendToDeviceType(Backend b) {
       return DeviceType::CUDA;
     case Backend::SparseHIP:
       return DeviceType::HIP;
+    case Backend::DPCPP:
+    case Backend::SparseDPCPP:
+      return DeviceType::DPCPP;
     case Backend::MkldnnCPU:
     case Backend::QuantizedCPU:
     case Backend::ComplexCPU:
@@ -173,12 +192,14 @@ static inline DeviceType backendToDeviceType(Backend b) {
 
 static inline Backend backendToCPU(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
       return Backend::CPU;
     case Backend::CUDA:
       return Backend::CPU;
     case Backend::HIP:
       return Backend::CPU;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
       return Backend::SparseCPU;
     case Backend::SparseCUDA:
@@ -192,6 +213,7 @@ static inline Backend backendToCPU(Backend b) {
       return Backend::MkldnnCPU;
     case Backend::QuantizedCPU:
       return Backend::QuantizedCPU;
+    case Backend::ComplexDPCPP:
     case Backend::ComplexCPU:
     case Backend::ComplexCUDA:
       return Backend::ComplexCPU;
@@ -204,16 +226,19 @@ static inline Backend backendToCPU(Backend b) {
 
 static inline Backend backendToCUDA(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
     case Backend::CUDA:
     case Backend::HIP:
     case Backend::MSNPU:
     case Backend::XLA:
       return Backend::CUDA;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
       return Backend::SparseCUDA;
+    case Backend::ComplexDPCPP:
     case Backend::ComplexCPU:
     case Backend::ComplexCUDA:
       return Backend::ComplexCUDA;
@@ -226,12 +251,14 @@ static inline Backend backendToCUDA(Backend b) {
 
 static inline Backend backendToHIP(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
     case Backend::CPU:
     case Backend::CUDA:
     case Backend::HIP:
     case Backend::MSNPU:
     case Backend::XLA:
       return Backend::HIP;
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
@@ -246,6 +273,8 @@ static inline Backend backendToHIP(Backend b) {
 // TODO: This probably shouldn't actually be static inline
 static inline const char* toString(Backend b) {
   switch (b) {
+    case Backend::DPCPP:
+      return "DPCPP";
     case Backend::CPU:
       return "CPU";
     case Backend::CUDA:
@@ -256,6 +285,8 @@ static inline const char* toString(Backend b) {
       return "MSNPU";
     case Backend::XLA:
       return "XLA";
+    case Backend::SparseDPCPP:
+      return "SparseDPCPP";
     case Backend::SparseCPU:
       return "SparseCPU";
     case Backend::SparseCUDA:
@@ -266,6 +297,8 @@ static inline const char* toString(Backend b) {
       return "MkldnnCPU";
     case Backend::QuantizedCPU:
       return "QuantizedCPU";
+    case Backend::ComplexDPCPP:
+      return "ComplexDPCPP";
     case Backend::ComplexCPU:
       return "ComplexCPU";
     case Backend::ComplexCUDA:
@@ -277,6 +310,7 @@ static inline const char* toString(Backend b) {
 
 static inline bool isSparse(Backend b) {
   switch (b) {
+    case Backend::SparseDPCPP:
     case Backend::SparseCPU:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
diff --git a/c10/core/Device.cpp b/c10/core/Device.cpp
index 1b936cd..29425d9 100644
--- a/c10/core/Device.cpp
+++ b/c10/core/Device.cpp
@@ -13,7 +13,7 @@
 namespace c10 {
 namespace {
 DeviceType parse_type(const std::string& device_string) {
-  static const std::array<std::pair<std::string, DeviceType>, 9> types = {{
+  static const std::array<std::pair<std::string, DeviceType>, 10> types = {{
       {"cpu", DeviceType::CPU},
       {"cuda", DeviceType::CUDA},
       {"mkldnn", DeviceType::MKLDNN},
@@ -23,6 +23,7 @@ DeviceType parse_type(const std::string& device_string) {
       {"hip", DeviceType::HIP},
       {"msnpu", DeviceType::MSNPU},
       {"xla", DeviceType::XLA},
+      {"dpcpp", DeviceType::DPCPP},
   }};
   auto device = std::find_if(
       types.begin(),
@@ -34,7 +35,7 @@ DeviceType parse_type(const std::string& device_string) {
     return device->second;
   }
   AT_ERROR(
-      "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: ", device_string);
+      "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, dpcpp, hip, msnpu device type at start of device string: ", device_string);
 }
 } // namespace
 
diff --git a/c10/core/Device.h b/c10/core/Device.h
index 95295c1..5995b70 100644
--- a/c10/core/Device.h
+++ b/c10/core/Device.h
@@ -86,6 +86,11 @@ struct C10_API Device final {
     return type_ == DeviceType::CPU;
   }
 
+  /// Return true if the device is of DPCPP type.
+  bool is_dpcpp() const noexcept {
+    return type_ == DeviceType::DPCPP;
+  }
+
  private:
   DeviceType type_;
   DeviceIndex index_ = -1;
diff --git a/c10/core/DeviceType.cpp b/c10/core/DeviceType.cpp
index 017267c..486b02e 100644
--- a/c10/core/DeviceType.cpp
+++ b/c10/core/DeviceType.cpp
@@ -27,6 +27,8 @@ std::string DeviceTypeName(DeviceType d, bool lower_case) {
       return lower_case ? "msnpu" : "MSNPU";
     case DeviceType::XLA:
       return lower_case ? "xla" : "XLA";
+    case DeviceType::DPCPP:
+      return lower_case ? "dpcpp" : "DPCPP";
     default:
       AT_ERROR(
           "Unknown device: ",
@@ -59,6 +61,7 @@ bool isValidDeviceType(DeviceType d) {
     case DeviceType::FPGA:
     case DeviceType::MSNPU:
     case DeviceType::XLA:
+    case DeviceType::DPCPP:
       return true;
     default:
       return false;
diff --git a/c10/core/DeviceType.h b/c10/core/DeviceType.h
index 9f75966..23f6808 100644
--- a/c10/core/DeviceType.h
+++ b/c10/core/DeviceType.h
@@ -23,11 +23,12 @@ enum class DeviceType : int16_t {
   FPGA = 7, // FPGA
   MSNPU = 8, // MSNPU
   XLA = 9, // XLA / TPU
+  DPCPP = 10, // DPCPP
   // NB: If you add more devices:
   //  - Change the implementations of DeviceTypeName and isValidDeviceType
   //    in DeviceType.cpp
   //  - Change the number below
-  COMPILE_TIME_MAX_DEVICE_TYPES = 10,
+  COMPILE_TIME_MAX_DEVICE_TYPES = 11,
   ONLY_FOR_TEST = 20901, // This device type is only for test.
 };
 
@@ -36,6 +37,7 @@ constexpr DeviceType kCUDA = DeviceType::CUDA;
 constexpr DeviceType kHIP = DeviceType::HIP;
 constexpr DeviceType kMSNPU = DeviceType::MSNPU;
 constexpr DeviceType kXLA = DeviceType::XLA;
+constexpr DeviceType kDPCPP = DeviceType::DPCPP;
 
 // define explicit int constant
 constexpr int COMPILE_TIME_MAX_DEVICE_TYPES =
diff --git a/c10/core/Layout.h b/c10/core/Layout.h
index c5ecc89..4aab440 100644
--- a/c10/core/Layout.h
+++ b/c10/core/Layout.h
@@ -15,6 +15,7 @@ constexpr auto kMkldnn = Layout::Mkldnn;
 inline Layout layout_from_backend(Backend backend) {
   switch (backend) {
     case Backend::SparseCPU:
+    case Backend::SparseDPCPP:
     case Backend::SparseCUDA:
     case Backend::SparseHIP:
       return Layout::Sparse;
diff --git a/c10/core/TensorImpl.h b/c10/core/TensorImpl.h
index 65f43ff..ae24ea5 100644
--- a/c10/core/TensorImpl.h
+++ b/c10/core/TensorImpl.h
@@ -425,7 +425,8 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     // NB: This method is not virtual and avoid dispatches for performance reasons.
     return type_set_.has(TensorTypeId::SparseCPUTensorId) ||
            type_set_.has(TensorTypeId::SparseCUDATensorId) ||
-           type_set_.has(TensorTypeId::SparseHIPTensorId);
+           type_set_.has(TensorTypeId::SparseHIPTensorId) ||
+           type_set_.has(TensorTypeId::SparseDPCPPTensorId);
   }
 
   bool is_quantized() const {
@@ -449,6 +450,11 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     return type_set_.has(TensorTypeId::MkldnnCPUTensorId);
   }
 
+  bool is_dpcpp() const {
+    return type_set_.has(TensorTypeId::DPCPPTensorId) ||
+           type_set_.has(TensorTypeId::SparseDPCPPTensorId);
+  }
+
   int64_t get_device() const {
     TORCH_CHECK(
         device_opt_.has_value(),
@@ -918,6 +924,7 @@ struct C10_API TensorImpl : public c10::intrusive_ptr_target {
     };
     auto is_sparse = [](TensorTypeSet ts) {
       return ts.has(TensorTypeId::SparseCPUTensorId) ||
+             ts.has(TensorTypeId::SparseDPCPPTensorId) ||
              ts.has(TensorTypeId::SparseCUDATensorId) ||
              ts.has(TensorTypeId::SparseHIPTensorId);
     };
diff --git a/c10/core/TensorOptions.h b/c10/core/TensorOptions.h
index 90eb7e2..6ab409b 100644
--- a/c10/core/TensorOptions.h
+++ b/c10/core/TensorOptions.h
@@ -381,6 +381,8 @@ struct C10_API TensorOptions {
             return TensorTypeId::MSNPUTensorId;
           case DeviceType::XLA:
             return TensorTypeId::XLATensorId;
+          case DeviceType::DPCPP:
+            return TensorTypeId::DPCPPTensorId;
           default:
             AT_ERROR("Unsupported device type for dense layout: ", device().type());
         }
@@ -392,6 +394,8 @@ struct C10_API TensorOptions {
             return TensorTypeId::SparseCUDATensorId;
           case DeviceType::HIP:
             return TensorTypeId::SparseHIPTensorId;
+          case DeviceType::DPCPP:
+            return TensorTypeId::SparseDPCPPTensorId;
           default:
             AT_ERROR("Unsupported device type for sparse layout: ", device().type());
         }
@@ -587,6 +591,10 @@ inline DeviceType computeDeviceType(TensorTypeId tid) {
     return DeviceType::MSNPU;
   } else if (tid == TensorTypeId::XLATensorId) {
     return DeviceType::XLA;
+  } else if (tid == TensorTypeId::DPCPPTensorId) {
+    return DeviceType::DPCPP;
+  } else if (tid == TensorTypeId::SparseDPCPPTensorId) {
+    return DeviceType::DPCPP;
   } else if (tid == TensorTypeId::SparseCPUTensorId) {
     return DeviceType::CPU;
   } else if (tid == TensorTypeId::SparseCUDATensorId) {
@@ -599,6 +607,8 @@ inline DeviceType computeDeviceType(TensorTypeId tid) {
     return DeviceType::CPU;
   } else if (tid == TensorTypeId::ComplexCUDATensorId) {
     return DeviceType::CUDA;
+  } else if (tid == TensorTypeId::DPCPPTensorId) {
+    return DeviceType::DPCPP;
   } else {
     AT_ASSERTM(false, "Unknown TensorTypeId: ", tid);
   }
diff --git a/c10/core/TensorTypeId.cpp b/c10/core/TensorTypeId.cpp
index 9f63c38..5bdf7be 100644
--- a/c10/core/TensorTypeId.cpp
+++ b/c10/core/TensorTypeId.cpp
@@ -40,6 +40,10 @@ const char* toString(TensorTypeId t) {
       return "ComplexCUDATensorId";
     case TensorTypeId::VariableTensorId:
       return "VariableTensorId";
+    case TensorTypeId::DPCPPTensorId:
+      return "DPCPPTensorId";
+    case TensorTypeId::SparseDPCPPTensorId:
+      return "SparseDPCPPTensorId";
     case TensorTypeId::TESTING_ONLY_GenericModeTensorId:
       return "TESTING_ONLY_GenericModeTensorId";
     case TensorTypeId::TESTING_ONLY_GenericWrapperTensorId:
diff --git a/c10/core/TensorTypeId.h b/c10/core/TensorTypeId.h
index e1bcbc2..74eecd9 100644
--- a/c10/core/TensorTypeId.h
+++ b/c10/core/TensorTypeId.h
@@ -42,6 +42,9 @@ enum class TensorTypeId : uint8_t {
   SparseCPUTensorId, // PyTorch only
   SparseCUDATensorId, // PyTorch only
 
+  DPCPPTensorId, // DPCPP only
+  SparseDPCPPTensorId, // DPCPP only
+
   // WARNING! If you add more "wrapper" style tensor ids (tensor
   // ids which don't get kernels directly defined in native_functions.yaml;
   // examples are tracing or profiling) here, you need to also adjust
diff --git a/torch/csrc/utils/tensor_layouts.cpp b/torch/csrc/utils/tensor_layouts.cpp
index 8f51a7d..67fe6d1 100644
--- a/torch/csrc/utils/tensor_layouts.cpp
+++ b/torch/csrc/utils/tensor_layouts.cpp
@@ -23,6 +23,7 @@ void initializeLayouts() {
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::CUDA);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::MSNPU);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::XLA);
+  registerLayoutObject((THPLayout*)strided_layout, at::Backend::DPCPP);
   registerLayoutObject((THPLayout*)strided_layout, at::Backend::QuantizedCPU);
 
   PyObject *sparse_coo_layout = THPLayout_New(at::Layout::Sparse, "torch.sparse_coo");
diff --git a/torch/csrc/utils/tensor_new.cpp b/torch/csrc/utils/tensor_new.cpp
index 7265ccb..be05001 100644
--- a/torch/csrc/utils/tensor_new.cpp
+++ b/torch/csrc/utils/tensor_new.cpp
@@ -58,6 +58,8 @@ Backend backendToBackendOfDeviceType(Backend b, DeviceType d) {
     case DeviceType::XLA:
       TORCH_CHECK(!isSparse(b), "Sparse not implemented for XLA");
       return Backend::XLA;
+    case DeviceType::DPCPP:
+      return Backend::DPCPP;
     default:
       AT_ERROR("Unknown device type");
   }
