From f715133cebbffe70e56a9070608dbe4818040db2 Mon Sep 17 00:00:00 2001
From: johnlu <chengjun.lu@intel.com>
Date: Wed, 9 Dec 2020 17:25:50 +0800
Subject: [PATCH 06/14] 6.Add prototype torch.runtime for intel XPU.

---
 tools/build_variables.bzl          |    1 +
 torch/_utils.py                    |   46 +-
 torch/csrc/Generator.cpp           |   48 ++
 torch/csrc/Module.cpp              |    2 +
 torch/csrc/Runtime.cpp             | 1099 ++++++++++++++++++++++++++++
 torch/csrc/Runtime.h               |   11 +
 torch/cuda/__init__.py             |   11 +
 torch/nn/parallel/data_parallel.py |   27 +-
 8 files changed, 1220 insertions(+), 25 deletions(-)
 create mode 100644 torch/csrc/Runtime.cpp
 create mode 100644 torch/csrc/Runtime.h

diff --git a/tools/build_variables.bzl b/tools/build_variables.bzl
index 341cb96763..af3d77910d 100644
--- a/tools/build_variables.bzl
+++ b/tools/build_variables.bzl
@@ -474,6 +474,7 @@ libtorch_python_core_sources = [
     "torch/csrc/Module.cpp",
     "torch/csrc/PtrWrapper.cpp",
     "torch/csrc/python_dimname.cpp",
+    "torch/csrc/Runtime.cpp",
     "torch/csrc/Size.cpp",
     "torch/csrc/Storage.cpp",
     "torch/csrc/Stream.cpp",
diff --git a/torch/_utils.py b/torch/_utils.py
index 11f378a4d7..83def84018 100644
--- a/torch/_utils.py
+++ b/torch/_utils.py
@@ -6,7 +6,6 @@ from collections import defaultdict
 import sys
 import traceback
 
-
 def _type(self, dtype=None, non_blocking=False, **kwargs):
     """Returns the type if `dtype` is not provided, else casts this object to
     the specified type.
@@ -429,33 +428,24 @@ class ExceptionWrapper(object):
 
 
 def _get_available_device_type():
-    if torch.cuda.is_available():
-        return "cuda"
-    # add more available device types here
-    return None
-
-
-def _get_device_attr(get_member):
-    device_type = _get_available_device_type()
-    if device_type.lower() == "cuda":
-        return get_member(torch.cuda)
-    # add more available device types here
+    if torch._C.runtime._named_members(lambda m: m.is_available()):
+        return torch._C.runtime._named_members(lambda m: m.get_device_type())
     return None
 
 
 def _get_current_device_index():
     # current device index
-    return _get_device_attr(lambda m: m.current_device())
+    return torch._C.runtime._named_members(lambda m: m.current_device())
 
 
 def _get_all_device_indices():
     # all device index
-    return _get_device_attr(lambda m: list(range(m.device_count())))
+    return torch._C.runtime._named_members(lambda m: list(range(m.device_count())))
 
 
 def _get_devices_properties(device_ids):
     # all device properties
-    return [_get_device_attr(lambda m: m.get_device_properties(i)) for i in device_ids]
+    return [torch._C.runtime._named_members(lambda m: m.get_device_properties(i)) for i in device_ids]
 
 
 def _get_device_index(device, optional=False, allow_cpu=False) -> int:
@@ -471,8 +461,8 @@ def _get_device_index(device, optional=False, allow_cpu=False) -> int:
     If :attr:`device` is a Python integer, it is returned as is.
 
     If :attr:`device` is ``None``, this will return the current default
-    device of the supported runtime platform if :attr:`optional` is ``True``.
-    i.e., the current default CUDA device will be returned if CUDA runtime is supported.
+    device of the current runtime platform if :attr:`optional` is ``True``.
+    i.e., the current default CUDA device will be returned if current runtime is CUDA.
     """
     if isinstance(device, str):
         device = torch.device(device)
@@ -491,3 +481,25 @@ def _get_device_index(device, optional=False, allow_cpu=False) -> int:
             raise ValueError('Expected a torch.device with a specified index '
                              'or an integer, but got:{}'.format(device))
     return device_idx
+
+
+def _get_device_type(device, optional=False, allow_cpu=False) -> str:
+    r"""TODO
+    """
+    if isinstance(device, str):
+        device = torch.device(device)
+    device_type: Optional[str]
+    device_type = None
+    if isinstance(device, torch.device):
+        if not allow_cpu and device.type == 'cpu':
+            raise ValueError('Expected a non cpu device, but got: {}'.format(device))
+        device_type = device.type
+    if isinstance(device, int):
+        device_type = _get_available_device_type()
+    if device_type is None:
+        if optional:
+            device_type = _get_available_device_type()
+        else:
+            raise ValueError('Expected a torch.device with a specified index '
+                             'or an integer or string, but got:{}'.format(device))
+    return device_type
diff --git a/torch/csrc/Generator.cpp b/torch/csrc/Generator.cpp
index 0884223f76..98dbe578a7 100644
--- a/torch/csrc/Generator.cpp
+++ b/torch/csrc/Generator.cpp
@@ -74,6 +74,50 @@ static PyObject * THPGenerator_pynew(PyTypeObject *type, PyObject *args, PyObjec
   END_HANDLE_TH_ERRORS
 }
 
+void THXRandom_getRNGState(at::Generator gen_, THByteTensor *rng_state)
+{
+  // auto gen = at::check_generator<at::DPCPPGeneratorImpl>(gen_);
+  std::lock_guard<std::mutex> lock(gen_.mutex());
+  static const size_t states_size = 200 * sizeof(4120);
+  static const size_t seed_size = sizeof(uint64_t);
+  static const size_t offset_size = sizeof(int64_t);
+  static const size_t total_size = states_size + seed_size + offset_size;
+  THByteTensor_resize1d(rng_state, total_size);
+  THArgCheck(THByteTensor_nElement(rng_state) == total_size, 1, "RNG state is wrong size");
+  THArgCheck(THByteTensor_isContiguous(rng_state), 1, "RNG state must be contiguous");
+  memset(THByteTensor_data(rng_state), -1, states_size);
+  auto current_seed = gen_.current_seed();
+  //auto offset = static_cast<int64_t>(gen_.philox_offset_per_thread()); // Note that old THCGeneratorState had offset as std::atomic<int64_t>
+  memcpy(THByteTensor_data(rng_state) + states_size, &current_seed, seed_size);
+  //memcpy(THByteTensor_data(rng_state) + states_size + seed_size, &offset, offset_size);
+}
+
+void THXRandom_setRNGState(at::Generator gen_, THByteTensor *rng_state)
+{
+  //auto gen = at::check_generator<at::DPCPPGeneratorImpl>(gen_);
+  std::lock_guard<std::mutex> lock(gen_.mutex());
+  static const size_t states_size = 200 * sizeof(4120); // this line is just here for BC reason
+  static const size_t seed_size = sizeof(uint64_t);
+  static const size_t offset_size = sizeof(int64_t);
+  static const size_t total_size = states_size + seed_size + offset_size;
+  bool no_philox_seed = false;
+  if (THByteTensor_nElement(rng_state) == total_size - offset_size) {
+    no_philox_seed = true;
+  }
+  else {
+    THArgCheck(THByteTensor_nElement(rng_state) == total_size, 1, "RNG state is wrong size");
+  }
+  THArgCheck(THByteTensor_isContiguous(rng_state), 1, "RNG state must be contiguous");
+  uint64_t input_seed;
+  memcpy(&input_seed, THByteTensor_data(rng_state) + states_size, seed_size);
+  gen_.set_current_seed(input_seed);
+  int64_t philox_offset = 0;
+  if (!no_philox_seed) {
+    memcpy(&philox_offset, THByteTensor_data(rng_state) + states_size + seed_size, offset_size);
+  }
+  //gen_.set_philox_offset_per_thread(static_cast<uint64_t>(philox_offset));
+}
+
 static PyObject * THPGenerator_getState(THPGenerator *self, PyObject *noargs)
 {
   using namespace torch::autograd;
@@ -81,6 +125,8 @@ static PyObject * THPGenerator_getState(THPGenerator *self, PyObject *noargs)
   Variable var = torch::empty({0}, at::device(at::kCPU).dtype(at::kByte));
   if (self->cdata.device().type() == at::kCPU) {
     THByteTensor_getRNGState(self->cdata, (THByteTensor*)(var.unsafeGetTensorImpl()));
+  } else if(self->cdata.device().type() == at::kXPU){
+    THXRandom_getRNGState(self->cdata, (THByteTensor*)(var.unsafeGetTensorImpl()));
   } else {
 #ifdef USE_CUDA
     TORCH_INTERNAL_ASSERT(self->cdata.device().type() == at::kCUDA);
@@ -107,6 +153,8 @@ static PyObject * THPGenerator_setState(THPGenerator *self, PyObject *_new_state
   }
   if (self->cdata.device().type() == at::kCPU) {
     THByteTensor_setRNGState(self->cdata, (THByteTensor*)tensor.unsafeGetTensorImpl());
+  } else if(self->cdata.device().type() == at::kXPU){
+    THXRandom_setRNGState(self->cdata, (THByteTensor*)tensor.unsafeGetTensorImpl());
   } else {
 #ifdef USE_CUDA
     TORCH_INTERNAL_ASSERT(self->cdata.device().type() == at::kCUDA);
diff --git a/torch/csrc/Module.cpp b/torch/csrc/Module.cpp
index ddc4226c69..3cab9ba5c4 100644
--- a/torch/csrc/Module.cpp
+++ b/torch/csrc/Module.cpp
@@ -52,6 +52,7 @@
 #include <torch/csrc/onnx/init.h>
 #include <torch/csrc/utils/init.h>
 #include <torch/csrc/api/include/torch/python/init.h>
+#include <torch/csrc/Runtime.h>
 
 #ifdef USE_DISTRIBUTED
 #ifdef USE_C10D
@@ -739,6 +740,7 @@ PyObject* initModule() {
   torch::autograd::initLinalgFunctions(module);
   torch::autograd::init_legacy_variable(module);
   torch::python::init_bindings(module);
+  torch::runtime::init_runtime(module);
 #ifdef USE_CUDA
   torch::cuda::initModule(module);
 #endif
diff --git a/torch/csrc/Runtime.cpp b/torch/csrc/Runtime.cpp
new file mode 100644
index 0000000000..ebd3405f9a
--- /dev/null
+++ b/torch/csrc/Runtime.cpp
@@ -0,0 +1,1099 @@
+#include <torch/csrc/python_headers.h>
+#include <fmt/format.h>
+#include <pybind11/chrono.h>
+#include <torch/csrc/utils/pybind.h>
+#include <torch/csrc/Runtime.h>
+
+namespace torch {
+namespace runtime {
+
+PyObject *runtime_module;
+
+std::string current_runtime;
+std::map<std::string, PyObject*> runtime_dict;
+
+std::vector<std::string> basic_attrs = {"is_available",
+                                        "get_device_type"};
+
+std::vector<std::string> device_management = {"current_device",
+                                              "device_count",
+                                              "device",
+                                              "device_of",
+                                              "get_device_properties",
+                                              "get_device_name"};
+
+std::vector<std::string> memory_management = {};
+
+std::vector<std::string> random_generator = {"get_rng_state",
+                                        "get_rng_state_all",
+                                        "set_rng_state",
+                                        "set_rng_state_all",
+                                        "manual_seed",
+                                        "manual_seed_all",
+                                        "seed",
+                                        "initial_seed"};
+
+std::vector<std::string> ipc = {};
+
+template <typename T>
+using shared_ptr_class_ = py::class_<T, std::shared_ptr<T>>;
+
+static py::module get_runtime_module(const std::string& runtime) {
+  TORCH_CHECK(runtime_dict.find(runtime) != runtime_dict.end(), "Runtime '", runtime, "' not exists.");
+  return py::handle(runtime_dict[current_runtime]).cast<py::module>();
+}
+
+PyObject* init_runtime(PyObject* module) {
+  auto m = py::handle(module).cast<py::module>();
+  auto runtime = m.def_submodule("runtime", "Runtime management");
+  runtime_module = runtime.ptr();
+  runtime.def(
+          "register_runtime",
+          [](const std::string& name, py::module& new_module) {
+
+              auto _torch = THPObjectPtr(PyImport_ImportModule("torch"));
+              if (!_torch) {
+                throw python_error();
+              }
+              auto torch = py::handle(_torch).cast<py::module>();
+
+              TORCH_CHECK(!py::hasattr(torch, name.c_str()), "torch attribute '", name, "' already exists.");
+              TORCH_CHECK(runtime_dict.find(name) == runtime_dict.end(), "Runtime '", name, "' already registered with ");
+
+              // the runtime name should be same as the device type name
+              auto device = at::Device(name.c_str());
+
+              // check the required attributes of the new module
+              auto check_attributes = [](const py::module& m, const std::string& attr){ return py::hasattr(m, attr.c_str());};
+
+              for (auto& attr : basic_attrs) {
+                TORCH_CHECK(check_attributes(new_module, attr), "torch module '", new_module, "' has no attribute '", attr, "'");
+              }
+
+              for (auto& attr : random_generator) {
+                TORCH_CHECK(check_attributes(new_module, attr), "torch module '", new_module, "' has no attribute '", attr, "'");
+              }
+
+              torch.attr(name.c_str()) = new_module;
+              runtime_dict.emplace(std::pair<std::string, PyObject*>(name, new_module.ptr()));
+              current_runtime = name;
+          },
+          R"(Example)")
+          .def("available_runtimes", [](){
+            py::dict rt;
+            for (auto& it : runtime_dict) {
+              rt[it.first.c_str()] = py::handle(it.second).cast<py::module>();
+            }
+            return rt;
+          })
+          .def("current_runtime", [](){
+            return get_runtime_module(current_runtime);
+          })
+          .def("_named_members", [](const py::object& get_member_fn){
+            py::module m = get_runtime_module(current_runtime);
+            return get_member_fn(m);
+          });
+#if 0
+
+  def _available_runtimes():
+    print(_run_time_dict)
+
+  module.def(
+          "_register_comm_hook",
+          &_register_comm_hook,
+          py::arg("ddp_model"),
+          py::arg("state"),
+          py::arg("comm_hook"));
+
+  shared_ptr_class_<::c10d::GradBucket>(module, "_GradBucket")
+          .def(py::init<std::vector<Tensor>&>(), py::arg("tensors"))
+          .def(
+                  "get_tensors",
+                  &::c10d::GradBucket::getTensors,
+                  py::call_guard<py::gil_scoped_release>(),
+                  R"(
+            ``get_tensors`` returns a list of ``torch.Tensor``. Each tensor in
+            the list refers to the replica on each device. There will be multiple
+            replicas only in the case of single process multiple device mode. In
+            the single process single device mode, this list would consist of only
+            a single tensor.
+           )");
+
+  shared_ptr_class_<::c10d::Reducer>(module, "Reducer")
+          .def(
+                  py::init<
+                          std::vector<std::vector<torch::autograd::Variable>>,
+                          std::vector<std::vector<size_t>>,
+                          std::shared_ptr<::c10d::ProcessGroup>,
+                          std::vector<std::vector<bool>>,
+                          int64_t,
+                          bool,
+                          bool>(),
+                  py::arg("replicas"),
+                  py::arg("bucket_indices"),
+                  py::arg("process_group"),
+                  py::arg("expect_sparse_gradients") = std::vector<std::vector<bool>>(),
+                  py::arg("bucket_bytes_cap") = ::c10d::kDefaultBucketBytesCap,
+                  py::arg("find_unused_parameters") = false,
+                  py::arg("gradient_as_bucket_view") = false,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "initialize_buckets",
+                  &::c10d::Reducer::initialize_buckets,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "prepare_for_backward",
+                  &::c10d::Reducer::prepare_for_backward,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "prepare_for_backward",
+                  [](::c10d::Reducer& reducer, const torch::autograd::Variable& output)
+                          -> void { reducer.prepare_for_backward({output}); },
+                  py::call_guard<py::gil_scoped_release>())
+          .def("get_backward_stats", &::c10d::Reducer::get_backward_stats)
+          .def(
+                  "_rebuild_buckets",
+                  &::c10d::Reducer::rebuild_buckets,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "get_bucket_tensors",
+                  &::c10d::Reducer::get_bucket_tensors,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "_push_all_rebuilt_params",
+                  &::c10d::Reducer::push_rebuilt_params_for_all_indices,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "_set_forward_pass_work_handle",
+                  &::c10d::Reducer::set_forward_pass_work_handle,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "_get_local_used_maps",
+                  &::c10d::Reducer::get_local_used_maps_on_device);
+
+  py::enum_<::c10d::ReduceOp>(module, "ReduceOp", R"(
+An enum-like class for available reduction operations: ``SUM``, ``PRODUCT``,
+``MIN``, ``MAX``, ``BAND``, ``BOR``, and ``BXOR``.
+
+Note that ``BAND``, ``BOR``, and ``BXOR`` reductions are not available when
+using the ``NCCL`` backend.
+
+The values of this class can be accessed as attributes, e.g., ``ReduceOp.SUM``.
+They are used in specifying strategies for reduction collectives, e.g.,
+:func:`reduce`, :func:`all_reduce_multigpu`, etc.)")
+          .value("SUM", ::c10d::ReduceOp::SUM)
+          .value("PRODUCT", ::c10d::ReduceOp::PRODUCT)
+          .value("MIN", ::c10d::ReduceOp::MIN)
+          .value("MAX", ::c10d::ReduceOp::MAX)
+          .value("BAND", ::c10d::ReduceOp::BAND)
+          .value("BOR", ::c10d::ReduceOp::BOR)
+          .value("BXOR", ::c10d::ReduceOp::BXOR);
+
+  py::class_<::c10d::BroadcastOptions>(module, "BroadcastOptions")
+          .def(py::init<>())
+          .def_readwrite("rootRank", &::c10d::BroadcastOptions::rootRank)
+          .def_readwrite("rootTensor", &::c10d::BroadcastOptions::rootTensor)
+          .def_readwrite("timeout", &::c10d::BroadcastOptions::timeout);
+
+  py::class_<::c10d::AllreduceOptions>(module, "AllreduceOptions")
+          .def(py::init<>())
+          .def_readwrite("reduceOp", &::c10d::AllreduceOptions::reduceOp)
+          .def_readwrite("timeout", &::c10d::AllreduceOptions::timeout);
+
+  py::class_<::c10d::AllreduceCoalescedOptions>(
+          module, "AllreduceCoalescedOptions")
+          .def(py::init<>())
+          .def_readwrite("reduceOp", &::c10d::AllreduceCoalescedOptions::reduceOp)
+          .def_readwrite("timeout", &::c10d::AllreduceCoalescedOptions::timeout);
+
+  py::class_<::c10d::ReduceOptions>(module, "ReduceOptions")
+          .def(py::init<>())
+          .def_readwrite("reduceOp", &::c10d::ReduceOptions::reduceOp)
+          .def_readwrite("rootRank", &::c10d::ReduceOptions::rootRank)
+          .def_readwrite("rootTensor", &::c10d::ReduceOptions::rootTensor)
+          .def_readwrite("timeout", &::c10d::ReduceOptions::timeout);
+
+  py::class_<::c10d::AllgatherOptions>(module, "AllgatherOptions")
+          .def(py::init<>())
+          .def_readwrite("timeout", &::c10d::AllgatherOptions::timeout);
+
+  py::class_<::c10d::GatherOptions>(module, "GatherOptions")
+          .def(py::init<>())
+          .def_readwrite("rootRank", &::c10d::GatherOptions::rootRank)
+          .def_readwrite("timeout", &::c10d::GatherOptions::timeout);
+
+  py::class_<::c10d::ScatterOptions>(module, "ScatterOptions")
+          .def(py::init<>())
+          .def_readwrite("rootRank", &::c10d::ScatterOptions::rootRank)
+          .def_readwrite("timeout", &::c10d::ScatterOptions::timeout);
+
+  py::class_<::c10d::ReduceScatterOptions>(module, "ReduceScatterOptions")
+          .def(py::init<>())
+          .def_readwrite("reduceOp", &::c10d::ReduceScatterOptions::reduceOp)
+          .def_readwrite("timeout", &::c10d::ReduceScatterOptions::timeout);
+
+  py::class_<::c10d::BarrierOptions>(module, "BarrierOptions")
+          .def(py::init<>())
+          .def_readwrite("timeout", &::c10d::BarrierOptions::timeout);
+
+  py::class_<::c10d::AllToAllOptions>(module, "AllToAllOptions")
+          .def(py::init<>())
+          .def_readwrite("timeout", &::c10d::AllToAllOptions::timeout);
+
+  auto store =
+          py::class_<::c10d::Store, std::shared_ptr<::c10d::Store>, PythonStore>(
+                  module, "Store",
+                  R"(
+Base class for all store implementations, such as the 3 provided by PyTorch
+distributed: (:class:`~torch.distributed.TCPStore`, :class:`~torch.distributed.FileStore`,
+and :class:`~torch.distributed.HashStore`).
+)")
+                  // Default constructor.
+                  .def(py::init<>())
+                          // Convert from std::string to std::vector<uint8>.
+                  .def(
+                          "set",
+                          [](::c10d::Store& store,
+                             const std::string& key,
+                             const std::string& value) {
+                              std::vector<uint8_t> value_(value.begin(), value.end());
+                              store.set(key, value_);
+                          },
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Inserts the key-value pair into the store based on the supplied ``key`` and
+``value``. If ``key`` already exists in the store, it will overwrite the old
+value with the new supplied ``value``.
+
+Arguments:
+    key (str): The key to be added to the store.
+    value (str): The value associated with ``key`` to be added to the store.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.set("first_key", "first_value")
+    >>> # Should return "first_value"
+    >>> store.get("first_key")
+)")
+                          // Convert from std::vector<uint8_t> to py::bytes.
+                          // The returned value is not guaranteed to be valid UTF-8.
+                  .def(
+                          "get",
+                          [](::c10d::Store& store, const std::string& key) -> py::bytes {
+                              auto value = store.get(key);
+                              return py::bytes(
+                                      reinterpret_cast<char*>(value.data()), value.size());
+                          },
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Retrieves the value associated with the given ``key`` in the store. If ``key`` is not
+present in the store, the function will wait for ``timeout``, which is defined
+when initializing the store, before throwing an exception.
+
+Arguments:
+    key (str): The function will return the value associated with this key.
+
+Returns:
+    Value associated with ``key`` if ``key`` is in the store.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.set("first_key", "first_value")
+    >>> # Should return "first_value"
+    >>> store.get("first_key")
+)")
+                  .def(
+                          "add",
+                          &::c10d::Store::add,
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+The first call to add for a given ``key`` creates a counter associated
+with ``key`` in the store, initialized to ``amount``. Subsequent calls to add
+with the same ``key`` increment the counter by the specified ``amount``.
+Calling :meth:`~torch.distributed.store.add` with a key that has already
+been set in the store by :meth:`~torch.distributed.store.set` will result
+in an exception.
+
+Arguments:
+    key (str): The key in the store whose counter will be incremented.
+    amount (int): The quantity by which the counter will be incremented.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> # Using TCPStore as an example, other store types can also be used
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.add("first_key", 1)
+    >>> store.add("first_key", 6)
+    >>> # Should return 7
+    >>> store.get("first_key")
+)")
+                  .def(
+                          "delete_key",
+                          &::c10d::Store::deleteKey,
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Deletes the key-value pair associated with ``key`` from the store. Returns
+`true` if the key was successfully deleted, and `false` if it was not.
+
+.. warning::
+    The ``delete_key`` API is only supported by the :class:`~torch.distributed.TCPStore`. Using this API
+    with the :class:`~torch.distributed.FileStore` or :class:`~torch.distributed.HashStore` will result in an exception.
+
+Arguments:
+    key (str): The key to be deleted from the store
+
+Returns:
+    `true` if ``key`` was deleted, otherwise `false`.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.set("first_key")
+    >>> # This should return true
+    >>> store.delete_key("first_key")
+    >>> # This should return false
+    >>> store.delete_key("bad_key")
+)")
+                  .def(
+                          "num_keys",
+                          &::c10d::Store::getNumKeys,
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Returns the number of keys set in the store. Note that this number will typically
+be one greater than the number of keys added by :meth:`~torch.distributed.store.set`
+and :meth:`~torch.distributed.store.add` since one key is used to coordinate all
+the workers using the store.
+
+.. warning::
+    The ``num_keys`` API is only supported by the :class:`~torch.distributed.TCPStore`. Using this API
+    with the :class:`~torch.distributed.FileStore` or :class:`~torch.distributed.HashStore` will result in an exception.
+
+Returns:
+    The number of keys present in the store.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.set("first_key", "first_value")
+    >>> # This should return 2
+    >>> store.num_keys()
+)")
+                  .def(
+                          "set_timeout",
+                          &::c10d::Store::setTimeout,
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Sets the store's default timeout. This timeout is used during initialization and in
+:meth:`~torch.distributed.store.wait` and :meth:`~torch.distributed.store.get`.
+
+Arguments:
+    timeout (timedelta): timeout to be set in the store.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> # Using TCPStore as an example, other store types can also be used
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> store.set_timeout(timedelta(seconds=10))
+    >>> # This will throw an exception after 10 seconds
+    >>> store.wait(["bad_key"])
+)")
+                  .def(
+                          "wait",
+                          [](::c10d::Store& store, const std::vector<std::string>& keys) {
+                              store.wait(keys);
+                          },
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Waits for each key in ``keys`` to be added to the store. If not all keys are
+set before the ``timeout`` (set during store initialization), then ``wait``
+will throw an exception.
+
+Arguments:
+    keys (list): List of keys on which to wait until they are set in the store.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> # Using TCPStore as an example, other store types can also be used
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> # This will throw an exception after 30 seconds
+    >>> store.wait(["bad_key"])
+)")
+                  .def(
+                          "wait",
+                          [](::c10d::Store& store,
+                             const std::vector<std::string>& keys,
+                             const std::chrono::milliseconds& timeout) {
+                              store.wait(keys, timeout);
+                          },
+                          py::call_guard<py::gil_scoped_release>(),
+                          R"(
+Waits for each key in ``keys`` to be added to the store, and throws an exception
+if the keys have not been set by the supplied ``timeout``.
+
+Arguments:
+    keys (list): List of keys on which to wait until they are set in the store.
+    timeout (timedelta): Time to wait for the keys to be added before throwing an exception.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> # Using TCPStore as an example, other store types can also be used
+    >>> store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> # This will throw an exception after 10 seconds
+    >>> store.wait(["bad_key"], timedelta(seconds=10))
+)");
+
+  shared_ptr_class_<::c10d::FileStore>(module, "FileStore", store,
+                                       R"(
+A store implementation that uses a file to store the underlying key-value pairs.
+
+Arguments:
+    file_name (str): path of the file in which to store the key-value pairs
+    world_size (int): The total number of processes using the store
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store1 = dist.FileStore("/tmp/filestore", 2)
+    >>> store2 = dist.FileStore("/tmp/filestore", 2)
+    >>> # Use any of the store methods from either the client or server after initialization
+    >>> store1.set("first_key", "first_value")
+    >>> store2.get("first_key")
+
+      )")
+          .def(py::init<const std::string&, int>());
+
+#ifndef _WIN32
+  shared_ptr_class_<::c10d::HashStore>(module, "HashStore", store,
+                                       R"(
+A thread-safe store implementation based on an underlying hashmap. This store can be used
+within the same process (for example, by other threads), but cannot be used across processes.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> store = dist.HashStore()
+    >>> # store can be used from other threads
+    >>> # Use any of the store methods after initialization
+    >>> store.set("first_key", "first_value")
+      )")
+          .def(py::init<>());
+
+  shared_ptr_class_<::c10d::TCPStore>(module, "TCPStore", store,
+                                      R"(
+A TCP-based distributed key-value store implementation. The server store holds
+the data, while the client stores can connect to the server store over TCP and
+perform actions such as :meth:`~torch.distributed.store.set` to insert a key-value
+pair, :meth:`~torch.distributed.store.get` to retrieve a key-value pair, etc.
+
+Arguments:
+    host_name (str): The hostname or IP Address the server store should run on.
+    port (int): The port on which the server store should listen for incoming requests.
+    world_size (int): The total number of store users (number of clients + 1 for the server).
+    is_master (bool): True when initializing the server store, False for client stores.
+    timeout (timedelta): Timeout used by the store during initialization and for methods such as :meth:`~torch.distributed.store.get` and :meth:`~torch.distributed.store.wait`.
+
+Example::
+    >>> import torch.distributed as dist
+    >>> server_store = dist.TCPStore("127.0.0.1", 0, true, timedelta(seconds=30))
+    >>> client_store = dist.TCPStore("127.0.0.1", 0, false)
+    >>> # Use any of the store methods from either the client or server after initialization
+    >>> server_store.set("first_key", "first_value")
+    >>> client_store.get("first_key")
+      )")
+          .def(
+                  py::init<
+                          const std::string&,
+                          int,
+                          int,
+                          bool,
+                          std::chrono::milliseconds>(),
+                  py::arg("host_name"),
+                  py::arg("port"),
+                  py::arg("world_size"),
+                  py::arg("is_master"),
+                  py::arg("timeout") =
+                          std::chrono::milliseconds(::c10d::Store::kDefaultTimeout));
+#endif
+
+  shared_ptr_class_<::c10d::PrefixStore>(module, "PrefixStore", store,
+                                         R"(
+A wrapper around any of the 3 key-value stores (:class:`~torch.distributed.TCPStore`,
+:class:`~torch.distributed.FileStore`, and :class:`~torch.distributed.HashStore`)
+that adds a prefix to each key inserted to the store.
+
+Arguments:
+    prefix (str): The prefix string that is prepended to each key before being inserted into the store.
+    store (torch.distributed.store): A store object that forms the underlying key-value store.
+      )")
+          .def(py::init<const std::string&, std::shared_ptr<::c10d::Store>>());
+
+  auto processGroup =
+          shared_ptr_class_<::c10d::ProcessGroup>(module, "ProcessGroup")
+                  .def("rank", &::c10d::ProcessGroup::getRank)
+                  .def("size", &::c10d::ProcessGroup::getSize)
+
+                  .def(
+                          "broadcast",
+                          &::c10d::ProcessGroup::broadcast,
+                          py::arg("tensors"),
+                          py::arg("opts") = ::c10d::BroadcastOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "broadcast",
+                          [](::c10d::ProcessGroup& pg, at::Tensor& x, int rootRank) {
+                              ::c10d::BroadcastOptions opts;
+                              opts.rootRank = rootRank;
+                              std::vector<at::Tensor> xs = {x};
+                              return pg.broadcast(xs, opts);
+                          },
+                          py::arg("tensor"),
+                          py::arg("root"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allreduce",
+                          &::c10d::ProcessGroup::allreduce,
+                          py::arg("tensors"),
+                          py::arg("opts") = ::c10d::AllreduceOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allreduce",
+                          [](::c10d::ProcessGroup& pg,
+                             std::vector<at::Tensor>& xs,
+                             ::c10d::ReduceOp op) {
+                              ::c10d::AllreduceOptions opts;
+                              opts.reduceOp = op;
+                              return pg.allreduce(xs, opts);
+                          },
+                          py::arg("tensors"),
+                          py::arg("op") = ::c10d::ReduceOp::SUM,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allreduce",
+                          [](::c10d::ProcessGroup& pg, at::Tensor& x, ::c10d::ReduceOp op) {
+                              ::c10d::AllreduceOptions opts;
+                              opts.reduceOp = op;
+                              std::vector<at::Tensor> xs = {x};
+                              return pg.allreduce(xs, opts);
+                          },
+                          py::arg("tensor"),
+                          py::arg("op") = ::c10d::ReduceOp::SUM,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allreduce_coalesced",
+                          [](::c10d::ProcessGroup& pg,
+                             std::vector<at::Tensor>& xs,
+                             ::c10d::AllreduceCoalescedOptions opts) {
+                              return pg.allreduce_coalesced(xs, opts);
+                          },
+                          py::arg("tensors"),
+                          py::arg("opts") = ::c10d::AllreduceCoalescedOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "reduce",
+                          &::c10d::ProcessGroup::reduce,
+                          py::arg("tensors"),
+                          py::arg("opts") = ::c10d::ReduceOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "reduce",
+                          [](::c10d::ProcessGroup& pg,
+                             at::Tensor& x,
+                             int rootRank,
+                             ::c10d::ReduceOp op) {
+                              ::c10d::ReduceOptions opts;
+                              opts.reduceOp = op;
+                              opts.rootRank = rootRank;
+                              std::vector<at::Tensor> xs = {x};
+                              return pg.reduce(xs, opts);
+                          },
+                          py::arg("tensor"),
+                          py::arg("root"),
+                          py::arg("op") = ::c10d::ReduceOp::SUM,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allgather",
+                          &::c10d::ProcessGroup::allgather,
+                          py::arg("output_tensors"),
+                          py::arg("input_tensors"),
+                          py::arg("opts") = ::c10d::AllgatherOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allgather",
+                          [](::c10d::ProcessGroup& pg,
+                             std::vector<at::Tensor>& output,
+                             at::Tensor& input) {
+                              std::vector<std::vector<at::Tensor>> outputs = {output};
+                              std::vector<at::Tensor> inputs = {input};
+                              return pg.allgather(
+                                      outputs, inputs, ::c10d::AllgatherOptions());
+                          },
+                          py::arg("output_tensors"),
+                          py::arg("input_tensor"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "allgather_coalesced",
+                          &::c10d::ProcessGroup::allgather_coalesced,
+                          py::arg("output_lists"),
+                          py::arg("input_list"),
+                          py::arg("opts") = ::c10d::AllgatherOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "gather",
+                          &::c10d::ProcessGroup::gather,
+                          py::arg("output_tensors"),
+                          py::arg("input_tensors"),
+                          py::arg("opts") = ::c10d::GatherOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "gather",
+                          [](::c10d::ProcessGroup& pg,
+                             std::vector<at::Tensor>& output,
+                             at::Tensor& input,
+                             int rootRank) {
+                              ::c10d::GatherOptions opts;
+                              opts.rootRank = rootRank;
+                              std::vector<std::vector<at::Tensor>> outputs = {output};
+                              std::vector<at::Tensor> inputs = {input};
+                              return pg.gather(outputs, inputs, opts);
+                          },
+                          py::arg("output_tensors"),
+                          py::arg("input_tensor"),
+                          py::arg("root"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "scatter",
+                          &::c10d::ProcessGroup::scatter,
+                          py::arg("output_tensors"),
+                          py::arg("input_tensors"),
+                          py::arg("opts") = ::c10d::ScatterOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "scatter",
+                          [](::c10d::ProcessGroup& pg,
+                             at::Tensor& output,
+                             std::vector<at::Tensor>& input,
+                             int rootRank) {
+                              ::c10d::ScatterOptions opts;
+                              opts.rootRank = rootRank;
+                              std::vector<std::vector<at::Tensor>> inputs = {input};
+                              std::vector<at::Tensor> outputs = {output};
+                              return pg.scatter(outputs, inputs, opts);
+                          },
+                          py::arg("output_tensor"),
+                          py::arg("input_tensors"),
+                          py::arg("root"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "reduce_scatter",
+                          &::c10d::ProcessGroup::reduce_scatter,
+                          py::arg("output_tensors"),
+                          py::arg("input_tensors"),
+                          py::arg("opts") = ::c10d::ReduceScatterOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "reduce_scatter",
+                          [](::c10d::ProcessGroup& pg,
+                             at::Tensor& output,
+                             std::vector<at::Tensor>& input) {
+                              std::vector<at::Tensor> outputs = {output};
+                              std::vector<std::vector<at::Tensor>> inputs = {input};
+                              return pg.reduce_scatter(
+                                      outputs, inputs, ::c10d::ReduceScatterOptions());
+                          },
+                          py::arg("output_tensors"),
+                          py::arg("input_tensor"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "alltoall_base",
+                          &::c10d::ProcessGroup::alltoall_base,
+                          py::arg("output_tensor"),
+                          py::arg("input_tensor"),
+                          py::arg("output_split_sizes"),
+                          py::arg("input_split_sizes"),
+                          py::arg("opts") = ::c10d::AllToAllOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "alltoall_base",
+                          [](::c10d::ProcessGroup& pg,
+                             at::Tensor& output,
+                             at::Tensor& input,
+                             std::vector<int64_t> outputSplitSizes,
+                             std::vector<int64_t> inputSplitSizes) {
+                              return pg.alltoall_base(
+                                      output,
+                                      input,
+                                      outputSplitSizes,
+                                      inputSplitSizes,
+                                      ::c10d::AllToAllOptions());
+                          },
+                          py::arg("output"),
+                          py::arg("input"),
+                          py::arg("output_split_sizes"),
+                          py::arg("input_split_sizes"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "alltoall",
+                          &::c10d::ProcessGroup::alltoall,
+                          py::arg("output_tensor"),
+                          py::arg("input_tensor"),
+                          py::arg("opts") = ::c10d::AllToAllOptions(),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "alltoall",
+                          [](::c10d::ProcessGroup& pg,
+                             std::vector<at::Tensor>& output,
+                             std::vector<at::Tensor>& input) {
+                              return pg.alltoall(output, input, ::c10d::AllToAllOptions());
+                          },
+                          py::arg("output"),
+                          py::arg("input"),
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "send",
+                          &::c10d::ProcessGroup::send,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "recv",
+                          &::c10d::ProcessGroup::recv,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "recv_anysource",
+                          &::c10d::ProcessGroup::recvAnysource,
+                          py::call_guard<py::gil_scoped_release>())
+
+                  .def(
+                          "barrier",
+                          &::c10d::ProcessGroup::barrier,
+                          py::arg("opts") = ::c10d::BarrierOptions(),
+                          py::call_guard<py::gil_scoped_release>());
+
+#ifndef _WIN32
+  module.def(
+          "_round_robin_process_groups",
+          [](std::vector<std::shared_ptr<::c10d::ProcessGroup>> processGroups)
+                  -> std::shared_ptr<::c10d::ProcessGroup> {
+              if (processGroups.size() == 0) {
+                throw std::invalid_argument("Specify at least 1 process group");
+              }
+              const auto& first = processGroups.front();
+              return std::make_shared<::c10d::ProcessGroupRoundRobin>(
+                      first->getRank(), first->getSize(), std::move(processGroups));
+          },
+          py::arg("process_groups"),
+          py::call_guard<py::gil_scoped_release>());
+#endif
+
+#ifdef USE_C10D_GLOO
+  auto processGroupGloo = shared_ptr_class_<::c10d::ProcessGroupGloo>(
+      module, "ProcessGroupGloo", processGroup);
+
+  shared_ptr_class_<::gloo::transport::Device>(processGroupGloo, "Device");
+
+  shared_ptr_class_<::c10d::ProcessGroupGloo::Options>(
+      processGroupGloo, "Options")
+      .def(py::init<>())
+      .def_readwrite("devices", &::c10d::ProcessGroupGloo::Options::devices)
+      .def_readwrite("timeout", &::c10d::ProcessGroupGloo::Options::timeout)
+      .def_readwrite("threads", &::c10d::ProcessGroupGloo::Options::threads);
+
+  processGroupGloo.def_static(
+      "create_device",
+      [](const std::string& hostname, const std::string& interface)
+          -> std::shared_ptr<::gloo::transport::Device> {
+        if (!hostname.empty()) {
+          return ::c10d::ProcessGroupGloo::createDeviceForHostname(hostname);
+        }
+        if (!interface.empty()) {
+          return ::c10d::ProcessGroupGloo::createDeviceForInterface(interface);
+        }
+        throw std::invalid_argument(
+            "Specify either `hostname` or `interface` argument.");
+      },
+      py::arg("hostname") = "",
+      py::arg("interface") = "");
+
+  processGroupGloo
+      .def(py::init<
+           const std::shared_ptr<::c10d::Store>&,
+           int,
+           int,
+           ::c10d::ProcessGroupGloo::Options>(),
+           py::call_guard<py::gil_scoped_release>())
+      .def(
+          py::init([](const std::shared_ptr<::c10d::Store>& store,
+                      int rank,
+                      int size,
+                      std::chrono::milliseconds timeout) {
+            ::c10d::ProcessGroupGloo::Options options;
+
+            // Use interfaces listed in "GLOO_SOCKET_IFNAME", if set.
+            char* ifnameEnv = getenv(GLOO_SOCKET_IFNAME_ENV);
+            if (ifnameEnv) {
+              for (const auto& iface : split(',', ifnameEnv)) {
+                options.devices.push_back(
+                    ::c10d::ProcessGroupGloo::createDeviceForInterface(iface));
+              }
+            } else {
+              // If no hostname is specified, this function looks up
+              // the machine's hostname and returns a device instance
+              // associated with the address that the hostname resolves to.
+              options.devices.push_back(
+                  ::c10d::ProcessGroupGloo::createDefaultDevice());
+            }
+
+            options.timeout = timeout;
+            options.threads = options.devices.size() * 2;
+            return std::make_shared<::c10d::ProcessGroupGloo>(
+                store, rank, size, options);
+          }),
+          py::arg("store"),
+          py::arg("rank"),
+          py::arg("size"),
+          py::arg("timeout") = std::chrono::milliseconds(10 * 1000), // NOLINT
+          py::call_guard<py::gil_scoped_release>());
+#endif
+
+#ifdef USE_C10D_NCCL
+  auto processGroupNCCL = shared_ptr_class_<::c10d::ProcessGroupNCCL>(
+      module, "ProcessGroupNCCL", processGroup)
+      .def(py::init<
+           const std::shared_ptr<::c10d::Store>&,
+           int,
+           int,
+           ::c10d::ProcessGroupNCCL::Options>(),
+           py::call_guard<py::gil_scoped_release>())
+      .def(
+          py::init([](const std::shared_ptr<::c10d::Store>& store,
+                      int rank,
+                      int size,
+                      const std::chrono::milliseconds& timeout){
+            ::c10d::ProcessGroupNCCL::Options options;
+            options.isHighPriorityStream = false;
+            options.opTimeout = timeout;
+            return std::make_shared<::c10d::ProcessGroupNCCL>(
+                store, rank, size, options);
+          }),
+          py::arg("store"),
+          py::arg("rank"),
+          py::arg("size"),
+          py::arg("timeout") = std::chrono::milliseconds(
+              ::c10d::ProcessGroupNCCL::kProcessGroupNCCLOpTimeoutMillis),
+          py::call_guard<py::gil_scoped_release>());
+
+  py::class_<::c10d::ProcessGroupNCCL::Options>(processGroupNCCL, "Options")
+      .def(py::init<>())
+      .def_readwrite("is_high_priority", &::c10d::ProcessGroupNCCL::Options::isHighPriorityStream)
+      .def_readwrite("op_timeout", &::c10d::ProcessGroupNCCL::Options::opTimeout);
+#endif
+
+#ifdef USE_C10D_MPI
+  auto processGroupMPI = shared_ptr_class_<::c10d::ProcessGroupMPI>(
+      module, "ProcessGroupMPI", processGroup);
+
+  // Define static create function instead of a constructor, because
+  // this function may return null. This happens if this process is not
+  // part of a sub group that is to be created.
+  processGroupMPI.def_static(
+    "create",
+    [](std::vector<int> ranks) {
+      return ::c10d::ProcessGroupMPI::createProcessGroupMPI(ranks);
+    },
+    py::call_guard<py::gil_scoped_release>());
+#endif
+
+  shared_ptr_class_<::c10d::ProcessGroup::Work>(module, "Work")
+          .def("is_completed", &::c10d::ProcessGroup::Work::isCompleted)
+          .def(
+                  "is_success",
+                  [](::c10d::ProcessGroup::Work& work) -> bool {
+                      TORCH_WARN_ONCE(fmt::format(
+                              kDeprecationWarning, "ProcessGroup::Work::is_success"));
+                      return work.isSuccess();
+                  })
+          .def(
+                  "exception",
+                  [](::c10d::ProcessGroup::Work& work) -> std::exception_ptr {
+                      TORCH_WARN_ONCE(fmt::format(
+                              kDeprecationWarning, "ProcessGroup::Work::exception"));
+                      return work.exception();
+                  })
+          .def(
+                  "source_rank",
+                  [](::c10d::ProcessGroup::Work& work) -> int {
+                      TORCH_WARN_ONCE(fmt::format(
+                              kDeprecationWarning, "ProcessGroup::Work::source_rank"));
+                      return work.sourceRank();
+                  })
+          .def("_source_rank", &::c10d::ProcessGroup::Work::sourceRank)
+          .def(
+                  "result",
+                  [](::c10d::ProcessGroup::Work& work) -> std::vector<at::Tensor> {
+                      return work.result();
+                  })
+          .def(
+                  "synchronize",
+                  [](::c10d::ProcessGroup::Work& work) -> void {
+                      TORCH_WARN_ONCE(fmt::format(
+                              kDeprecationWarning, "ProcessGroup::Work::synchronize"));
+                      work.synchronize();
+                  })
+          .def(
+                  "wait",
+                  &::c10d::ProcessGroup::Work::wait,
+                  py::arg("timeout") = kNoTimeout,
+                  py::call_guard<py::gil_scoped_release>())
+          .def(
+                  "get_future",
+                  [](::c10d::ProcessGroup::Work& work)
+                          -> std::shared_ptr<jit::PythonFutureWrapper> {
+                      return std::make_shared<jit::PythonFutureWrapper>(work.getFuture());
+                  },
+                  R"(
+            Returns:
+                A ``torch._C.Future`` object which is associated with the completion of
+                the ``ProcessGroup::Work``. As an example, a future object can be retrieved
+                by ``fut = process_group.allreduce(tensors).get_future()``.
+
+            Example::
+                Below is an example of a simple allreduce DDP communication hook that uses
+                ``get_future` API to retrieve a Future associated with the completion of
+                ``allreduce`` work.
+
+                >>> def allreduce(state: object, bucket: dist._GradBucket): -> torch._C.Future
+                >>>     tensors = [t / process_group.world_size for t in bucket.get_tensors()]
+                >>>     work = process_group.allreduce(tensors)
+                >>>     return work.get_future()
+
+                >>> ddp_model._register_comm_hook(state = None, hook = allreduce)
+
+            .. warning ::
+                ``get_future`` API supports only NCCL backend and single-process single-device mode.
+                The ``torch._C.Future`` object returned by this API can be used in
+                ``DistributedDataParallel._register_comm_hook``, but it is subject to some subtle
+                differences compared to ``torch.futures.Future`` due to compromises made for performance
+                reasons.
+
+                In the example above, ``allreduce`` work will be done on GPU using NCCL backend,
+                ``fut.wait()`` will return after synchronizing the appropriate NCCL streams
+                with PyTorch's default device streams to ensure we can have asynchronous CUDA
+                execution and it does not wait for the entire operation to complete on GPU. Note that
+                ``FutureNCCL``  does not support ``NCCL_BLOCKING_WAIT`` flag or NCCL's ``barrier()``.
+                In addition, if a callback function was added by ``fut.then()``, it will wait until
+                ``WorkNCCL``'s NCCL streams synchronize with ``ProcessGroupNCCL``'s dedicated callback
+                stream and invoke the callback inline after running the callback on the callback stream.
+                ``fut.then()`` will return another ``FutureNCCL`` that holds the return value of the
+                callback and a ``CUDAEvent`` that recorded the callback stream.
+
+                Note that ``fut.done()`` returns if the enire operation is completed on the GPU.
+           )");
+
+  module.def(
+          "_compute_bucket_assignment_by_size",
+          &::c10d::compute_bucket_assignment_by_size,
+          py::arg("tensors"),
+          py::arg("bucket_size"),
+          py::arg("expect_sparse_gradient") = std::vector<bool>(),
+          py::arg("tensor_indices") = std::vector<int64_t>(),
+          py::call_guard<py::gil_scoped_release>());
+
+  module.def(
+          "_broadcast_coalesced",
+          // Define a lambda such that the pybind11 prototype can take a std::vector
+          // for the tensor list argument, but still pass it to the underlying
+          // function as a c10::ArrayRef.
+          [](std::shared_ptr<::c10d::ProcessGroup> process_group,
+             std::vector<at::Tensor> tensors, // NOLINT
+             size_t buffer_size,
+             int rank) {
+              broadcast_coalesced(
+                      std::move(process_group), tensors, buffer_size, rank);
+          },
+          py::arg("process_group"),
+          py::arg("tensors"),
+          py::arg("buffer_size"),
+          // The source of truth rank to broadcast the tensors from.
+          py::arg("src") = 0,
+          py::call_guard<py::gil_scoped_release>());
+
+  module.def(
+          "_test_python_store",
+          // Define a function that takes a c10d store and runs a few tests.
+          // This is used by the PythonStore tests, which we cannot test from the
+          // Python side of the world. Calling Python functions on a Python object
+          // completely bypasses pybind11. We need to test that the overloaded
+          // functions call into Python and behave like we expect.
+          [](std::shared_ptr<::c10d::Store> store) {
+              auto add = [&store](const std::string& key, int64_t value) {
+                  store->add(key, value);
+              };
+
+              auto set = [&store](const std::string& key, const std::string& value) {
+                  std::vector<uint8_t> value_(value.begin(), value.end());
+                  store->set(key, value_);
+              };
+
+              auto get = [&store](const std::string& key) {
+                  auto value = store->get(key);
+                  return std::string(value.begin(), value.end());
+              };
+
+              add("key", 1);
+              add("key", 2);
+              add("key", 3);
+              set("key0", "value0");
+              add("key3", 1);
+              set("key1", "value1");
+              add("key3", 2);
+              set("key2", "value2");
+              add("key3", 3);
+              add("key3", 4);
+              add("key3", 3);
+              add("key3", 2);
+              if (get("key") != "6") {
+                throw std::runtime_error("assertion failed");
+              }
+              if (get("key0") != "value0") {
+                throw std::runtime_error("assertion failed");
+              }
+              if (get("key1") != "value1") {
+                throw std::runtime_error("assertion failed");
+              }
+              if (get("key2") != "value2") {
+                throw std::runtime_error("assertion failed");
+              }
+              if (get("key3") != "15") {
+                throw std::runtime_error("assertion failed");
+              }
+          },
+          py::call_guard<py::gil_scoped_release>());
+
+  module.attr("_DEFAULT_FIRST_BUCKET_BYTES") = ::c10d::kDefaultFirstBucketBytes;
+#endif
+  Py_RETURN_TRUE;
+}
+
+} // namespace distributed
+} // namespace torch
diff --git a/torch/csrc/Runtime.h b/torch/csrc/Runtime.h
new file mode 100644
index 0000000000..aec2772a2c
--- /dev/null
+++ b/torch/csrc/Runtime.h
@@ -0,0 +1,11 @@
+#pragma once
+
+#include <torch/csrc/python_headers.h>
+
+namespace torch {
+namespace runtime {
+
+PyObject* init_runtime(PyObject* module);
+
+} // namespace distributed
+} // namespace torch
diff --git a/torch/cuda/__init__.py b/torch/cuda/__init__.py
index 1176c6ee30..a0aa5a2908 100644
--- a/torch/cuda/__init__.py
+++ b/torch/cuda/__init__.py
@@ -8,6 +8,7 @@ It is lazily initialized, so you can always import it, and use
 :ref:`cuda-semantics` has more details about working with CUDA.
 """
 
+import sys
 import contextlib
 import os
 import torch
@@ -473,6 +474,10 @@ class _CudaBase(object):
     __new__ = _lazy_new
 
 
+def get_device_type() -> str:
+    return 'cuda'
+
+
 class DoubleStorage(_CudaBase, torch._C.CudaDoubleStorageBase, _StorageBase):
     pass
 
@@ -536,3 +541,9 @@ from . import sparse
 from . import profiler
 from . import nvtx
 from . import amp
+
+from torch._C.runtime import register_runtime
+
+
+current_module = sys.modules[__name__]
+register_runtime('cuda', current_module)
diff --git a/torch/nn/parallel/data_parallel.py b/torch/nn/parallel/data_parallel.py
index b66c1513ad..d8ba838cff 100644
--- a/torch/nn/parallel/data_parallel.py
+++ b/torch/nn/parallel/data_parallel.py
@@ -10,6 +10,7 @@ from torch._utils import (
     _get_all_device_indices,
     _get_available_device_type,
     _get_device_index,
+    _get_device_type,
     _get_devices_properties
 )
 
@@ -121,14 +122,19 @@ class DataParallel(Module):
     def __init__(self, module, device_ids=None, output_device=None, dim=0):
         super(DataParallel, self).__init__()
 
-        device_type = _get_available_device_type()
-        if device_type is None:
-            self.module = module
-            self.device_ids = []
-            return
-
         if device_ids is None:
+            device_type = _get_available_device_type()
+            if device_type is None:
+                self.module = module
+                self.device_ids = []
+                return
             device_ids = _get_all_device_indices()
+        else:
+            distinct_device_types = {_get_device_type(device_id, optional=True) for device_id in device_ids}
+            assert len(distinct_device_types) == 1, (
+                "DataParallel's device_ids must be the same type of devices, but device_ids locate in {}."
+            ).format(distinct_device_types)
+            device_type = list(distinct_device_types)[0]
 
         if output_device is None:
             output_device = device_ids[0]
@@ -192,10 +198,15 @@ def data_parallel(module, inputs, device_ids=None, output_device=None, dim=0, mo
     if not isinstance(inputs, tuple):
         inputs = (inputs,)
 
-    device_type = _get_available_device_type()
-
     if device_ids is None:
+        device_type = _get_available_device_type()
         device_ids = _get_all_device_indices()
+    else:
+        distinct_device_types = {_get_device_type(device_id, optional=True) for device_id in device_ids}
+        assert len(distinct_device_types) == 1, (
+            "DataParallel's device_ids must be the same type of devices, but device_ids locate in {}."
+        ).format(distinct_device_types)
+        device_type = list(distinct_device_types)[0]
 
     if output_device is None:
         output_device = device_ids[0]
-- 
2.25.1

