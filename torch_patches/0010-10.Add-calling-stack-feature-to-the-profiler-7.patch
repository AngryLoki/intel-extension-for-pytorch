From 9ddefa4ef4657fea54163785f040ec448333c69f Mon Sep 17 00:00:00 2001
From: "Xunsong, Huang" <xunsong.huang@intel.com>
Date: Thu, 1 Jul 2021 16:17:28 +0800
Subject: [PATCH 10/14] 10.Add calling stack feature to the profiler (#7)

* Add level tree for called op in profiler

Use `profile_level` in `torch.autograd.profiler.profile` to use this
feature.
You can also limit `max_level` in `table` to avoid too much items for
showing.

Signed-off-by: Xunsong, Huang <xunsong.huang@intel.com>

* Rename 'level' to 'calling_stack'

Signed-off-by: Xunsong, Huang <xunsong.huang@intel.com>
---
 torch/autograd/profiler.py | 58 +++++++++++++++++++++++++++++++-------
 1 file changed, 48 insertions(+), 10 deletions(-)

diff --git a/torch/autograd/profiler.py b/torch/autograd/profiler.py
index dc88741ebc..51a5e65b62 100644
--- a/torch/autograd/profiler.py
+++ b/torch/autograd/profiler.py
@@ -37,11 +37,14 @@ class EventList(list):
         use_cuda = kwargs.pop('use_cuda', True)
         use_xpu = kwargs.pop('use_xpu', False)
         profile_memory = kwargs.pop('profile_memory', False)
+        with_calling_stack = kwargs.pop('with_calling_stack', False)
         super(EventList, self).__init__(*args, **kwargs)
         self._cpu_children_populated = False
         self._use_cuda = use_cuda
         self._use_xpu = use_xpu
         self._profile_memory = profile_memory
+        self._with_calling_stack = with_calling_stack 
+
 
     def __str__(self):
         return self.table()
@@ -153,7 +156,7 @@ class EventList(list):
     def cpu_children_populated(self):
         return self._cpu_children_populated
 
-    def table(self, sort_by=None, row_limit=100, header=None, top_level_events_only=False):
+    def table(self, sort_by=None, row_limit=100, max_depth=10, header=None, top_level_events_only=False):
         """Prints an EventList as a nicely formatted table.
 
         Arguments:
@@ -175,10 +178,12 @@ class EventList(list):
             self,
             sort_by=sort_by,
             row_limit=row_limit,
+            max_depth=max_depth,
             header=header,
             use_cuda=self._use_cuda,
             use_xpu=self._use_xpu,
             profile_memory=self._profile_memory,
+            with_calling_stack=self._with_calling_stack,
             top_level_events_only=top_level_events_only)
 
     def export_chrome_trace(self, path):
@@ -277,7 +282,8 @@ class EventList(list):
         for evt in self:
             stats[get_key(evt, group_by_input_shapes, group_by_stack_n)].add(evt)
 
-        avg_list = EventList(stats.values(), use_cuda=self._use_cuda, use_xpu=self._use_xpu, profile_memory=self._profile_memory)
+        avg_list = EventList(stats.values(), use_cuda=self._use_cuda, use_xpu=self._use_xpu,
+                             profile_memory=self._profile_memory, with_calling_stack=self._with_calling_stack)
         for evt in avg_list:
             evt.stack = evt.stack[:group_by_stack_n]
             if not group_by_input_shapes:
@@ -329,6 +335,8 @@ class profile(object):
 
         profile_memory (bool, optional): Whether to report memory usage, default: ``False``
 
+        with_calling_stack (bool, optional): Whether to report op call stack as a tree, default: ``False``
+
         with_stack (bool, optional): record source information (file and line number) for the ops
 
     .. warning:
@@ -371,6 +379,7 @@ class profile(object):
             use_xpu=False,
             record_shapes=False,
             profile_memory=False,
+            with_calling_stack=False,
             with_stack=False):
         self.enabled = enabled
         self.use_cuda = use_cuda
@@ -381,6 +390,7 @@ class profile(object):
         self.entered = False
         self.record_shapes = record_shapes
         self.profile_memory = profile_memory
+        self.with_calling_stack = with_calling_stack 
         self.with_stack = with_stack
 
     def __enter__(self):
@@ -414,7 +424,8 @@ class profile(object):
             parse_event_records(records),
             use_cuda=self.use_cuda,
             use_xpu=self.use_xpu,
-            profile_memory=self.profile_memory)
+            profile_memory=self.profile_memory,
+            with_calling_stack = self.with_calling_stack)
         if self.with_stack:
             self.function_events.set_backward_stacktraces()
         return False
@@ -435,11 +446,11 @@ class profile(object):
             raise RuntimeError("can't export a trace that didn't finish running")
         self.function_events.populate_cpu_children()
 
-    def table(self, sort_by=None, row_limit=100, header=None, top_level_events_only=False):
+    def table(self, sort_by=None, row_limit=100, max_depth=10, header=None, top_level_events_only=False):
         self._check_finish()
         assert self.function_events is not None
         return self.function_events.table(
-            sort_by=sort_by, row_limit=row_limit, header=header,
+            sort_by=sort_by, row_limit=row_limit, max_depth=max_depth, header=header,
             top_level_events_only=top_level_events_only
         )
     table.__doc__ = EventList.table.__doc__
@@ -753,7 +764,7 @@ Kernel = namedtuple('Kernel', ['name', 'device', 'interval'])
 class FunctionEvent(FormattedTimesMixin):
     """Profiling information about a single function."""
     def __init__(
-            self, id, node_id, name, thread, cpu_start=0, cpu_end=0, fwd_thread=None, input_shapes=None,
+            self, id, node_id, name, thread, cpu_start=0, cpu_end=0, fwd_thread=None, input_shapes=None, cstack=None,
             stack=None, scope=0, cpu_memory_usage=0, cuda_memory_usage=0, xpu_memory_usage=0, is_async=False,
             is_remote=True, sequence_nr=-1):
         self.id: int = id
@@ -768,6 +779,7 @@ class FunctionEvent(FormattedTimesMixin):
         self.cpu_children: List[FunctionEvent] = []
         self.cpu_parent: Optional[FunctionEvent] = None
         self.input_shapes: Tuple[int, ...] = input_shapes
+        self.cstack: Tuple[int, ...] = cstack 
         self.stack: List = stack
         self.scope: int = scope
         self.cpu_memory_usage: int = cpu_memory_usage
@@ -865,7 +877,7 @@ class FunctionEvent(FormattedTimesMixin):
     def __repr__(self):
         return (
             '<FunctionEvent id={} node_id={} cpu_time={} cpu_start={} cpu_end={} '
-            'cpu_children={} cuda_time={} xpu_time={} name={} thread={} input_shapes={} '
+            'cpu_children={} cuda_time={} xpu_time={} name={} thread={} input_shapes={} cstack={}'
             'cpu_memory_usage={} cuda_memory_usage={} xpu_memory_usage={} xpu_kernels={} is_async={} is_remote={} seq_nr={}>'.format(
                 self.id,
                 self.node_id,
@@ -878,6 +890,7 @@ class FunctionEvent(FormattedTimesMixin):
                 self.name,
                 self.thread,
                 str(self.input_shapes),
+                str(self.cstack),
                 self.cpu_memory_usage,
                 self.cuda_memory_usage,
                 self.xpu_memory_usage,
@@ -904,6 +917,7 @@ class FunctionEventAvg(FormattedTimesMixin):
         self.self_cuda_time_total: int = 0
         self.self_xpu_time_total: int = 0
         self.input_shapes: Optional[List[List[int]]] = None
+        self.cstack: Optional[List] = None
         self.stack: Optional[List] = None
         self.scope: Optional[int] = None
         self.cpu_memory_usage: int = 0
@@ -927,6 +941,7 @@ class FunctionEventAvg(FormattedTimesMixin):
             self.cpu_children = other.cpu_children
 
             self.input_shapes = other.input_shapes
+            self.cstack= other.cstack
             self.stack = other.stack
             self.scope = other.scope
 
@@ -953,7 +968,7 @@ class FunctionEventAvg(FormattedTimesMixin):
     def __repr__(self):
         return (
             '<FunctionEventAvg key={} self_cpu_time={} cpu_time={} '
-            ' self_cuda_time={} cuda_time={} self_xpu_time={} xpu_time={} input_shapes={} '
+            ' self_cuda_time={} cuda_time={} self_xpu_time={} xpu_time={} input_shapes={} cstack={}'
             'cpu_memory_usage={} cuda_memory_usage={} xpu_memory_usage={}>'.format(
                 self.key,
                 self.self_cpu_time_total_str,
@@ -963,6 +978,7 @@ class FunctionEventAvg(FormattedTimesMixin):
                 self.self_xpu_time_str,
                 self.xpu_time_str,
                 str(self.input_shapes),
+                str(self.cstack),
                 self.cpu_memory_usage,
                 self.cuda_memory_usage,
                 self.xpu_memory_usage,
@@ -1050,6 +1066,8 @@ def parse_event_records(thread_records):
         # ranges per handle
         range_starts = {}
         function_stack = []
+        calling_stack = []
+        calling_id = 0
 
         filtered_handles = set()
         prev_record = None
@@ -1077,6 +1095,8 @@ def parse_event_records(thread_records):
                 cpu_memory_allocs[record_key] = 0
                 cuda_memory_allocs[record_key] = 0
                 xpu_memory_allocs[record_key] = 0
+                calling_stack.append(calling_id+1)
+                calling_id = 0
 
                 fe = FunctionEvent(
                     id=record.handle(),
@@ -1084,6 +1104,7 @@ def parse_event_records(thread_records):
                     name=string_table[record.name()],
                     thread=record.thread_id(),
                     input_shapes=record.shapes(),
+                    cstack=tuple(calling_stack),
                 )
                 function_stack.append(fe)
             elif record.kind() == 'pop':
@@ -1096,6 +1117,7 @@ def parse_event_records(thread_records):
 
                 start = range_starts[record_key]
                 fe = function_stack.pop()
+                calling_id = calling_stack.pop()
 
                 cpu_memory_usage = cpu_memory_allocs[record_key]
                 cuda_memory_usage = cuda_memory_allocs[record_key]
@@ -1150,7 +1172,8 @@ def parse_event_records(thread_records):
                             node_id=record.node_id(),
                             name=string_table[record.name()],
                             thread=record.thread_id(),
-                            input_shapes=record.shapes())
+                            input_shapes=record.shapes(),
+                            cstack = tuple(calling_stack))
                         fe.append_xpu_kernel(record.name,
                                                record.device,
                                                record.xpu_elapsed_us())
@@ -1255,9 +1278,11 @@ def build_table(
         sort_by=None,
         header=None,
         row_limit=100,
+        max_depth=10,
         use_cuda=True,
         use_xpu=False,
         profile_memory=False,
+        with_calling_stack=False,
         top_level_events_only=False):
     """Prints a summary of events (which can be a list of FunctionEvent or FunctionEventAvg)."""
     if len(events) == 0:
@@ -1266,7 +1291,7 @@ def build_table(
     if sort_by is not None:
         events = EventList(sorted(
             events, key=lambda evt: getattr(evt, sort_by), reverse=True
-        ), use_cuda=use_cuda, use_xpu=use_xpu, profile_memory=profile_memory)
+        ), use_cuda=use_cuda, use_xpu=use_xpu, profile_memory=profile_memory, with_calling_stack=with_calling_stack)
 
     has_input_shapes = any(
         [(event.input_shapes is not None and len(event.input_shapes) > 0) for event in events])
@@ -1278,6 +1303,9 @@ def build_table(
     shapes_column_width = max([len(str(evt.input_shapes)) for evt in events]) + 4
     shapes_column_width = min(shapes_column_width, 45)
 
+    cstack_column_width = max([len(str(evt.cstack[:max_depth])[1:-1]) for evt in events]) + 8
+    cstack_column_width = max(cstack_column_width, 20)
+
     src_column_width = None
     stacks = []
     for evt in events:
@@ -1349,6 +1377,10 @@ def build_table(
     for _ in headers[1:]:
         add_column(DEFAULT_COLUMN_WIDTH)
 
+    if with_calling_stack:
+        headers.append('Calling Stack Tree'.ljust(cstack_column_width))
+        add_column(cstack_column_width)
+
     if has_input_shapes:
         headers.append('Input Shapes')
         add_column(shapes_column_width)
@@ -1444,6 +1476,12 @@ def build_table(
             evt.count,  # Number of calls
         )
 
+        if with_calling_stack:
+            if len(evt.cstack) > max_depth:
+                cstack_str = str(evt.cstack[:max_depth])[1:-1] + ",..."
+            else:
+                cstack_str = str(evt.cstack)[1:-1]
+            row_values.append(cstack_str.ljust(cstack_column_width))
         if append_node_id:
             row_values.append(evt.node_id)
         if has_input_shapes:
-- 
2.25.1

