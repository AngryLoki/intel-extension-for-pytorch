From 9fe3df49765b9f2c369ae71e2f59be37ac1267b7 Mon Sep 17 00:00:00 2001
From: Zhiwei <532707544@qq.com>
Date: Fri, 30 Sep 2022 17:30:59 +0800
Subject: [PATCH 26/28] Enhance non-cpu qtensor serialization support (#55)

* Use empty_quantized for pickling int8 tensor
* Add fake size setting when unpickling qtensor
* Make linear prepack TORCH_API
* Add building marco to control int8 jit save
* INT8 jit save build default on
* Fix Windows build, __declspec(dllexport) should
  be present in the declaration as well,
  if it's present in the definition

Co-authored-by: Jinghui <jinghui.gu@intel.com>
---
 CMakeLists.txt                                    |  5 +++++
 aten/src/ATen/native/native_functions.yaml        |  2 +-
 aten/src/ATen/native/quantized/QTensor.cpp        |  6 +++++-
 .../ATen/native/quantized/cpu/fbgemm_utils.cpp    |  8 ++++++++
 aten/src/ATen/native/quantized/cpu/fbgemm_utils.h |  4 ++++
 cmake/Summary.cmake                               |  1 +
 torch/csrc/jit/serialization/pickler.cpp          | 15 ++++++++++++++-
 torch/csrc/jit/serialization/unpickler.cpp        |  3 +--
 8 files changed, 39 insertions(+), 5 deletions(-)

diff --git a/CMakeLists.txt b/CMakeLists.txt
index 0c11507838..2085f27d51 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -216,6 +216,7 @@ option(USE_METAL "Use Metal for Caffe2 iOS build" ON)
 option(USE_PYTORCH_METAL "Use Metal for PyTorch iOS build" OFF)
 option(USE_PYTORCH_METAL_EXPORT "Export Metal models on MacOSX desktop" OFF)
 option(USE_NATIVE_ARCH "Use -march=native" OFF)
+option(BUILD_JIT_QUANTIZATION_SAVE "Support jit quantization model save and load for XPU device" ON)
 cmake_dependent_option(
     USE_MLCOMPUTE "Use ML Compute for macOS build" ON
     "MLCOMPUTE_FOUND" OFF)
@@ -656,6 +657,10 @@ if(USE_FBGEMM)
   string(APPEND CMAKE_CXX_FLAGS " -DUSE_FBGEMM")
 endif()
 
+if(BUILD_JIT_QUANTIZATION_SAVE)
+  string(APPEND CMAKE_CXX_FLAGS " -DBUILD_JIT_QUANTIZATION_SAVE")
+endif()
+
 if(USE_QNNPACK)
   string(APPEND CMAKE_CXX_FLAGS " -DUSE_QNNPACK")
 endif()
diff --git a/aten/src/ATen/native/native_functions.yaml b/aten/src/ATen/native/native_functions.yaml
index 592d0f79ae..87ee7433e3 100644
--- a/aten/src/ATen/native/native_functions.yaml
+++ b/aten/src/ATen/native/native_functions.yaml
@@ -5552,7 +5552,7 @@
   device_check: NoCheck
   device_guard: False
   dispatch:
-    CPU, CUDA: set_
+    CPU, CUDA, QuantizedCPU: set_
 
 - func: set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, int storage_offset, int[] size, int[] stride=[]) -> Tensor(a!)
   variants: method
diff --git a/aten/src/ATen/native/quantized/QTensor.cpp b/aten/src/ATen/native/quantized/QTensor.cpp
index 8220fc1fab..c41943c5a7 100644
--- a/aten/src/ATen/native/quantized/QTensor.cpp
+++ b/aten/src/ATen/native/quantized/QTensor.cpp
@@ -134,7 +134,11 @@ Tensor& set_storage_quantized_(
   auto* self_ = self.unsafeGetTensorImpl();
   self_->set_storage_keep_dtype(storage);
   self_->set_storage_offset(storage_offset);
-  self_->set_sizes_and_strides(sizes, strides);
+  if(strides.data() == nullptr){
+    self_->set_sizes_contiguous(sizes);
+  }else{
+    self_->set_sizes_and_strides(sizes, strides);
+  }
   return self;
 }
 
diff --git a/aten/src/ATen/native/quantized/cpu/fbgemm_utils.cpp b/aten/src/ATen/native/quantized/cpu/fbgemm_utils.cpp
index 1d933741c7..aa2d57c1aa 100644
--- a/aten/src/ATen/native/quantized/cpu/fbgemm_utils.cpp
+++ b/aten/src/ATen/native/quantized/cpu/fbgemm_utils.cpp
@@ -13,7 +13,11 @@
 #include <c10/util/accumulate.h>
 #include <torch/custom_class.h>
 
+#ifdef BUILD_JIT_QUANTIZATION_SAVE
+TORCH_API torch::class_<LinearPackedParamsBase> register_linear_params();
+#else
 torch::class_<LinearPackedParamsBase> register_linear_params();
+#endif
 torch::class_<EmbeddingPackedParamsBase> register_embedding_params();
 
 #ifdef USE_FBGEMM
@@ -405,7 +409,11 @@ TORCH_API torch::class_<ConvPackedParamsBase<2>> register_conv_params<2>();
 template
 TORCH_API torch::class_<ConvPackedParamsBase<3>> register_conv_params<3>();
 
+#ifdef BUILD_JIT_QUANTIZATION_SAVE
+TORCH_API torch::class_<LinearPackedParamsBase> register_linear_params() {
+#else
 torch::class_<LinearPackedParamsBase> register_linear_params() {
+#endif
   using SerializationType = std::tuple<at::Tensor, c10::optional<at::Tensor>>;
   static auto register_linear_params =
       torch::class_<LinearPackedParamsBase>(
diff --git a/aten/src/ATen/native/quantized/cpu/fbgemm_utils.h b/aten/src/ATen/native/quantized/cpu/fbgemm_utils.h
index 8854f2dce0..4baf7a4fa7 100644
--- a/aten/src/ATen/native/quantized/cpu/fbgemm_utils.h
+++ b/aten/src/ATen/native/quantized/cpu/fbgemm_utils.h
@@ -20,7 +20,11 @@
 // of the A rows. The column offsets are needed for the asymmetric quantization
 // (affine quantization) of input matrix.
 // Note that in JIT mode we can think of a way to fuse col_offsets with bias.
+#ifdef BUILD_JIT_QUANTIZATION_SAVE
 struct TORCH_API PackedLinearWeight : public LinearPackedParamsBase {
+#else
+struct PackedLinearWeight : public LinearPackedParamsBase {
+#endif
   PackedLinearWeight(
       std::unique_ptr<fbgemm::PackBMatrix<int8_t>> w,
       c10::optional<at::Tensor> bias,
diff --git a/cmake/Summary.cmake b/cmake/Summary.cmake
index 6d021536c1..0d2bf09f2e 100644
--- a/cmake/Summary.cmake
+++ b/cmake/Summary.cmake
@@ -184,4 +184,5 @@ function(caffe2_print_configuration_summary)
   message(STATUS "  Private Dependencies : ${Caffe2_DEPENDENCY_LIBS}")
   # coreml
   message(STATUS "  USE_COREML_DELEGATE     : ${USE_COREML_DELEGATE}")
+  message(STATUS "  BUILD_JIT_QUANTIZATION_SAVE : ${BUILD_JIT_QUANTIZATION_SAVE}")
 endfunction()
diff --git a/torch/csrc/jit/serialization/pickler.cpp b/torch/csrc/jit/serialization/pickler.cpp
index f465eaf4df..43ef9fbd2f 100644
--- a/torch/csrc/jit/serialization/pickler.cpp
+++ b/torch/csrc/jit/serialization/pickler.cpp
@@ -667,7 +667,19 @@ WriteableTensorData getWriteableTensorData(
     // NB: This new tensor is created to support cuda tensors.
     // Storages can be mutated when converting tensors from cuda to cpu,
     // and we need a cpu tensor to copy data from.
-    result.tensor_ =
+    if(tensor.is_quantized()){
+      result.tensor_ =
+        at::empty_quantized({0}, tensor)
+            .set_(
+                tensor.storage(),
+                /* storage_offset = */ 0,
+                /* size = */
+                {static_cast<int64_t>(
+                    tensor.storage().nbytes() / tensor.element_size())},
+                /* stride = */ {1})
+            .cpu();
+    }else{
+      result.tensor_ =
         at::empty({0}, tensor.options())
             .set_(
                 tensor.storage(),
@@ -677,6 +689,7 @@ WriteableTensorData getWriteableTensorData(
                     tensor.storage().nbytes() / tensor.element_size())},
                 /* stride = */ {1})
             .cpu();
+    }
     TORCH_CHECK(
         result.tensor_.storage().nbytes() == result.size_,
         "Storage tensor size did not match record size");
diff --git a/torch/csrc/jit/serialization/unpickler.cpp b/torch/csrc/jit/serialization/unpickler.cpp
index e0e556ecbb..b59b7a200b 100644
--- a/torch/csrc/jit/serialization/unpickler.cpp
+++ b/torch/csrc/jit/serialization/unpickler.cpp
@@ -450,8 +450,7 @@ PickleOpCode Unpickler::readInstruction() {
 
       at::Tensor tensor;
       if (options.backend() == c10::Backend::QuantizedCPU) {
-        tensor = at::_empty_affine_quantized({}, options, 0, 0)
-                     .set_(storage, 0, {}, {});
+        tensor = at::_empty_affine_quantized({}, options, 0, 0).set_(storage);
       } else {
         tensor = at::empty({0}, options).set_(storage);
       }
-- 
2.25.1

