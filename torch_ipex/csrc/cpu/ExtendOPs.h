// Autogenerated file by gen-common-ops.py. Do not edit directly!
#pragma once

#include <ATen/Tensor.h>
#include <torch/extension.h>
#include "ideep/ideep.hpp"

namespace torch_ipex {

class AtenIpexTypeExt {
 public:
  static at::Tensor ROIAlign_forward(const at::Tensor& input,
                                     const at::Tensor& rois,
                                     const double spatial_scale,
                                     const int64_t pooled_height,
                                     const int64_t pooled_width,
                                     const int64_t sampling_ratio);

  static at::Tensor ROIAlign_backward(const at::Tensor& grad,
                                      const at::Tensor& rois,
                                      const double spatial_scale,
                                      const int64_t pooled_height,
                                      const int64_t pooled_width,
                                      const int64_t batch_size,
                                      const int64_t channels,
                                      const int64_t height,
                                      const int64_t width,
                                      const int64_t sampling_ratio);

  /// \brief Perform non-maximum suppression.
  ///
  /// \param dets: predicted loc in ltrb format for one batchsize, size [number_boxes, 4], for example: [200, 4].
  /// \param scores: predicted score for one batchsize and one class, size [number_boxes], for example: [200].
  /// \param threshold: IOU threshold(scalar) to suppress bboxs which has the IOU val larger than the threshold.
  /// \param sorted: The score and dets are already sorted in Descending order.
  ///
  /// \return result is a Tensor of dets' indexs to be keeped.
  static at::Tensor nms(const at::Tensor& dets,
                        const at::Tensor& scores,
                        const double threshold,
                        const bool sorted);

  /// \brief Perform batch non-maximum suppression.
  ///
  /// C++ version of Encoder::decode_single.
  /// Refer to https://github.com/mlcommons/inference/blob/v0.7/others/cloud/single_stage_detector/pytorch/utils.py.
  ///
  /// \param dets: predicted loc in ltrb format, size [BS, number_boxes, 4], for example: [1, 15130, 4].
  /// \param scores: predicted score, size [BS, number_boxes, class_number], for example: [1, 15130, 81].
  /// \param threshold: IOU threshold(scalar) to suppress bboxs which has the IOU val larger than the threshold.
  /// \param max_output: the max number of output bbox.
  ///
  /// \return result is a list of tuble. In each tuble, there are 3 tensors:
  ///   bboxes_out_: the selected out bboxes coordinate, size [max_output, 4].
  ///   labels_out_: the label of each selected out bboxes, size [max_output].
  ///   scores_out_: the score of each selected out bboxes, size [max_output].
  static std::vector<std::tuple<at::Tensor, at::Tensor, at::Tensor>> batch_score_nms(const at::Tensor& dets,
                        const at::Tensor& scores,
                        const double threshold,
                        const int64_t max_output);

  static at::Tensor interaction_forward(const std::vector<at::Tensor> & input);
  static std::vector<at::Tensor> interaction_backward(const at::Tensor & grad_out, 
                                                                     const std::vector<at::Tensor> & input);

  static at::Tensor embedding_bag(
      const at::Tensor &weight,
      const at::Tensor &indices,
      const at::Tensor &offsets,
      bool sparse,
      bool include_last_offset);

  static bool embedding_bag_fast_path_sum(
      const at::Tensor weight, 
      const c10::optional<at::Tensor> per_sample_weights, 
      int64_t mode, 
      const c10::optional<int64_t> padding_idx);

  /// \brief Do scale and transform from xywh to ltrb for predicted loc and do Softmax along the last dim for predicted score.
  ///
  /// C++ version of Encoder::scale_back_batch.
  /// Refer to https://github.com/mlcommons/inference/blob/v0.7/others/cloud/single_stage_detector/pytorch/utils.py.
  ///
  /// \param bboxes_in: predicted loc in xywh format, size [BS, number_boxes, 4], for example: [1, 15130, 4].
  /// \param scores_in: predicted score, size [BS, number_boxes, class_number], for example: [1, 15130, 81].
  /// \param dboxes_xywh: scale factor for each bbox from predicted loc to true loc, size [1, number_boxes, 4].
  /// \param scale_xy: scale factor(scalar) of xy dimention for bboxes_in.
  /// \param scale_wh: scale factor(scalar) of wh dimention for bboxes_in.
  ///
  /// \return tuple<bbox_result, bbox_result>,
  ///   bbox_result: True loc in lrtb format, size [BS, number_boxes, 4], for example: [1, 15130, 4].
  ///   scores_result: Normalized score, size [BS, number_boxes, class_number], for example: [1, 15130, 81].
  static std::tuple<at::Tensor, at::Tensor> parallel_scale_back_batch(const at::Tensor& bboxes_in,
                        const at::Tensor& scores_in,
                        const at::Tensor& dboxes_xywh,
                        const double scale_xy,
                        const double scale_wh);
  static std::tuple<at::Tensor, at::Tensor, at::Tensor> lstm(
      const at::Tensor& input, std::vector<at::Tensor> hx, std::vector<at::Tensor> params, bool has_biases,
      int64_t num_layers, double dropout_p, bool train, bool bidirectional, bool batch_first);
};

}  // namespace torch_ipex
