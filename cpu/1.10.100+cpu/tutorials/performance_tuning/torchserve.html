<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TorchServe with Intel® Extension for PyTorch* &mdash; intel_extension_for_pytorch 1.10.100+cpu documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Known Issues" href="known_issues.html" />
    <link rel="prev" title="Launch Script Usage Guide" href="launch_script.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> intel_extension_for_pytorch
          </a>
              <div class="version">
                <a href="/intel-extension-for-pytorch/versions.html">1.10.100+cpu ▼</a>
                <p>Click link above to switch version</p>
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc.html">API Documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../performance_tuning.html">Performance Tuning Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="launch_script.html">Launch Script Usage Guide</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">TorchServe with Intel® Extension for PyTorch*</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#contents-of-this-document">Contents of this Document</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-intel-extension-for-pytorch">Install Intel Extension for PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#serving-model-with-intel-extension-for-pytorch">Serving model with Intel Extension for PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="#creating-and-exporting-int8-model-for-ipex">Creating and Exporting INT8 model for IPEX</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#creating-a-serialized-file">1. Creating a serialized file</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#bert">BERT</a></li>
<li class="toctree-l5"><a class="reference internal" href="#resnet50">ResNet50</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#creating-a-model-archive">2. Creating a Model Archive</a></li>
<li class="toctree-l4"><a class="reference internal" href="#start-torchserve-to-serve-the-model">3. Start Torchserve to serve the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#registering-and-deploying-model">4. Registering and Deploying model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#benchmarking-with-launcher">Benchmarking with Launcher</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="known_issues.html">Known Issues</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../blogs_publications.html">Blogs &amp; Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribution.html">Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">intel_extension_for_pytorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../performance_tuning.html">Performance Tuning Guide</a> &raquo;</li>
      <li>TorchServe with Intel® Extension for PyTorch*</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/performance_tuning/torchserve.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="torchserve-with-intel-extension-for-pytorch">
<h1>TorchServe with Intel® Extension for PyTorch*<a class="headerlink" href="#torchserve-with-intel-extension-for-pytorch" title="Permalink to this headline"></a></h1>
<p>TorchServe can be used with Intel® Extension for PyTorch* (IPEX) to give performance boost on Intel hardware.
Here we show how to use TorchServe with IPEX.</p>
<section id="contents-of-this-document">
<h2>Contents of this Document<a class="headerlink" href="#contents-of-this-document" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#install-intel-extension-for-pytorch">Install Intel Extension for PyTorch</a></p></li>
<li><p><a class="reference external" href="#serving-model-with-intel-extension-for-pytorch">Serving model with Intel Extension for PyTorch</a></p></li>
<li><p><a class="reference external" href="#creating-and-exporting-int8-model-for-ipex">Creating and Exporting INT8 model for IPEX</a></p></li>
<li><p><a class="reference external" href="#benchmarking-with-launcher">Benchmarking with Launcher</a></p></li>
</ul>
</section>
<section id="install-intel-extension-for-pytorch">
<h2>Install Intel Extension for PyTorch<a class="headerlink" href="#install-intel-extension-for-pytorch" title="Permalink to this headline"></a></h2>
<p>Refer to the documentation <a class="reference external" href="https://github.com/intel/intel-extension-for-pytorch#installation">here</a>.</p>
</section>
<section id="serving-model-with-intel-extension-for-pytorch">
<h2>Serving model with Intel Extension for PyTorch<a class="headerlink" href="#serving-model-with-intel-extension-for-pytorch" title="Permalink to this headline"></a></h2>
<p>After installation, all it needs to be done to use TorchServe with IPEX is to enable it in <code class="docutils literal notranslate"><span class="pre">config.properties</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ipex_enable</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
<p>Once IPEX is enabled, deploying IPEX exported model follows the same procedure shown <a class="reference external" href="https://pytorch.org/serve/use_cases.html">here</a>. Torchserve with IPEX can deploy any model and do inference.</p>
</section>
<section id="creating-and-exporting-int8-model-for-ipex">
<h2>Creating and Exporting INT8 model for IPEX<a class="headerlink" href="#creating-and-exporting-int8-model-for-ipex" title="Permalink to this headline"></a></h2>
<p>Intel Extension for PyTorch supports both eager and torchscript mode. In this section, we show how to deploy INT8 model for IPEX.</p>
<section id="creating-a-serialized-file">
<h3>1. Creating a serialized file<a class="headerlink" href="#creating-a-serialized-file" title="Permalink to this headline"></a></h3>
<p>First create <code class="docutils literal notranslate"><span class="pre">.pt</span></code> serialized file using IPEX INT8 inference. Here we show two examples with BERT and ResNet50.</p>
<section id="bert">
<h4>BERT<a class="headerlink" href="#bert" title="Permalink to this headline"></a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>import intel_extension_for_pytorch as ipex
from transformers import AutoModelForSequenceClassification, AutoConfig
import transformers
from datasets import load_dataset
import torch

# load the model 
config = AutoConfig.from_pretrained(
    &quot;bert-base-uncased&quot;, return_dict=False, torchscript=True, num_labels=2)
model = AutoModelForSequenceClassification.from_pretrained(
    &quot;bert-base-uncased&quot;, config=config)
model = model.eval()

max_length = 384 
dummy_tensor = torch.ones((1, max_length), dtype=torch.long)
jit_inputs = (dummy_tensor, dummy_tensor, dummy_tensor)
conf = ipex.quantization.QuantConf(qscheme=torch.per_tensor_affine)


# calibration 
with torch.no_grad():
    for i in range(100):
        with ipex.quantization.calibrate(conf):
            model(dummy_tensor, dummy_tensor, dummy_tensor)

# optionally save the configuraiton for later use 
conf.save(‘model_conf.json’, default_recipe=True)

# conversion 
model = ipex.quantization.convert(model, conf, jit_inputs)

# save to .pt 
torch.jit.save(model, &#39;bert_int8_jit.pt&#39;)
</pre></div>
</div>
</section>
<section id="resnet50">
<h4>ResNet50<a class="headerlink" href="#resnet50" title="Permalink to this headline"></a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">intel_extension_for_pytorch</span> <span class="k">as</span> <span class="nn">ipex</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx.experimental.optimization</span> <span class="k">as</span> <span class="nn">optimization</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">dummy_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">(</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">channels_last</span><span class="p">)</span>
<span class="n">jit_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">dummy_tensor</span><span class="p">)</span>
<span class="n">conf</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">QuantConf</span><span class="p">(</span><span class="n">qscheme</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">per_tensor_symmetric</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
		<span class="k">with</span> <span class="n">ipex</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">calibrate</span><span class="p">(</span><span class="n">conf</span><span class="p">):</span>
			<span class="n">model</span><span class="p">(</span><span class="n">dummy_tensor</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">conf</span><span class="p">,</span> <span class="n">jit_inputs</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;rn50_int8_jit.pt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="creating-a-model-archive">
<h3>2. Creating a Model Archive<a class="headerlink" href="#creating-a-model-archive" title="Permalink to this headline"></a></h3>
<p>Once the serialized file ( <code class="docutils literal notranslate"><span class="pre">.pt</span></code>) is created, it can be used with <code class="docutils literal notranslate"><span class="pre">torch-model-archiver</span></code> as ususal. Use the following command to package the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">archiver</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">name</span> <span class="n">rn50_ipex_int8</span> <span class="o">--</span><span class="n">version</span> <span class="mf">1.0</span> <span class="o">--</span><span class="n">serialized</span><span class="o">-</span><span class="n">file</span> <span class="n">rn50_int8_jit</span><span class="o">.</span><span class="n">pt</span> <span class="o">--</span><span class="n">handler</span> <span class="n">image_classifier</span> 
</pre></div>
</div>
</section>
<section id="start-torchserve-to-serve-the-model">
<h3>3. Start Torchserve to serve the model<a class="headerlink" href="#start-torchserve-to-serve-the-model" title="Permalink to this headline"></a></h3>
<p>Make sure to set <code class="docutils literal notranslate"><span class="pre">ipex_enable</span> <span class="pre">=</span> <span class="pre">True</span></code> in <code class="docutils literal notranslate"><span class="pre">config.properties</span></code>. Use the following command to start Torchserve with IPEX.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchserve</span> <span class="o">--</span><span class="n">start</span> <span class="o">--</span><span class="n">ncs</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">store</span> <span class="n">model_store</span> <span class="o">--</span><span class="n">ts</span><span class="o">-</span><span class="n">config</span> <span class="n">config</span><span class="o">.</span><span class="n">properties</span>
</pre></div>
</div>
</section>
<section id="registering-and-deploying-model">
<h3>4. Registering and Deploying model<a class="headerlink" href="#registering-and-deploying-model" title="Permalink to this headline"></a></h3>
<p>Registering and deploying the model follows the same steps shown <a class="reference external" href="https://pytorch.org/serve/use_cases.html">here</a>.</p>
</section>
</section>
<section id="benchmarking-with-launcher">
<h2>Benchmarking with Launcher<a class="headerlink" href="#benchmarking-with-launcher" title="Permalink to this headline"></a></h2>
<p>In this section, we show how to use <code class="docutils literal notranslate"><span class="pre">intel_extension_for_pytorch.cpu.launch</span></code> launcher with Torchserve official benchmark to launch server and benchmark requests. Use the following command to run benchmark on a single socket with all physical cores on the socket.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">intel_extension_for_pytorch</span><span class="o">.</span><span class="n">cpu</span><span class="o">.</span><span class="n">launch</span> <span class="o">--</span><span class="n">socket_id</span> <span class="mi">0</span> <span class="o">--</span><span class="n">ninstance</span> <span class="mi">1</span> <span class="n">benchmark</span><span class="o">-</span><span class="n">ab</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p><img alt="benchmarking with launcher script" src="../../_images/benchmark.gif" /></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="launch_script.html" class="btn btn-neutral float-left" title="Launch Script Usage Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="known_issues.html" class="btn btn-neutral float-right" title="Known Issues" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Intel(R).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
