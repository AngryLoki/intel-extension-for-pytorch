<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Installation Guide &mdash; intel_extension_for_pytorch 1.13.120+xpu documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Examples" href="examples.html" />
    <link rel="prev" title="Releases" href="releases.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> intel_extension_for_pytorch
          </a>
              <div class="version">
                <a href="../../../">1.13.120+xpu ▼</a>
                <p>Click link above to switch version</p>
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="releases.html">Releases</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Installation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#system-requirements">System Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hardware-requirement">Hardware Requirement</a></li>
<li class="toctree-l3"><a class="reference internal" href="#software-requirements">Software Requirements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#preparations">Preparations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#install-intel-gpu-driver">Install Intel GPU Driver</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-oneapi-base-toolkit">Install oneAPI Base Toolkit</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pytorch-intel-extension-for-pytorch-version-mapping">PyTorch-Intel® Extension for PyTorch* Version Mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="#install-via-wheel-files">Install via wheel files</a></li>
<li class="toctree-l2"><a class="reference internal" href="#install-via-compiling-from-source">Install via compiling from source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configure-the-aot-optional">Configure the AOT (Optional)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#compile-the-bundle-pytorch-torchvision-torchaudio-intel-extension-for-pytorch-with-script">Compile the bundle (PyTorch*, torchvision, torchaudio, Intel® Extension for PyTorch*) with script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#solutions-to-potential-issues-on-wsl2">Solutions to potential issues on WSL2</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_doc.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance_tuning.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="technical_details.html">Technical Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="blogs_publications.html">Blogs &amp; Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="contribution.html">Contribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">intel_extension_for_pytorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Installation Guide</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/installation.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="installation-guide">
<h1>Installation Guide<a class="headerlink" href="#installation-guide" title="Permalink to this heading"></a></h1>
<section id="system-requirements">
<h2>System Requirements<a class="headerlink" href="#system-requirements" title="Permalink to this heading"></a></h2>
<section id="hardware-requirement">
<h3>Hardware Requirement<a class="headerlink" href="#hardware-requirement" title="Permalink to this heading"></a></h3>
<p>Verified Hardware Platforms:</p>
<ul class="simple">
<li><p>Intel® Data Center GPU Flex Series 170</p></li>
<li><p>Intel® Data Center GPU Max Series</p></li>
<li><p>Intel® Arc™ A-Series GPUs (Experimental support)</p></li>
</ul>
</section>
<section id="software-requirements">
<h3>Software Requirements<a class="headerlink" href="#software-requirements" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p>OS &amp; Intel GPU Drivers</p></li>
</ul>
<table border="1" class="docutils">
<thead>
<tr>
<th>Hardware</th>
<th>OS</th>
<th>Driver</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intel® Data Center GPU Flex Series</td>
<td>Ubuntu 22.04 (Validated), Red Hat 8.6</td>
<td><a href="https://dgpu-docs.intel.com/releases/stable_602_20230323.html">Stable 602</a></td>
</tr>
<tr>
<td>Intel® Data Center GPU Max Series</td>
<td>Ubuntu 22.04, Red Hat 8.6, Sles 15sp3/sp4 (Validated)</td>
<td><a href="https://dgpu-docs.intel.com/releases/stable_602_20230323.html">Stable 602</a></td>
</tr>
<tr>
<td>Intel® Arc™ A-Series Graphics</td>
<td>Ubuntu 22.04</td>
<td><a href="https://dgpu-docs.intel.com/releases/stable_602_20230323.html">Stable 602</a></td>
</tr>
<tr>
<td>Intel® Arc™ A-Series Graphics</td>
<td>Windows 11 or Windows 10 21H2 (via WSL2)</td>
<td><a href="https://www.intel.com/content/www/us/en/download/726609/intel-arc-iris-xe-graphics-whql-windows.html">for Windows 11 or Windows 10 21H2</a></td>
</tr>
<tr>
<td>CPU (3<sup>rd</sup> and 4<sup>th</sup> Gen of Intel® Xeon® Scalable Processors)</td>
<td>Linux* distributions with glibc&gt;=2.17. Validated on RHEL 8.</td>
<td>N/A</td>
</tr>
</tbody>
</table><ul class="simple">
<li><p>Intel® oneAPI Base Toolkit 2023.1</p></li>
<li><p><a class="reference external" href="https://registrationcenter-download.intel.com/akdlm/IRC_NAS/89283df8-c667-47b0-b7e1-c4573e37bd3e/2023.1-linux-hotfix.zip">DPC++ Compiler hotfix</a></p></li>
<li><p>Python 3.7-3.10</p></li>
<li><p>Verified with GNU GCC 11</p></li>
</ul>
</section>
</section>
<section id="preparations">
<h2>Preparations<a class="headerlink" href="#preparations" title="Permalink to this heading"></a></h2>
<section id="install-intel-gpu-driver">
<h3>Install Intel GPU Driver<a class="headerlink" href="#install-intel-gpu-driver" title="Permalink to this heading"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>OS</th>
<th>Instructions for installing Intel GPU Driver</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux*</td>
<td>Refer to the <a href="https://dgpu-docs.intel.com/installation-guides/index.html">Installation Guides</a> for the driver installation on individual Linux* distributions. When installing the verified driver mentioned in the table above, use the specific version of each component packages mentioned in the installation guide page, such as <code>sudo apt-get install intel-opencl-icd=&lt;version&gt;</code></td>
</tr>
<tr>
<td>Windows 11 or Windows 10 21H2 (via WSL2)</td>
<td>Please download drivers for Intel® Arc™ A-Series from the web page mentioned in the table above. Please note that you would have to follow the rest of the steps in WSL2, but the drivers should be installed on Windows. Besides that, please follow Steps 4 &amp; 5 of the <a href="https://dgpu-docs.intel.com/installation-guides/ubuntu/ubuntu-jammy-arc.html#step-4-install-run-time-packages">Installation Guides</a> on WSL2 Ubuntu 22.04.</td>
</tr>
</tbody>
</table></section>
<section id="install-oneapi-base-toolkit">
<h3>Install oneAPI Base Toolkit<a class="headerlink" href="#install-oneapi-base-toolkit" title="Permalink to this heading"></a></h3>
<p>Please refer to <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html">Install oneAPI Base Toolkit Packages</a>.</p>
<p>Need to install components of Intel® oneAPI Base Toolkit:</p>
<ul class="simple">
<li><p>Intel® oneAPI DPC++ Compiler (<code class="docutils literal notranslate"><span class="pre">DPCPPROOT</span></code> as its installation path)</p></li>
<li><p>Intel® oneAPI Math Kernel Library (oneMKL) (<code class="docutils literal notranslate"><span class="pre">MKLROOT</span></code> as its installation path)</p></li>
</ul>
<p>Default installation location <em>{ONEAPI_ROOT}</em> is <code class="docutils literal notranslate"><span class="pre">/opt/intel/oneapi</span></code> for root account, <code class="docutils literal notranslate"><span class="pre">${HOME}/intel/oneapi</span></code> for other accounts. Generally, <code class="docutils literal notranslate"><span class="pre">DPCPPROOT</span></code> is <code class="docutils literal notranslate"><span class="pre">{ONEAPI_ROOT}/compiler/latest</span></code>, <code class="docutils literal notranslate"><span class="pre">MKLROOT</span></code> is <code class="docutils literal notranslate"><span class="pre">{ONEAPI_ROOT}/mkl/latest</span></code>.</p>
<p>A DPC++ compiler patch is required to use with oneAPI Basekit 2023.1.0. Use the command below to download the patch package.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/89283df8-c667-47b0-b7e1-c4573e37bd3e/2023.1-linux-hotfix.zip
</pre></div>
</div>
<p>You can either follow instructions in the <code class="docutils literal notranslate"><span class="pre">README.txt</span></code> of the patch package, or use the commands below to install the patch.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>unzip <span class="m">2023</span>.1-linux-hotfix.zip
<span class="nb">cd</span> <span class="m">2023</span>.1-linux-hotfix
<span class="nb">source</span> <span class="o">{</span>ONEAPI_ROOT<span class="o">}</span>/setvars.sh
bash installpatch.sh
</pre></div>
</div>
<p>If later on you are not using the environment of the patch installation, you need to activate ONLY DPC++ compiler and oneMKL environment later on when no matter <strong><em>compiling</em></strong> or <strong><em>using</em></strong> Intel® Extension for PyTorch* on Intel GPUs.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span> <span class="o">{</span>DPCPPROOT<span class="o">}</span>/env/vars.sh
<span class="nb">source</span> <span class="o">{</span>MKLROOT<span class="o">}</span>/env/vars.sh
</pre></div>
</div>
</section>
</section>
<section id="pytorch-intel-extension-for-pytorch-version-mapping">
<h2>PyTorch-Intel® Extension for PyTorch* Version Mapping<a class="headerlink" href="#pytorch-intel-extension-for-pytorch-version-mapping" title="Permalink to this heading"></a></h2>
<p>Intel® Extension for PyTorch* has to work with a corresponding version of PyTorch. Here are the PyTorch versions that we support and the mapping relationship:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>PyTorch Version</th>
<th>Extension Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/pytorch/pytorch/tree/v1.13.1">v1.13.*</a> (patches needed)</td>
<td><a href="https://github.com/intel/intel-extension-for-pytorch/tree/v1.13.120+xpu">v1.13.*</a></td>
</tr>
<tr>
<td><a href="https://github.com/pytorch/pytorch/tree/v1.10.0">v1.10.*</a> (patches needed)</td>
<td><a href="https://github.com/intel/intel-extension-for-pytorch/tree/v1.10.200+gpu">v1.10.*</a></td>
</tr>
</tbody>
</table></section>
<section id="install-via-wheel-files">
<h2>Install via wheel files<a class="headerlink" href="#install-via-wheel-files" title="Permalink to this heading"></a></h2>
<p>Prebuilt wheel files availability matrix for Python versions:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th style="text-align: center;">Extension Version</th>
<th style="text-align: center;">Python 3.6</th>
<th style="text-align: center;">Python 3.7</th>
<th style="text-align: center;">Python 3.8</th>
<th style="text-align: center;">Python 3.9</th>
<th style="text-align: center;">Python 3.10</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1.13.120+xpu</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
</tr>
<tr>
<td style="text-align: center;">1.13.10+xpu</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
</tr>
<tr>
<td style="text-align: center;">1.10.200+gpu</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;">✔️</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table><hr class="docutils" />
<p>Prebuilt wheel files for generic Python* and Intel® Distribution for Python* are released in separate repositories.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># General Python*</span>
python -m pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.13.0a0+git6c9b55e <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.14.1a0 <span class="nv">intel_extension_for_pytorch</span><span class="o">==</span><span class="m">1</span>.13.120+xpu -f https://developer.intel.com/ipex-whl-stable-xpu

<span class="c1"># Intel® Distribution for Python*</span>
python -m pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.13.0a0+git6c9b55e <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.14.1a0 <span class="nv">intel_extension_for_pytorch</span><span class="o">==</span><span class="m">1</span>.13.120+xpu -f https://developer.intel.com/ipex-whl-stable-xpu-idp
</pre></div>
</div>
<p><strong>Note:</strong> Wheel files for Intel® Distribution for Python* only supports Python 3.9. The support starts from 1.13.10+xpu.</p>
<p><strong>Note:</strong> Installation of TorchVision is optional.</p>
<p><strong>Note:</strong> You may need to have gomp package in your system (<code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">libgomp1</span></code> or <code class="docutils literal notranslate"><span class="pre">yum/dnf</span> <span class="pre">install</span> <span class="pre">libgomp</span></code>).</p>
<p><strong>Note:</strong> Since DPC++ compiler doesn’t support old <a class="reference external" href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html">C++ ABI</a> (<code class="docutils literal notranslate"><span class="pre">_GLIBCXX_USE_CXX11_ABI=0</span></code>), ecosystem packages, including PyTorch and TorchVision, need to be compiled with the new C++ ABI (<code class="docutils literal notranslate"><span class="pre">_GLIBCXX_USE_CXX11_ABI=1</span></code>).</p>
<p><strong>Note:</strong> If you need TorchAudio, please follow the <a class="reference external" href="https://github.com/pytorch/audio/tree/v0.13.0#from-source">instructions</a> to compile it from source. According to torchaudio-pytorch dependency table, torchaudio 0.13.0 is recommended.</p>
</section>
<section id="install-via-compiling-from-source">
<h2>Install via compiling from source<a class="headerlink" href="#install-via-compiling-from-source" title="Permalink to this heading"></a></h2>
<section id="configure-the-aot-optional">
<h3>Configure the AOT (Optional)<a class="headerlink" href="#configure-the-aot-optional" title="Permalink to this heading"></a></h3>
<p>Please refer to <a class="reference internal" href="AOT.html"><span class="doc">AOT documentation</span></a> for how to configure <code class="docutils literal notranslate"><span class="pre">USE_AOT_DEVLIST</span></code>. Without configuring AOT, the start-up time for processes using Intel® Extension for PyTorch* will be long, so this step is important.</p>
</section>
<section id="compile-the-bundle-pytorch-torchvision-torchaudio-intel-extension-for-pytorch-with-script">
<h3>Compile the bundle (PyTorch*, torchvision, torchaudio, Intel® Extension for PyTorch*) with script<a class="headerlink" href="#compile-the-bundle-pytorch-torchvision-torchaudio-intel-extension-for-pytorch-with-script" title="Permalink to this heading"></a></h3>
<p>To ensure a smooth compilation of the bundle, including PyTorch*, torchvision, torchaudio, Intel® Extension for PyTorch*, a script is provided in the Github repo. If you would like to compile the binaries from source, it is highly recommended to utilize this script.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ wget https://github.com/intel/intel-extension-for-pytorch/raw/release/xpu/1.13.120/scripts/compile_bundle.sh
$ bash compile_bundle.sh &lt;DPCPPROOT&gt; &lt;MKLROOT&gt; <span class="o">[</span>AOT<span class="o">]</span>
  DPCPPROOT and MKLROOT are mandatory, should be absolute or relative path to the root directory of DPC++ compiler and oneMKL respectively.
  AOT is optional, should be the text string <span class="k">for</span> environment variable USE_AOT_DEVLIST.
</pre></div>
</div>
<p><strong>Note:</strong> Recommend to use the <code class="docutils literal notranslate"><span class="pre">compile_bundle.sh</span></code> script in a clean docker container.</p>
<p><strong>Note:</strong> Use the <code class="docutils literal notranslate"><span class="pre">compile_bundle.sh</span></code> script under a <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment.</p>
<p><strong>Note:</strong> Depends on what applications are available on your OS, you probably need to install some Linux commands, like <code class="docutils literal notranslate"><span class="pre">patch</span></code>, <code class="docutils literal notranslate"><span class="pre">git</span></code>, etc. Installation of these Linux commands are not included in this script.</p>
<p><strong>Note:</strong> The <code class="docutils literal notranslate"><span class="pre">compile_bundle.sh</span></code> script downloads source code of PyTorch*, torchvision, torchaudio, Intel® Extension for PyTorch* into individual folders in its directory. You can consider to create a specific folder to use this script. Wheel files will be generated under <code class="docutils literal notranslate"><span class="pre">dist</span></code> folder of each source code directory. Besides, compilation progress is dumped into a log file <code class="docutils literal notranslate"><span class="pre">build.log</span></code> in each source code directory. The log file is helpful to identify errors occurred during compilation. Should any failure happened, after addressing the issue, you can simply run the <code class="docutils literal notranslate"><span class="pre">compile_bundle.sh</span></code> script again with the same command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ mkdir ipex_bundle
$ <span class="nb">cd</span> ipex_bundle
$ wget .../compile_bundle.sh
$ bash compile_bundle.sh ...
$ ls
audio  compile_bundle.sh  intel_extension_for_pytorch  torch  vision
$ tree -L <span class="m">3</span> .
.
├── audio
│   ├── dist
│   │   └── torchaudio-....whl
│   ├ build.log
│   └ ...
├── compile_bundle.sh
├── intel_extension_for_pytorch
│   ├── dist
│   │   └── intel_extension_for_pytorch-....whl
│   ├ build.log
│   └ ...
├── torch
│   ├── dist
│   │   └── torch-....whl
│   ├ build.log
│   └ ...
└── vision
    ├── dist
    │   └── torchvision-....whl
    ├ build.log
    └ ...
</pre></div>
</div>
</section>
</section>
<section id="solutions-to-potential-issues-on-wsl2">
<h2>Solutions to potential issues on WSL2<a class="headerlink" href="#solutions-to-potential-issues-on-wsl2" title="Permalink to this heading"></a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Issue</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Building from source for Intel® Arc™ A-Series GPUs failed on WSL2 without any error thrown</td>
<td>Your system probably does not have enough RAM, so Linux kernel's Out-of-memory killer got invoked. You can verify it by running <code>dmesg</code> on bash (WSL2 terminal). If the OOM killer had indeed killed the build process, then you can try increasing the swap-size of WSL2, and/or decreasing the number of parallel build jobs with the environment variable <code>MAX_JOBS</code> (by default, it's equal to the number of logical CPU cores. So, setting <code>MAX_JOBS</code> to 1 is a very conservative approach, which would slow things down a lot).</td>
</tr>
<tr>
<td>On WSL2, some workloads terminate with an error <code>CL_DEVICE_NOT_FOUND</code> after some time</td>
<td>This is due to the <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/display/tdr-registry-keys#tdrdelay">TDR feature</a> in Windows. You can try increasing TDRDelay in your Windows Registry to a large value, such as 20 (it is 2 seconds, by default), and reboot.</td>
</tr>
</tbody>
</table></section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="releases.html" class="btn btn-neutral float-left" title="Releases" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="examples.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Intel(R).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
