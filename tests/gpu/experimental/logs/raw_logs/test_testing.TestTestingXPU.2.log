test__comparescalars_debug_msg_xpu (__main__.TestTestingXPU) ... FAIL
test__comparetensors_debug_msg_xpu (__main__.TestTestingXPU) ... ok
test__comparetensors_legacy_xpu (__main__.TestTestingXPU) ... FAIL
test_assertEqual_numpy_xpu_bool (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_complex128 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_assertEqual_numpy_xpu_complex64 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_assertEqual_numpy_xpu_float16 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_float32 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_float64 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_int16 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_int32 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_int64 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_int8 (__main__.TestTestingXPU) ... ok
test_assertEqual_numpy_xpu_uint8 (__main__.TestTestingXPU) ... ok
test_assert_messages_xpu (__main__.TestTestingXPU) ... ok
test_get_supported_dtypes_xpu (__main__.TestTestingXPU) ... FAIL
test_isclose_atol_rtol_greater_than_zero_xpu_bool (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_float16 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_float32 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_float64 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_int16 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_int32 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_int64 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_int8 (__main__.TestTestingXPU) ... ok
test_isclose_atol_rtol_greater_than_zero_xpu_uint8 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_bool_xpu (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_complex_xpu_complex128 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_isclose_comparetensors_complex_xpu_complex64 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_isclose_comparetensors_float_xpu_float16 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_float_xpu_float32 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_float_xpu_float64 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_integer_xpu_int16 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_integer_xpu_int32 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_integer_xpu_int64 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_integer_xpu_int8 (__main__.TestTestingXPU) ... ok
test_isclose_comparetensors_integer_xpu_uint8 (__main__.TestTestingXPU) ... ok
test_isclose_equality_shortcut_xpu (__main__.TestTestingXPU) ... ok
test_isclose_nan_equality_shortcut_xpu_complex128 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_isclose_nan_equality_shortcut_xpu_complex64 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_isclose_nan_equality_shortcut_xpu_float16 (__main__.TestTestingXPU) ... ok
test_isclose_nan_equality_shortcut_xpu_float32 (__main__.TestTestingXPU) ... ok
test_isclose_nan_equality_shortcut_xpu_float64 (__main__.TestTestingXPU) ... ok
test_make_tensor_xpu_bool (__main__.TestTestingXPU) ... ok
test_make_tensor_xpu_complex64 (__main__.TestTestingXPU) ... skipped 'dtype not support on XPU'
test_make_tensor_xpu_float32 (__main__.TestTestingXPU) ... ok
test_make_tensor_xpu_int64 (__main__.TestTestingXPU) ... ok
test_xpu_assert_should_not_stop_common_distributed_test_suite_xpu (__main__.TestTestingXPU) ... ok
test_xpu_assert_should_stop_common_device_type_test_suite_xpu (__main__.TestTestingXPU) ... FAIL
test_xpu_assert_should_stop_common_utils_test_suite_xpu (__main__.TestTestingXPU) ... FAIL

======================================================================
FAIL: test__comparescalars_debug_msg_xpu (__main__.TestTestingXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_testing.py", line 93, in test__comparescalars_debug_msg
    self.assertEqual(debug_msg, expected_msg)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1916, in assertEqual
    super().assertEqual(x, y, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: 'Comp[74 chars]th rtol=1.3e-06 and atol=0.001 is only 0.0010091!' != 'Comp[74 chars]th rtol=1.3e-06 and atol=1e-05 is only 1.9100000000000003e-05!'
- Comparing 4.0 and 7.0 gives a difference of 3.0, but the allowed difference with rtol=1.3e-06 and atol=0.001 is only 0.0010091!
?                                                                                                         ^^^^         ^ ^^   ^^
+ Comparing 4.0 and 7.0 gives a difference of 3.0, but the allowed difference with rtol=1.3e-06 and atol=1e-05 is only 1.9100000000000003e-05!
?                                                                                                        +++ ^         ^ ^   ^^^^^^^^^^^^^^^^
 : Attempted to compare [string] types: Expected: 'Comparing 4.0 and 7.0 gives a difference of 3.0, but the allowed difference with rtol=1.3e-06 and atol=0.001 is only 0.0010091!'; Actual: 'Comparing 4.0 and 7.0 gives a difference of 3.0, but the allowed difference with rtol=1.3e-06 and atol=1e-05 is only 1.9100000000000003e-05!'.

======================================================================
FAIL: test__comparetensors_legacy_xpu (__main__.TestTestingXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_testing.py", line 84, in test__comparetensors_legacy
    self.assertFalse(result)
AssertionError: True is not false

======================================================================
FAIL: test_get_supported_dtypes_xpu (__main__.TestTestingXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_testing.py", line 594, in test_get_supported_dtypes
    dynamic_dtypes = opinfo_helper.get_supported_dtypes(op.op, op.sample_inputs_func, self.device_type)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo_helper.py", line 53, in get_supported_dtypes
    assert device_type in ['cpu', 'cuda']
AssertionError

======================================================================
FAIL: test_xpu_assert_should_stop_common_device_type_test_suite_xpu (__main__.TestTestingXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 980, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_testing.py", line 543, in test_xpu_assert_should_stop_common_device_type_test_suite
    self.assertIn('XPU error: device-side assert triggered', stderr)
AssertionError: 'XPU error: device-side assert triggered' not found in 'PYTORCH_API_USAGE torch.python.import\nPYTORCH_API_USAGE c10d.python.import\nPYTORCH_API_USAGE tensor.create\n..\n----------------------------------------------------------------------\nRan 2 tests in 0.393s\n\nOK\n'

======================================================================
FAIL: test_xpu_assert_should_stop_common_utils_test_suite_xpu (__main__.TestTestingXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 980, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_testing.py", line 503, in test_xpu_assert_should_stop_common_utils_test_suite
    self.assertIn('XPU error: device-side assert triggered', stderr)
AssertionError: 'XPU error: device-side assert triggered' not found in 'PYTORCH_API_USAGE torch.python.import\nPYTORCH_API_USAGE c10d.python.import\nEPYTORCH_API_USAGE tensor.create\nE\n======================================================================\nERROR: test_throw_unrecoverable_xpu_exception (__main__.TestThatContainsXPUAssertFailure)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 980, in wrapper\n    fn(*args, **kwargs)\n  File "<string>", line 10, in test_throw_unrecoverable_xpu_exception\nNotImplementedError: Could not run \'aten::empty.memory_format\' with arguments from the \'XPU\' backend. This could be because the operator doesn\'t exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. \'aten::empty.memory_format\' is only available for these backends: [CPU, Meta, MkldnnCPU, SparseCPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterMkldnnCPU.cpp:595 [kernel]\nSparseCPU: registered at aten/src/ATen/RegisterSparseCPU.cpp:958 [kernel]\nBackendSelect: registered at aten/src/ATen/RegisterBackendSelect.cpp:665 [kernel]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at ../aten/src/ATen/ConjugateFallback.cpp:22 [kernel]\nNegative: fallthrough registered at ../aten/src/ATen/native/NegateFallback.cpp:22 [kernel]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n\n\n======================================================================\nERROR: test_trivial_passing_test_case_on_cpu_xpu (__main__.TestThatContainsXPUAssertFailure)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 980, in wrapper\n    fn(*args, **kwargs)\n  File "<string>", line 16, in test_trivial_passing_test_case_on_cpu_xpu\nRuntimeError: PyTorch is not linked with support for xpu devices\n\n----------------------------------------------------------------------\nRan 2 tests in 0.015s\n\nFAILED (errors=2)\n'

----------------------------------------------------------------------
Ran 49 tests in 15.281s

FAILED (failures=5, skipped=7)
Raised CalledProcessError: return code 1.