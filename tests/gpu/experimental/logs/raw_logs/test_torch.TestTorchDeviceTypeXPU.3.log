test_addcdiv_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_addcdiv_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_addcdiv_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcdiv_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_addcmul_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_addcmul_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_addcmul_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_edge_cases_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_edge_cases_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_edge_cases_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_p_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_p_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_p_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bernoulli_self_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_bool_tensor_value_change_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_broadcast_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_cauchy_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_cauchy_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_cauchy_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_cauchy_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_cauchy_no_inf_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_cauchy_no_inf_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_large_batch_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_cdist_large_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_non_contiguous_batch_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_non_contiguous_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_norm_batch_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_norm_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cdist_xpu_backward_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_clone_all_dtypes_and_devices_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_clone_not_memory_dense_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_clone_zero_stride_dim_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_complex_unsupported_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_complex_unsupported_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_constants_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_transposed_backward_agnostic_to_memory_format_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_conv_transposed_large_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_copy_all_dtypes_and_devices_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_copy_mem_overlap_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_corrcoef_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_corrcoef_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:4455: UserWarning: cov(): degrees of freedom is <= 0 (Triggered internally at  ../aten/src/ATen/native/Correlation.cpp:99.)
  res = torch.corrcoef(x)
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/numpy/lib/function_base.py:495: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis)
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide
  ret = um.true_divide(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/numpy/lib/function_base.py:2821: RuntimeWarning: Degrees of freedom <= 0 for slice
  c = cov(x, y, rowvar, dtype=dtype)
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: divide by zero encountered in true_divide
  c *= np.true_divide(1, fact)
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: invalid value encountered in multiply
  c *= np.true_divide(1, fact)
ok
test_corrcoef_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_cov_error_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cov_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_cov_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:4462: UserWarning: cov(): degrees of freedom is <= 0 (Triggered internally at  ../aten/src/ATen/native/Correlation.cpp:99.)
  res = torch.cov(t, correction=correction, fweights=fweights, aweights=aweights)
/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:4466: RuntimeWarning: Degrees of freedom <= 0 for slice
  ref = np.cov(t, ddof=correction, fweights=fweights, aweights=aweights)
ok
test_cov_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_cpp_warnings_have_python_context_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cublas_config_nondeterministic_alert_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_cummax_cummin_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_cummax_helper' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_cummax_helper' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_cummax_discontiguous_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_cummax_helper' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_cummax_helper' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_cummin_discontiguous_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_cummin_helper' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_cummin_helper' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_cumprod_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_cumsum_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_deepcopy_scalar_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_deepcopy_scalar_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_deepcopy_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_deepcopy_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_device_guard_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::to_sparse' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::to_sparse' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:10257 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_diff_noncontig_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_noncontig_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_noncontig_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_diff_noncontig_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_diff_noncontig_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_noncontig_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_noncontig_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_noncontig_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_noncontig_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_noncontig_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_noncontig_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_noncontig_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_diff_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_diff_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_diff_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_diff_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_dim_function_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_logcumsumexp' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_logcumsumexp' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_discontiguous_out_cumsum_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_dist_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_dlpack_capsule_conversion_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_capsule_conversion_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_diff_streams_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_conversion_with_streams_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_error_on_bool_tensor_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_export_is_conj_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_export_non_strided_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_export_requires_grad_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_protocol_conversion_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_shared_storage_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_dlpack_tensor_invalid_stream_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_embedding_scalar_weight_error_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_error_gradient_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_error_gradient_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_error_gradient_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_errors_index_copy_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_exponential_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_no_zero_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_no_zero_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_exponential_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_exponential_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_gather_backward_deterministic_path_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_gather_backward_one_dim_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_gather_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_kstest_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_kstest_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_geometric_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_geometric_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_gradient_all_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_gradient_all_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::nan_to_num.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::nan_to_num.out' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_gradient_all_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::nan_to_num.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::nan_to_num.out' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_gradient_extreme_cases_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_gradient_extreme_cases_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_gradient_extreme_cases_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_gradient_type_promotion_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::nan_to_num.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::nan_to_num.out' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_half_tensor_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_hook_remove_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_add_deterministic_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_index_add_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_deterministic_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_index_copy_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_index_copy_scalars_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_copy_scalars_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_copy_scalars_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_scalars_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_copy_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_copy_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_copy_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_index_fill_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_fill_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_fill_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_fill_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_put_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_index_put_non_accumulate_deterministic_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'not ready on XPU'
test_index_select_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_index_select_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_select_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_index_select_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_index_select_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_is_set_to_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_is_signed_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_large_cumprod_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_large_cumsum_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_log_normal_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_log_normal_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_log_normal_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_log_normal_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_logcumsumexp_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_logcumsumexp' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_logcumsumexp' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_lognormal_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_lognormal_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_lognormal_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_lognormal_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_bool_tensor_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_masked_fill_xpu_bfloat16_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_bfloat16_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_bool_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_bool_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_complex128_bool (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_fill_xpu_complex128_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_fill_xpu_complex64_bool (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_fill_xpu_complex64_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_fill_xpu_float16_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_float16_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_float32_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_float32_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_float64_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_float64_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int16_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int16_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int32_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int32_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int64_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int64_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int8_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_int8_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_uint8_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_fill_xpu_uint8_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_bool_tensor_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_large_tensor_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'Insufficient xpu:0 memory'
test_masked_scatter_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_masked_scatter_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_scatter_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_scatter_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_scatter_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_select_discontiguous_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_masked_select_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_masked_select_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_select_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_masked_select_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_masked_select_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... /home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py:6009: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a mask with dtype torch.bool instead. (Triggered internally at  /home/gta/xunsongh/ipex-gpu/csrc/aten/operators/Indexing.cpp:1293.)
  torch.masked_select(src, mask, out=dst3)
ok
test_memory_format_clone_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_consistency_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_cpu_and_xpu_ops_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_empty_like_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::to_sparse' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::to_sparse' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_0.cpp:8878 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_0.cpp:10257 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_memory_format_factory_like_functions_preserve_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_operators_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::hypot.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::hypot.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_memory_format_preserved_after_permute_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_propagation_rules_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_to_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_type_shortcuts_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_memory_format_type_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_constraints_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_deterministic_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_multinomial_deterministic_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_multinomial_deterministic_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_multinomial_device_constrain_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_empty_w_replacement_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_multinomial_empty_wo_replacement_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_multinomial_gpu_device_constrain_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_invalid_distribution_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_invalid_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_rng_state_advance_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_multinomial_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_narrow_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_nondeterministic_alert_AdaptiveAvgPool2d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_AdaptiveAvgPool3d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_AdaptiveMaxPool2d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_AvgPool3d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_CTCLoss_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_EmbeddingBag_max_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'XPU EmbeddingBag backward in max mode is implemented deterministically, so this case is skipped'
test_nondeterministic_alert_FractionalMaxPool2d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_FractionalMaxPool3d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_MaxPool3d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_NLLLoss_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_ReflectionPad1d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_ReflectionPad2d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_ReflectionPad3d_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::reflection_pad3d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::reflection_pad3d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_nondeterministic_alert_ReplicationPad1d_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::replication_pad1d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::replication_pad1d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:2505 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_nondeterministic_alert_ReplicationPad2d_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_ReplicationPad3d_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::replication_pad3d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::replication_pad3d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:2505 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_nondeterministic_alert_bincount_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_gather_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_nondeterministic_alert_grid_sample_2d_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_nondeterministic_alert_grid_sample_3d_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_nondeterministic_alert_histc_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_interpolate_bicubic_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_interpolate_bilinear_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_interpolate_linear_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_interpolate_trilinear_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_kthvalue_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_median_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_put_accumulate_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_put_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_nondeterministic_alert_scatter_add_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_normal_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_normal_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_normal_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_normal_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_nullary_op_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_pairwise_distance_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_pdist_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_pdist_norm_backward_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::count_nonzero.dim_IntList' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::count_nonzero.dim_IntList' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:10491 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:11425 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_pdist_norm_forward_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_pdist_norm_large_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_pickle_gradscaler_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_pin_memory_from_constructor_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_put_accumulate_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_put_accumulate_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_put_accumulate_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_accumulate_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_put_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_put_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_put_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_put_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_repeat_interleave_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_scalar_check_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_scatter_add_bool_xpu (__main__.TestTorchDeviceTypeXPU) ... ERROR
test_scatter_add_non_unique_index_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_add_one_dim_deterministic_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_add_to_large_input_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_bool_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_multiply_unsupported_dtypes_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_multiply_unsupported_dtypes_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_multiply_unsupported_dtypes_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_multiply_unsupported_dtypes_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_multiply_unsupported_dtypes_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_multiply_unsupported_dtypes_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_multiply_unsupported_dtypes_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_non_unique_index_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_non_unique_index_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_non_unique_index_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_non_unique_index_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_non_unique_index_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_non_unique_index_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_non_unique_index_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_non_unique_index_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_non_unique_index_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_non_unique_index_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_non_unique_index_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_non_unique_index_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_operations_to_large_input_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_operations_to_large_input_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_operations_to_large_input_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_operations_to_large_input_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_operations_to_large_input_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_operations_to_large_input_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_operations_to_large_input_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.value_reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.value_reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_scalar_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_scalar_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_scatter_reduce_scalar_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.value_reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.value_reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_scalar_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.value_reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.value_reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_scalar_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::scatter.value_reduce_out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::scatter.value_reduce_out' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_scatter_reduce_scalar_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_reduce_scalar_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_scatter_to_large_input_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_serialization_xpu (__main__.TestTorchDeviceTypeXPU) ... FAIL
test_shift_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped "not_implemented: Could not run 'aten::__ilshift__.Tensor' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::__ilshift__.Tensor' is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]\nMeta: registered at aten/src/ATen/RegisterMeta.cpp:12703 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_3.cpp:10141 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_3.cpp:11560 [kernel]\nUNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]\nAutocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
test_storage_device_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_storage_multigpu_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_storage_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_storage_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_strides_propagation_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_sync_warning_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'XPUSyncGuard not ready yet'
test_take_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_bool (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_take_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_take_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_take_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_tensor_set_errors_multigpu_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_tensor_shape_empty_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_ternary_op_mem_overlap_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_unfold_all_devices_and_dtypes_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_unfold_scalars_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_uniform_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_uniform_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_uniform_kstest_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_uniform_kstest_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_warn_always_caught_xpu (__main__.TestTorchDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_where_scalar_invalid_combination_raises_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_where_scalar_invalid_combination_raises_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_where_scalar_invalid_combination_raises_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_invalid_combination_raises_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_scalar_xpu (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_complex128 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_where_scalar_valid_combination_xpu_complex64 (__main__.TestTorchDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_where_scalar_valid_combination_xpu_float16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_float32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_float64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_int16 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_int32 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_int64 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_int8 (__main__.TestTorchDeviceTypeXPU) ... ok
test_where_scalar_valid_combination_xpu_uint8 (__main__.TestTorchDeviceTypeXPU) ... ok

======================================================================
ERROR: test_broadcast_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3653, in test_broadcast
    r2 = tensorfn_inplace(large_expanded_clone, small, small2)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3648, in tensorfn_inplace
    return t0_fn(t1)
RuntimeError: invalid src/dst dimension in oneDNN reorder ...

======================================================================
ERROR: test_cdist_large_batch_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 980, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 115, in wrapped
    with_tf32_disabled(kwargs['self'], lambda: f(**kwargs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 95, in with_tf32_disabled
    function_call()
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 115, in <lambda>
    with_tf32_disabled(kwargs['self'], lambda: f(**kwargs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4698, in test_cdist_large_batch
    actual = torch.cdist(x, y, p=2, compute_mode=cm)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/functional.py", line 1157, in cdist
    return _VF.cdist(x1, x2, p, 2)  # type: ignore[attr-defined]
RuntimeError: Provided range is out of integer limits. Pass `-fno-sycl-id-queries-fit-in-int' to disable range check. -30 (CL_INVALID_VALUE)

======================================================================
ERROR: test_copy_all_dtypes_and_devices_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5334, in test_copy_all_dtypes_and_devices
    y = copy(x)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/copy.py", line 92, in copy
    rv = reductor(4)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 133, in __reduce_ex__
    return self._reduce_ex_internal(proto)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 218, in _reduce_ex_internal
    args = (self.storage(),
RuntimeError: unsupported Storage type

======================================================================
ERROR: test_geometric_kstest_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4572, in test_geometric_kstest
    res = stats.chisquare(actual, expected)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/scipy/stats/_stats_py.py", line 6911, in chisquare
    return power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/scipy/stats/_stats_py.py", line 6753, in power_divergence
    raise ValueError(msg)
ValueError: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:
0.0010010006823958574

======================================================================
ERROR: test_geometric_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4572, in test_geometric_kstest
    res = stats.chisquare(actual, expected)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/scipy/stats/_stats_py.py", line 6911, in chisquare
    return power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/scipy/stats/_stats_py.py", line 6753, in power_divergence
    raise ValueError(msg)
ValueError: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:
0.0010010006823958574

======================================================================
ERROR: test_geometric_kstest_xpu_int16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4569, in test_geometric_kstest
    t = torch.empty(size, dtype=dtype, device=device).geometric_(p=p)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Short'

======================================================================
ERROR: test_geometric_kstest_xpu_int32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4569, in test_geometric_kstest
    t = torch.empty(size, dtype=dtype, device=device).geometric_(p=p)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Int'

======================================================================
ERROR: test_geometric_kstest_xpu_int64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4569, in test_geometric_kstest
    t = torch.empty(size, dtype=dtype, device=device).geometric_(p=p)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Long'

======================================================================
ERROR: test_geometric_kstest_xpu_int8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4569, in test_geometric_kstest
    t = torch.empty(size, dtype=dtype, device=device).geometric_(p=p)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Char'

======================================================================
ERROR: test_geometric_kstest_xpu_uint8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4569, in test_geometric_kstest
    t = torch.empty(size, dtype=dtype, device=device).geometric_(p=p)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Byte'

======================================================================
ERROR: test_geometric_xpu_int16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4319, in test_geometric
    a = torch.tensor([10], dtype=dtype, device=device).geometric_(0.5)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Short'

======================================================================
ERROR: test_geometric_xpu_int32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4319, in test_geometric
    a = torch.tensor([10], dtype=dtype, device=device).geometric_(0.5)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Int'

======================================================================
ERROR: test_geometric_xpu_int64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4319, in test_geometric
    a = torch.tensor([10], dtype=dtype, device=device).geometric_(0.5)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Long'

======================================================================
ERROR: test_geometric_xpu_int8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4319, in test_geometric
    a = torch.tensor([10], dtype=dtype, device=device).geometric_(0.5)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Char'

======================================================================
ERROR: test_geometric_xpu_uint8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4319, in test_geometric
    a = torch.tensor([10], dtype=dtype, device=device).geometric_(0.5)
RuntimeError: "geometric_scalar_dpcpp" not implemented for 'Byte'

======================================================================
ERROR: test_index_select_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_bool (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_float32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_float64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_int16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_int32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_int64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_int8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_index_select_xpu_uint8 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5596, in test_index_select
    out = torch.index_select(src, dim, idx)
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_masked_fill_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6567, in test_masked_fill_mem_overlap
    x.masked_fill_(mask, 0.)
RuntimeError: not implemented THDPCPPTensor_copyIgnoringOverlaps


======================================================================
ERROR: test_multinomial_deterministic_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7356, in test_multinomial_deterministic
    gen = torch.Generator(device=device)
RuntimeError: Device type XPU is not supported for torch.Generator() api.

======================================================================
ERROR: test_multinomial_deterministic_xpu_float32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7356, in test_multinomial_deterministic
    gen = torch.Generator(device=device)
RuntimeError: Device type XPU is not supported for torch.Generator() api.

======================================================================
ERROR: test_multinomial_deterministic_xpu_float64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7356, in test_multinomial_deterministic
    gen = torch.Generator(device=device)
RuntimeError: Device type XPU is not supported for torch.Generator() api.

======================================================================
ERROR: test_multinomial_empty_w_replacement_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7746, in test_multinomial_empty_w_replacement
    self._test_multinomial_empty(device, True, 1)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7742, in _test_multinomial_empty
    out = torch.multinomial(probs, num_samples=num_samples, replacement=replacement)
RuntimeError: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous

======================================================================
ERROR: test_multinomial_empty_wo_replacement_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7750, in test_multinomial_empty_wo_replacement
    self._test_multinomial_empty(device, False, 1)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7742, in _test_multinomial_empty
    out = torch.multinomial(probs, num_samples=num_samples, replacement=replacement)
RuntimeError: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous

======================================================================
ERROR: test_nondeterministic_alert_gather_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4120, in test_nondeterministic_alert_gather
    test_func(torch.gather)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4111, in test_func
    res = op_call(a, dim, index)
RuntimeError: Input tensor must have same size as output tensor apart from the specified dimension

======================================================================
ERROR: test_pdist_norm_large_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 772, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6358, in test_pdist_norm_large
    actual_gpu = torch.pdist(x.to(device), p=2)
RuntimeError: Provided range is out of integer limits. Pass `-fno-sycl-id-queries-fit-in-int' to disable range check. -30 (CL_INVALID_VALUE)

======================================================================
ERROR: test_pickle_gradscaler_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7682, in test_pickle_gradscaler
    a = torch.xpu.amp.GradScaler(init_scale=3., growth_factor=4., backoff_factor=.5, growth_interval=2)
AttributeError: module 'intel_extension_for_pytorch.xpu' has no attribute 'amp'

======================================================================
ERROR: test_pin_memory_from_constructor_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7243, in test_pin_memory_from_constructor
    pinned_tensors = _get_tensors(pin_memory=True) + _get_like(torch.empty(5, dtype=torch.float64), pin_memory=True)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 7232, in _get_tensors
    torch.tensor([10, 11], **kwargs),
RuntimeError: Pinned memory requires CUDA. PyTorch splits its backend into two shared libraries: a CPU library and a CUDA library; this error has occurred because you are trying to use some CUDA functionality, but the CUDA library has not been loaded by the dynamic linker for some reason.  The CUDA library MUST be loaded, EVEN IF you don't directly use any symbols from the CUDA library! One common culprit is a lack of -Wl,--no-as-needed in your link arguments; many dynamic linkers will delete dynamic library dependencies if you don't depend on any of their symbols.  You can check if this has occurred by using ldd on your binary to see if there is a dependency on *_cuda.so library.

======================================================================
ERROR: test_repeat_interleave_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4332, in test_repeat_interleave
    a = torch.repeat_interleave(
RuntimeError: index_select(): Expected dtype int64 for index but got: Int

======================================================================
ERROR: test_scatter_add_bool_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 402, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5895, in test_scatter_add_bool
    res = res.scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]], device=device), x)
RuntimeError: scatter add only supports float, bfloat16, int, int64 and double type

======================================================================
FAIL: test_diff_noncontig_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5035, in test_diff_noncontig
    self._test_diff_numpy(non_contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=0.016 and atol=0.001, found 2 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 4.78125 (-4.78125 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_noncontig_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5035, in test_diff_noncontig
    self._test_diff_numpy(non_contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=0.001 and atol=0.001, found 1 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.6875 (-2.6875 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_noncontig_xpu_float32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5035, in test_diff_noncontig
    self._test_diff_numpy(non_contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=1.3e-06 and atol=0.001, found 1 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.692237854003906 (5.692237854003906 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_noncontig_xpu_int32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5035, in test_diff_noncontig
    self._test_diff_numpy(non_contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!Found 2 different element(s) (out of 2), with the greatest difference of 524279 (524279 vs. 0) occuring at index 1.

======================================================================
FAIL: test_diff_xpu_bfloat16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5051, in test_diff
    self._test_diff_numpy(contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=0.016 and atol=0.001, found 1 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 7.0 (7.0 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5051, in test_diff
    self._test_diff_numpy(contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=0.001 and atol=0.001, found 1 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 7.46484375 (7.46484375 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_xpu_float32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5051, in test_diff
    self._test_diff_numpy(contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=1.3e-06 and atol=0.001, found 1 element(s) (out of 2) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.9722890853881836 (2.9722890853881836 vs. 0.0), which occurred at index 0.

======================================================================
FAIL: test_diff_xpu_int32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5051, in test_diff
    self._test_diff_numpy(contig)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 5009, in _test_diff_numpy
    self.assertEqual(actual, expected.to(t.dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!Found 2 different element(s) (out of 2), with the greatest difference of 327678 (327678 vs. 0) occuring at index 1.

======================================================================
FAIL: test_exponential_no_zero_xpu_float32 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4436, in test_exponential_no_zero
    self.assertTrue(x.min() > 0)
AssertionError: tensor(False, device='xpu:0') is not true

======================================================================
FAIL: test_gather_backward_deterministic_path_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4228, in test_gather_backward_deterministic_path
    self._test_gather_backward_one_dim(device, True)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4219, in _test_gather_backward_one_dim
    self.assertEqual(src.grad, grad, atol=0, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1877, in assertEqual
    super().assertTrue(result, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: False is not true : Tensors failed to compare as equal!With rtol=0 and atol=0.001, found 1202 element(s) (out of 2989) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 3.0 (11755067.0 vs. 11755064.0), which occurred at index 815.

======================================================================
FAIL: test_index_copy_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6482, in test_index_copy_mem_overlap
    x.index_copy_(0, ind, value)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1282, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_index_fill_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6498, in test_index_fill_mem_overlap
    x.index_fill_(0, ind, 1.0)
AssertionError: UserWarning not triggered

======================================================================
FAIL: test_index_put_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6550, in test_index_put_mem_overlap
    x.index_put_((ind,), value)
AssertionError: UserWarning not triggered

======================================================================
FAIL: test_lognormal_kstest_xpu_float16 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 948, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4528, in test_lognormal_kstest
    self.assertTrue(res.statistic < 0.3)
AssertionError: False is not true

======================================================================
FAIL: test_masked_scatter_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6595, in test_masked_scatter_mem_overlap
    x.masked_scatter_(mask, src)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1282, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_masked_select_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6584, in test_masked_select_mem_overlap
    torch.masked_select(y, mask, out=y)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1282, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_nondeterministic_alert_AdaptiveAvgPool2d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3773, in test_nondeterministic_alert_AdaptiveAvgPool2d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_AdaptiveAvgPool3d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3785, in test_nondeterministic_alert_AdaptiveAvgPool3d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_AdaptiveMaxPool2d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3809, in test_nondeterministic_alert_AdaptiveMaxPool2d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_AvgPool3d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3761, in test_nondeterministic_alert_AvgPool3d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_CTCLoss_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3991, in test_nondeterministic_alert_CTCLoss
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_FractionalMaxPool2d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3821, in test_nondeterministic_alert_FractionalMaxPool2d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_FractionalMaxPool3d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3833, in test_nondeterministic_alert_FractionalMaxPool3d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_MaxPool3d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3797, in test_nondeterministic_alert_MaxPool3d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_NLLLoss_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3976, in test_nondeterministic_alert_NLLLoss
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_ReflectionPad1d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3905, in test_nondeterministic_alert_ReflectionPad1d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_ReflectionPad2d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3917, in test_nondeterministic_alert_ReflectionPad2d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_ReplicationPad2d_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3953, in test_nondeterministic_alert_ReplicationPad2d
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_bincount_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4079, in test_nondeterministic_alert_bincount
    test_func(torch.bincount)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4077, in test_func
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_histc_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4066, in test_nondeterministic_alert_histc
    test_func(torch.histc)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4064, in test_func
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_interpolate_bicubic_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3878, in test_nondeterministic_alert_interpolate_bicubic
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_interpolate_bilinear_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3863, in test_nondeterministic_alert_interpolate_bilinear
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_interpolate_linear_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3848, in test_nondeterministic_alert_interpolate_linear
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_interpolate_trilinear_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3893, in test_nondeterministic_alert_interpolate_trilinear
    backward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_kthvalue_xpu_float64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4101, in test_nondeterministic_alert_kthvalue
    test_func(self, device, 'function')
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_median_xpu_float64 (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1060, in efail_fn
    fn(slf, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4194, in test_func_expect_error
    test_func(slf, device, call_type)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4180, in test_func
    torch.median(a, 0)
NotImplementedError: Could not run 'aten::median.dim_values' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::median.dim_values' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].

CPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]
BackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]
Named: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]
Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]
Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]
AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
Tracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]
UNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
Autocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]
Batched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]
VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4197, in test_nondeterministic_alert_median
    test_func_expect_error(self, device, 'function with indices')
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1065, in efail_fn
    slf.fail(
AssertionError: expected non-deterministic error message to start with "median XPU with indices output does not have a deterministic implementation, but you set" but got this instead: "Could not run 'aten::median.dim_values' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::median.dim_values' is only available for these backends: [CPU, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].

CPU: registered at aten/src/ATen/RegisterCPU.cpp:18433 [kernel]
BackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]
Named: fallthrough registered at ../aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]
Conjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]
Negative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ADInplaceOrView: registered at ../torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:2399 [kernel]
AutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradMLC: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
AutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_1.cpp:9548 [autograd kernel]
Tracer: registered at ../torch/csrc/autograd/generated/TraceType_1.cpp:10664 [kernel]
UNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:466 [backend fallback]
Autocast: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:305 [backend fallback]
Batched: registered at ../aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]
VmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
"

======================================================================
FAIL: test_nondeterministic_alert_put_accumulate_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4053, in test_nondeterministic_alert_put_accumulate
    test_func(torch.Tensor.put)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4051, in test_func
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_put_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4038, in test_nondeterministic_alert_put
    test_func(torch.Tensor.put)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4036, in test_func
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_nondeterministic_alert_scatter_add_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4021, in test_nondeterministic_alert_scatter_add
    test_func(torch.Tensor.scatter_add_)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 4019, in test_func
    forward_func(self, device)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1071, in efail_fn
    slf.fail('expected a non-deterministic error, but it was not raised')
AssertionError: expected a non-deterministic error, but it was not raised

======================================================================
FAIL: test_put_mem_overlap_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 575, in only_fn
    return fn(self, device, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6531, in test_put_mem_overlap
    x.put_(ind, value)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1282, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_scalar_check_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 3152, in test_scalar_check
    self.assertEqual((1,), torch.remainder(zero_d, one_d).shape)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1943, in assertEqual
    super().assertEqual(len(x), len(y), msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: 1 != 0 : Attempted to compare the lengths of [iterable] types: Expected: 1; Actual: 0.

======================================================================
FAIL: test_serialization_xpu (__main__.TestTorchDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1396, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 397, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/common/pytorch_test_base.py", line 558, in only_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 905, in multi_fn
    return fn(slf, devices, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6799, in test_serialization
    _test_serialization(tempfile.NamedTemporaryFile)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/pytorch/test_torch.py", line 6797, in _test_serialization
    self.assertEqual(str(un.device), devices[-1])
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1916, in assertEqual
    super().assertEqual(x, y, msg=self._get_assert_msg(msg, debug_msg=debug_msg))
AssertionError: 'xpu:0' != 'xpu:1'
- xpu:0
?     ^
+ xpu:1
?     ^
 : Attempted to compare [string] types: Expected: 'xpu:0'; Actual: 'xpu:1'.

----------------------------------------------------------------------
Ran 534 tests in 576.980s

FAILED (failures=42, errors=37, skipped=160)
Raised CalledProcessError: return code 1.