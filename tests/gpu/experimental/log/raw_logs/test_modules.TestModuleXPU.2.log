MESA: warning: Driver does not support the 0xbd5 PCI ID.
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
test_check_inplace_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_cpu_gpu_parity_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_cpu_gpu_parity_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_cpu_gpu_parity_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_factory_kwargs_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ok
test_factory_kwargs_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'not ready on XPU'
test_forward_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ERROR
test_grad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ERROR
test_grad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped "not implemented: Could not run 'aten::_efficientzerotensor' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_efficientzerotensor' is only available for these backends: [CPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nBackendSelect: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_gradgrad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ERROR
test_gradgrad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_BatchNorm2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTM_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTM_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_MultiheadAttention_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_MultiheadAttention_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNN_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNN_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_multiple_device_transfer_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_non_contiguous_tensors_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_non_contiguous_tensors_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'not ready on XPU'
test_pickle_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_pickle_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_repr_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ok

======================================================================
ERROR: test_forward_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_forward_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_forward_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_forward_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_forward_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(1.1274, device='xpu:0', dtype=torch.float64)
analytical:tensor(1.1518, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 2.7636,  2.1451, -0.4034,  0.1162,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-4.2422,  3.5941, -5.4573, -4.9737,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 4.5358, -0.8585,  3.8466,  0.5782,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  5.0929,  4.6630, -2.5147,  2.2892,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.7604,  1.6324, -4.8200, -3.8679,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  3.7786, -1.8183,  3.3511, -0.6514,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0677, -0.2933,  0.8530, -1.0080,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -3.5419,  2.5194, -2.6849, -2.7028,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          2.3424,  0.0940,  1.9151,  0.8506,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  4.0081,  3.4322, -1.3864,  1.1073,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -2.9597,  2.9546, -5.5456, -4.8166,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  4.5062, -1.3520,  3.8879,  0.0618,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          5.1962,  5.2581, -3.8145,  3.7986,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          4.1994, -1.8530, -1.2259, -0.2114,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.6263, -2.0217,  0.7840, -1.8751,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -1.3333, -1.3179,  0.9006, -0.8831,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -0.7661,  0.2552,  0.5457,  0.2881,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -0.3628,  0.5083, -0.3661,  0.4054,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -3.9532, -3.3198,  1.2044, -0.9012,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          3.5687, -3.3735,  5.9516,  5.2382,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -4.8661,  1.3117, -4.1786, -0.2190,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -0.6907, -1.1068,  1.5246, -1.6969],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -4.6121,  3.1132, -2.8452, -3.0151],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  2.5477,  0.4044,  2.0428,  1.2355]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-1.7601e+02,  2.7636e+00,  2.1451e+00, -4.0340e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.7018e+02, -4.2422e+00,  3.5941e+00, -5.4573e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.8888e+02,  4.5358e+00, -8.5853e-01,  3.8466e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.1968e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -2.5147e+00, -2.5147e+00,  2.2892e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.7870e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -4.8200e+00, -4.8200e+00, -3.8679e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.8798e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  3.3511e+00,  3.3511e+00, -6.5141e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.3457e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.7744e-02,
         -2.9327e-01,  8.5302e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.2264e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.5419e+00,
          2.5194e+00, -2.6849e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.1109e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3424e+00,
          9.4022e-02,  1.9151e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-1.8099e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.0081e+00,  3.4322e+00, -1.3864e+00,
          1.1073e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.3365e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -2.9597e+00,  2.9546e+00, -5.5456e+00,
         -4.8166e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-2.0349e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.5062e+00, -1.3520e+00,  3.8879e+00,
          6.1810e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.7067e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  5.1962e+00,  5.2581e+00, -3.8145e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.3793e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  4.1994e+00, -1.8530e+00, -1.2259e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.0570e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  6.2628e-01, -2.0217e+00,  7.8405e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 7.3357e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.3333e+00, -1.3179e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.2150e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -7.6611e-01,  2.5522e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.9962e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -3.6284e-01,  5.0835e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 8.8714e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.9532e+00,
         -3.3198e+00,  1.2044e+00, -9.0116e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-8.0086e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.5687e+00,
         -3.3735e+00,  5.9516e+00,  5.2382e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.0920e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.8661e+00,
          1.3117e+00, -4.1786e+00, -2.1900e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [-4.1519e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -6.9072e-01, -1.1068e+00,
          1.5246e+00,  0.0000e+00],
        [-2.7723e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6121e+00,  3.1132e+00,
         -2.8452e+00,  0.0000e+00],
        [ 1.5314e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5477e+00,  4.0443e-01,
          2.0428e+00,  0.0000e+00]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 293.4167266613585.


======================================================================
ERROR: test_grad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0130, device='xpu:0', dtype=torch.float64)
analytical:tensor(9.1673, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.2719,  0.1587,  0.2693,  0.1984,  0.2216,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0566,  0.1852,  0.1385, -0.0424,  0.1780,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.1387, -0.1274, -0.0279,  0.2634,  0.1460,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0770,  0.1049, -0.0140, -0.2442,  0.2303,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2550, -0.1249,  0.1641, -0.0515,  0.1062,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1158,  0.0905, -0.2006, -0.2879,  0.1535,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2588, -0.1508,  0.0960,  0.0239,  0.2396,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0184,  0.1335, -0.0957,  0.0819, -0.0582,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1003,  0.0584,  0.1670, -0.1169, -0.2251,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0973, -0.1130, -0.1030,  0.1199, -0.1420,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1638, -0.1416,  0.0143, -0.0468, -0.0385,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0364,  0.0747,  0.0975, -0.2509, -0.0317,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2719,  0.1587,  0.2693,
          0.1984,  0.2216],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0566,  0.1852,  0.1385,
         -0.0424,  0.1780],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1387, -0.1274, -0.0279,
          0.2634,  0.1460],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0770,  0.1049, -0.0140,
         -0.2442,  0.2303],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2550, -0.1249,  0.1641,
         -0.0515,  0.1062],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1158,  0.0905, -0.2006,
         -0.2879,  0.1535],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2588, -0.1508,  0.0960,
          0.0239,  0.2396],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0184,  0.1335, -0.0957,
          0.0819, -0.0582],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1003,  0.0584,  0.1670,
         -0.1169, -0.2251],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0973, -0.1130, -0.1030,
          0.1199, -0.1420],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1638, -0.1416,  0.0143,
         -0.0468, -0.0385],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0364,  0.0747,  0.0975,
         -0.2509, -0.0317]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000,  0.0000,  0.2693,  0.2693,  0.2693,  0.2693,  0.2693,
          0.2693,  0.2693],
        [ 0.0000,  0.0000,  0.0000,  0.1385,  0.1385,  0.1385,  0.1385,  0.1385,
          0.1385,  0.1385],
        [ 1.0000,  0.0000,  1.0000, -0.0279, -0.0279, -0.0279, -0.0279, -0.0279,
         -0.0279, -0.0279],
        [ 0.0000,  0.0000,  0.0000, -0.0140, -0.0140, -0.0140, -0.0140, -0.0140,
         -0.0140, -0.0140],
        [-0.0539,  0.0000, -0.0539,  0.1641,  0.1641,  0.1641,  0.1641,  0.1641,
          0.1641,  0.1641],
        [-0.2022,  0.0000, -0.2022, -0.2006, -0.2006, -0.2006, -0.2006, -0.2006,
         -0.2006, -0.2006],
        [-0.3329,  0.0000, -0.3329,  0.0960,  0.0960,  0.0960,  0.0960,  0.0960,
          0.0960,  0.0960],
        [ 6.6175,  0.0000,  6.6175, -0.0957, -0.0957, -0.0957, -0.0957, -0.0957,
         -0.0957, -0.0957],
        [ 5.1490,  0.0000,  5.1490,  0.1670,  0.1670,  0.1670,  0.1670,  0.1670,
          0.1670,  0.1670],
        [ 1.7117,  0.0000,  1.7117, -0.1030, -0.1030, -0.1030, -0.1030, -0.1030,
         -0.1030, -0.1030],
        [ 0.1203,  0.0000,  0.1203,  0.0143,  0.0143,  0.0143,  0.0143,  0.0143,
          0.0143,  0.0143],
        [-0.2172,  0.0000, -0.2172,  0.0975,  0.0975,  0.0975,  0.0975,  0.0975,
          0.0975,  0.0975],
        [ 5.8692,  0.0000,  5.8692,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0443,  0.0000, -0.0443,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 6.4568,  0.0000,  6.4568,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 2.8224,  0.0000,  2.8224,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0353,  0.0000, -0.0353,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0580,  0.0000, -0.0580,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 5.1720,  0.0000,  5.1720,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.3265,  0.0000, -0.3265,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 4.6422,  0.0000,  4.6422,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 3.1389, -1.6969,  3.1389,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 5.8534, -3.0151,  5.8534,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 4.6927,  1.2355,  4.6927,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 6.713200200720423.


======================================================================
ERROR: test_grad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0061, device='xpu:0', dtype=torch.float64)
analytical:tensor(5.2522, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.1570,  0.0000,  0.1145,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0327, -0.1570, -0.0245,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0801, -0.0327,  0.1520,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.1071, -0.0976, -0.0949],
        [ 0.0000,  0.0000,  0.0000,  ..., -0.0501, -0.0081, -0.0976],
        [ 0.0000,  0.0000,  0.0000,  ..., -0.0339,  0.0000, -0.0081]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [1.7274, 6.2104, 1.7274,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 50.49381888590901.


======================================================================
ERROR: test_grad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0715, device='xpu:0', dtype=torch.float64)
analytical:tensor(24.9469, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0906,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0189, -0.0906,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0462, -0.0189, -0.0906,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0624, -0.0627, -0.0023],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0624, -0.0627],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0624]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0976,  0.0000, -0.0976,  ...,  0.0624, -0.0627, -0.0023],
        [-0.0081,  0.0000, -0.0081,  ...,  0.0000,  0.0624, -0.0627],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0624]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 667.9864505852802.


======================================================================
ERROR: test_grad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_grad_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.5121, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[2.6406e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 3.2434e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.3617e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 7.0573e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2278e-03, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8368e-04, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9171e-03, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3957e-01, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4897e-03,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         9.4713e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 5.6613e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 5.6052e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0057, 0.0057,
         0.0057, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.361674217532638.


======================================================================
ERROR: test_grad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(1.0685, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0000000000000009.


======================================================================
ERROR: test_grad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0001, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 9.2704e-05, -4.8018e-04, -2.7982e-05, -1.7587e-04],
        [-7.6241e-04, -9.9927e-05, -3.1015e-04, -1.5375e-05],
        [ 0.0000e+00,  0.0000e+00,  7.5984e-03,  2.7225e-03],
        [ 0.0000e+00,  0.0000e+00, -8.9394e-03,  3.2300e-04]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.008939399091953404.


======================================================================
ERROR: test_grad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0002, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-1.8762e-04, -1.7838e-03, -3.0685e-04, -6.3307e-04],
        [ 9.2715e-04, -3.7659e-05,  3.4688e-04, -3.9881e-05],
        [ 0.0000e+00,  0.0000e+00, -8.5022e-04,  1.3807e-03],
        [ 0.0000e+00,  0.0000e+00, -4.4265e-04,  2.1832e-04]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.001783751329006598.


======================================================================
ERROR: test_grad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[-2.8756e+303, -6.5342e+303, -1.3887e+304],
        [ 1.0469e-314,  2.3787e-314,  5.0555e-314]], device='xpu:0',
       dtype=torch.float64)

Expected:
tensor([[-0.2553, -0.5801, -1.2329],
        [ 0.4933,  1.1210,  2.3824]], device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.4061, device='xpu:0', dtype=torch.float64)
analytical:tensor(1.4573e+304, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  1.0260,  0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.0542,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.4127]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [-0., -0., -0., -0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0259986237403096.


======================================================================
ERROR: test_grad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[[-2.4288e+302, -2.4288e+302, -2.4288e+302,  2.4288e+302],
          [ 2.4288e+302, -2.4288e+302,  2.4288e+302, -2.4288e+302],
          [ 2.4288e+302, -2.4288e+302,  2.4288e+302, -2.4288e+302]],

         [[-2.4288e+302,  2.4288e+302,  2.4288e+302, -2.4288e+302],
          [-2.4288e+302,  2.4288e+302, -2.4288e+302, -2.4288e+302],
          [-2.4288e+302,  2.4288e+302, -2.4288e+302,  2.4288e+302]]],


        [[[ 1.7683e-315,  1.7683e-315,  1.7683e-315, -1.7683e-315],
          [-1.7683e-315,  1.7683e-315, -1.7683e-315,  1.7683e-315],
          [-1.7683e-315,  1.7683e-315, -1.7683e-315,  1.7683e-315]],

         [[ 1.7683e-315, -1.7683e-315, -1.7683e-315,  1.7683e-315],
          [ 1.7683e-315, -1.7683e-315,  1.7683e-315,  1.7683e-315],
          [ 1.7683e-315, -1.7683e-315,  1.7683e-315, -1.7683e-315]]]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[[ 0.0024,  0.0024,  0.0024, -0.0024],
          [-0.0024,  0.0024, -0.0024,  0.0024],
          [-0.0024,  0.0024, -0.0024,  0.0024]],

         [[ 0.0024, -0.0024, -0.0024,  0.0024],
          [ 0.0024, -0.0024,  0.0024,  0.0024],
          [ 0.0024, -0.0024,  0.0024, -0.0024]]],


        [[[ 0.0115,  0.0115,  0.0115, -0.0115],
          [-0.0115,  0.0115, -0.0115,  0.0115],
          [-0.0115,  0.0115, -0.0115,  0.0115]],

         [[ 0.0115, -0.0115, -0.0115,  0.0115],
          [ 0.0115, -0.0115,  0.0115,  0.0115],
          [ 0.0115, -0.0115,  0.0115, -0.0115]]]], device='xpu:0',
       dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 839, in _test_batched_grad
    result = vmap(vjp)(torch.stack(grad_outputs))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_vmap_internals.py", line 323, in wrapped
    batched_outputs = func(*batched_inputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 822, in vjp
    results = grad(v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: different elements ...

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 845, in _test_batched_grad
    raise GradcheckError(
torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got: different elements ...

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

======================================================================
ERROR: test_grad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0002, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0025, -0.0007, -0.0032,  0.0019, -0.0017, -0.0020],
        [-0.0037, -0.0008,  0.0045, -0.0028,  0.0003,  0.0029],
        [ 0.0000,  0.0000,  0.0000,  0.0249,  0.0119, -0.0173],
        [ 0.0000,  0.0000,  0.0000, -0.0165, -0.0077,  0.0113]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.0249247526144733.


======================================================================
ERROR: test_grad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0033, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0033,  0.0007, -0.0045,  0.0025, -0.0001, -0.0026],
        [-0.0026, -0.0007,  0.0035, -0.0028, -0.0006,  0.0025],
        [ 0.0000,  0.0000,  0.0000,  0.0150,  0.0062, -0.0068],
        [ 0.0000,  0.0000,  0.0000,  0.0104,  0.0072, -0.0069]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0033,  0.0000, -0.0045,  0.0000,  0.0000],
        [ 0.0000, -0.0026,  0.0000,  0.0035,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.015026615043121916.


======================================================================
ERROR: test_grad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 1e-12.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[[[inf, inf, -inf, -inf],
           [inf, -inf, -inf, -inf],
           [inf, -inf, inf, -inf]],

          [[inf, inf, -inf, -inf],
           [-inf, inf, inf, -inf],
           [-inf, inf, -inf, inf]],

          [[-inf, inf, -inf, -inf],
           [inf, -inf, inf, inf],
           [-inf, inf, -inf, inf]],

          [[-inf, inf, inf, inf],
           [-inf, -inf, -inf, inf],
           [inf, -inf, inf, -inf]]],


         [[[inf, -inf, inf, -inf],
           [inf, -inf, -inf, -inf],
           [-inf, inf, inf, inf]],

          [[inf, inf, inf, -inf],
           [inf, inf, -inf, -inf],
           [-inf, -inf, -inf, inf]],

          [[inf, inf, -inf, inf],
           [-inf, inf, inf, inf],
           [-inf, inf, inf, inf]],

          [[inf, -inf, inf, -inf],
           [-inf, -inf, inf, -inf],
           [-inf, -inf, inf, -inf]]]],



        [[[[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]]],


         [[[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]],

          [[0., 0., 0., 0.],
           [0., 0., 0., 0.],
           [0., 0., 0., 0.]]]]], device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[[[ 2.6479e-01, -3.0249e-01,  2.1657e-01,  5.2986e-02],
           [ 3.5886e-01,  2.6828e-01, -2.6723e-01, -1.9902e-01],
           [-1.3401e-01, -1.3563e-01, -1.0021e-01,  2.0316e-01]],

          [[ 3.6616e-02,  7.7704e-02,  2.2170e-01, -7.8981e-02],
           [-1.8905e-02, -2.9999e-01,  2.4006e-01, -2.8755e-01],
           [-6.1985e-01, -4.1667e-01, -3.2931e-01, -1.4124e-01]],

          [[-3.2174e-01,  4.4204e-02, -3.2389e-02,  2.4455e-01],
           [-4.2586e-01,  9.8550e-03,  5.1446e-01,  2.1540e-02],
           [-3.7442e-01,  6.8237e-02,  1.5028e-01,  3.3618e-01]],

          [[-4.2488e-02, -4.4306e-01,  5.1633e-02,  6.6768e-02],
           [ 1.8738e-02, -3.0763e-01,  1.8572e-01,  7.9545e-02],
           [ 2.4116e-01, -1.2480e-01,  4.6248e-01, -1.7204e-01]]],


         [[[-3.0839e-01,  5.9576e-01, -1.3419e-01, -9.2693e-02],
           [-3.1436e-01, -2.1901e-01, -6.6083e-02,  1.9611e-02],
           [ 2.9813e-01, -3.9895e-01,  7.3075e-01,  1.9482e-01]],

          [[-2.2142e-01,  3.6780e-01, -1.8100e-01,  1.4984e-01],
           [-3.5410e-01, -2.7734e-01,  4.7713e-01, -2.0685e-01],
           [ 4.3246e-01,  3.7517e-01, -3.8153e-01, -1.1520e-01]],

          [[ 1.8615e-02, -2.5930e-01,  1.3640e-01, -4.8545e-02],
           [ 6.3684e-01, -3.8443e-01, -1.5891e-01,  4.7983e-02],
           [ 1.3374e-01, -2.1362e-01, -3.2084e-01,  2.0780e-01]],

          [[-3.9042e-01,  1.5912e-01, -1.9898e-01,  3.2575e-01],
           [ 2.8364e-01, -3.6725e-01, -3.2855e-01,  2.2874e-01],
           [ 9.7422e-02,  2.0740e-01,  2.3287e-01,  1.9364e-02]]]],



        [[[[-1.1674e-02, -6.5785e-04, -1.5090e-02, -8.4167e-03],
           [ 3.2578e-03,  5.1714e-02,  3.0343e-02,  1.5307e-02],
           [-1.4123e-02, -6.8414e-02, -3.6310e-02,  1.2570e-02]],

          [[-3.9684e-02, -3.3601e-02,  6.9009e-03,  2.8200e-02],
           [-7.5497e-04, -4.8903e-02,  1.8966e-02,  1.0646e-02],
           [ 4.1152e-03,  1.1832e-02,  3.9705e-03, -1.8557e-02]],

          [[-1.0581e-03,  1.5238e-02, -8.7793e-03,  4.5739e-03],
           [-2.0707e-02, -2.8393e-02, -1.9834e-02, -1.7046e-02],
           [ 7.3066e-03, -4.8857e-02, -3.2775e-02,  5.4186e-03]],

          [[ 1.2363e-02,  1.9043e-02, -4.6075e-02,  2.5693e-02],
           [ 3.9117e-02,  1.1328e-02, -1.8493e-02,  3.6822e-02],
           [ 3.6729e-03,  2.3693e-03,  2.0036e-02,  1.3577e-02]]],


         [[[-1.4447e-02, -1.8689e-02, -4.9239e-03, -8.6614e-03],
           [-8.5539e-03,  4.1820e-02,  4.0639e-02,  1.2744e-02],
           [-2.4675e-02, -4.7139e-02, -3.1126e-02,  1.2687e-02]],

          [[-5.3033e-02, -2.8006e-02,  2.7100e-02,  1.4014e-02],
           [ 5.7121e-03, -5.2185e-02,  9.5745e-03,  1.7001e-02],
           [ 2.0352e-02,  1.6737e-02,  4.4152e-03, -1.1110e-02]],

          [[ 1.3879e-02,  4.2726e-03, -1.2141e-02,  1.5335e-02],
           [-2.5752e-02, -1.7593e-02, -1.9491e-02, -2.2322e-02],
           [ 8.4462e-03, -4.5556e-02, -3.6936e-02,  2.6138e-03]],

          [[ 2.5227e-02,  7.8212e-03, -1.7724e-02,  7.1437e-03],
           [ 3.8998e-02,  2.5451e-03,  2.0452e-03,  2.6717e-02],
           [ 5.7938e-04,  6.2822e-03,  2.7587e-02,  4.1262e-03]]]]],
       device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 1e-12.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[ 1.2906e+303,  4.8436e+304,  3.8333e+304, -2.0079e+304, -3.1762e+304,
           1.9969e+301,  4.7347e+304,  5.1154e+304, -4.1412e+304, -1.5421e+304],
         [-2.3796e+304,  2.4057e+303, -2.5193e+304,  3.0633e+303,  3.4775e+303,
          -1.1706e+304, -1.6950e+304,  3.5350e+304,  9.1181e+303,  2.4420e+304],
         [ 2.5988e-313, -2.6274e-314,  2.7514e-313, -3.3455e-314, -3.7978e-314,
           1.2785e-313,  1.8511e-313, -3.8607e-313, -9.9581e-314, -2.6670e-313],
         [ 1.2906e+303,  4.8436e+304,  3.8333e+304, -2.0079e+304, -3.1762e+304,
           1.9969e+301,  4.7347e+304,  5.1154e+304, -4.1412e+304, -1.5421e+304],
         [-2.3796e+304,  2.4057e+303, -2.5193e+304,  3.0633e+303,  3.4775e+303,
          -1.1706e+304, -1.6950e+304,  3.5350e+304,  9.1181e+303,  2.4420e+304],
         [ 5.1976e-313, -5.2547e-314,  5.5028e-313, -6.6909e-314, -7.5957e-314,
           2.5569e-313,  3.7023e-313, -7.7214e-313, -1.9916e-313, -5.3339e-313],
         [ 1.2906e+303,  4.8436e+304,  3.8333e+304, -2.0079e+304, -3.1762e+304,
           1.9969e+301,  4.7347e+304,  5.1154e+304, -4.1412e+304, -1.5421e+304],
         [-2.3796e+304,  2.4057e+303, -2.5193e+304,  3.0633e+303,  3.4775e+303,
          -1.1706e+304, -1.6950e+304,  3.5350e+304,  9.1181e+303,  2.4420e+304]],

        [[  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00]]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[ 6.5617e+00, -1.3767e+01,  4.0494e+00,  5.5663e+00,  9.7741e+00,
           4.7691e+00, -1.2381e+01, -8.3116e-01, -6.9550e+00, -4.1403e+00],
         [ 1.1477e+00, -1.7422e+00,  2.3501e+01, -4.3174e+00,  6.3091e+00,
           1.4063e+01,  1.3980e+01, -4.9654e+00, -1.1238e+01, -9.2780e+00],
         [ 1.4419e+01, -2.9254e+01,  1.0186e+01,  8.3619e+00,  2.0166e+01,
           1.4371e+01, -1.3883e+01, -3.2605e+01, -5.0741e-01, -1.1420e+01],
         [ 1.0830e+00,  1.1243e+01,  5.8852e+00, -3.0785e+00, -8.2237e+00,
          -2.8280e+00,  5.9020e+00,  1.9717e+01, -1.2290e+01, -2.4831e+00],
         [ 5.3328e+00, -1.2531e+01,  8.1967e+00,  3.7687e+00,  1.0162e+01,
           7.3827e+00, -7.3254e+00, -3.3425e+00, -7.1754e+00, -5.1830e+00],
         [-2.2251e+00, -1.8411e+01, -2.1357e+00,  7.0835e+00,  1.6255e+01,
           5.1192e+00, -1.7995e+01,  2.1472e+00, -9.3766e-01,  3.6059e+00],
         [-2.2271e+00,  1.6248e+00,  7.8142e+00, -4.1071e+00,  1.0575e+00,
           6.1973e+00,  1.2445e+01, -1.4236e+01,  4.1966e+00, -2.5086e+00],
         [ 1.3039e+00,  4.8196e+00,  1.4284e+01, -2.4026e+00, -9.1289e-01,
           4.0144e+00,  5.3656e+00,  1.8793e+01, -1.7330e+01, -5.1854e+00]],

        [[ 9.9539e+00,  2.1881e+01, -3.5417e+01,  3.1505e+00, -3.0751e+01,
          -3.2549e+01, -1.3503e+01,  2.1682e+01,  5.9635e+00,  6.6683e+00],
         [ 3.9273e+03, -5.6403e+03,  4.5063e+03,  2.0985e+03,  4.1498e+03,
           3.0378e+03, -4.3365e+03,  9.5120e+02, -5.7152e+03, -3.3506e+03],
         [ 3.2457e+04, -4.6937e+04,  3.7673e+04,  1.7359e+04,  3.4667e+04,
           2.5473e+04, -3.5808e+04,  7.6880e+03, -4.7421e+04, -2.7830e+04],
         [-1.2477e+05,  1.8019e+05, -1.4453e+05, -6.6715e+04, -1.3300e+05,
          -9.7663e+04,  1.3766e+05, -2.9697e+04,  1.8217e+05,  1.0689e+05],
         [-1.2208e+04,  1.7610e+04, -1.4116e+04, -6.5263e+03, -1.2990e+04,
          -9.5335e+03,  1.3471e+04, -2.9197e+03,  1.7816e+04,  1.0450e+04],
         [ 3.5380e+01, -3.1750e+01,  1.5088e+01,  1.7839e+01,  1.5427e+01,
           5.7857e+00, -4.0572e+01,  1.7890e+01, -3.9841e+01, -2.1946e+01],
         [ 2.0952e+05, -3.0254e+05,  2.4263e+05,  1.1203e+05,  2.2328e+05,
           1.6394e+05, -2.3119e+05,  4.9900e+04, -3.0590e+05, -1.7947e+05],
         [ 3.9604e+00, -3.1321e+01,  3.7118e+01,  3.6267e+00,  3.3249e+01,
           3.1393e+01, -2.4318e+00, -1.4100e+01, -1.9214e+01, -1.3980e+01]]],
       device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[ -5.6912e-02,   1.0061e-01,   1.2983e-01,   7.5655e-02,  -3.7020e-01,
           -5.3408e-01,  -1.1977e-02,  -5.0787e-02,  -3.4687e-03,   3.6267e+00],
         [  3.3249e+01,   3.1393e+01,  -2.4318e+00,  -1.4100e+01,  -1.9214e+01,
           -1.3980e+01,  -3.9417e-02,  -4.1330e-02,  -2.6017e-02,  -2.1769e-02],
         [  3.2424e-03,  -6.3227e-02,  -7.6079e-03,  -1.3800e-02,  -1.6415e-02,
            1.0456e-02,  -3.0078e-02,  -4.7060e-02,  -5.3107e-02,  -5.8331e-03],
         [  4.8352e-03,  -3.8342e-03,  -1.1359e-02,  -2.2892e-02,  -3.6051e-02,
           -1.6553e-02,  -2.3854e-02,  -5.6675e-02,   3.0599e-04,   2.0888e-04],
         [  3.9216e-03,   3.9538e-03,  -3.0281e-02,  -1.8268e-02,   8.3081e-03,
            2.1395e-02,   2.5503e-03,  -1.1185e-02,  -1.6661e-03,  -1.3835e-02],
         [ -2.0897e-02,  -1.9382e-03,  -2.6080e-02,  -1.9211e-02,  -2.5179e-02,
           -1.9531e-02,   5.2461e-03,   1.3166e-02,   1.8887e-03,  -1.0581e-02],
         [ -1.1143e-02,   7.8011e-04,  -2.2781e-02,   1.0356e-02,   1.1445e-02,
           -5.5161e-02,   1.1242e-02,  -6.4488e-03,  -1.4771e-01,  -7.5591e-02],
         [  2.5293e-02,   1.7474e-02,  -1.9087e-02,   1.5720e-01,  -1.0055e-01,
           -1.1911e-01,   2.4112e-02,   1.1907e-02,  -8.9605e-02,  -1.5897e-01],
         [ -7.1862e-02,  -3.5289e-02,   6.9654e-01,  -2.9400e+00,  -2.5380e+00,
            4.1874e-01,  -1.8250e+00,  -1.5416e+00,  -2.9423e-01,   4.2259e-01],
         [  3.1270e-01,  -3.7866e-03,  -2.1437e-02,  -1.7931e-02,  -1.0131e-02,
           -8.5609e-03,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   1.1445e-02,  -5.5161e-02],
         [  1.1242e-02,  -3.8157e-03,  -5.5846e-04,   1.6279e-02,   0.0000e+00,
            0.0000e+00,   0.0000e+00,  -0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00]],

        [[  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00, -5.8290e+303,  6.3660e-314,  4.4466e-323,
          -5.8290e+303,  6.3660e-314,  4.4466e-323, -5.8290e+303,  6.3660e-314],
         [ 4.4466e-323, -5.8290e+303,  6.3660e-314,  1.4822e-323, -5.8290e+303,
           1.2732e-313,  2.9644e-323, -5.8290e+303,  1.2732e-313,  2.9644e-323],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00],
         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,
            0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00]]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000, -0.0502],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0502,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0502,
           0.0000,  0.0000,  0.0000],
         [-0.0502,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [-0.0502,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000, -0.0502,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0502,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000, -0.0502,  0.0000],
         [-0.0502,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0502,  0.0000,
           0.0000,  0.0000,  0.0000],
         [-0.0502,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0502,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0502,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000, -0.0502,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000, -0.0502,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000, -0.0045],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0045,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0045,
           0.0000,  0.0000,  0.0000],
         [-0.0045,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [-0.0045,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000, -0.0045,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0045,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000, -0.0045,  0.0000],
         [-0.0045,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0045,  0.0000,
           0.0000,  0.0000,  0.0000],
         [-0.0045,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0045,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0045,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000, -0.0045,  0.0000,  0.0000,  0.0000,
           0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
           0.0000, -0.0045,  0.0000]]], device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[-1.3688e+302,  1.4088e+302, -2.3579e+302,  1.5243e+302, -2.5128e+301],
        [-2.6896e+302, -5.0384e+301, -2.3681e+302, -3.0532e+302,  2.2413e+302]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[ 0.0114, -0.0006,  0.0244,  0.0882, -0.0549],
        [ 0.0353, -0.0117,  0.0392,  0.0255, -0.0220]], device='xpu:0',
       dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(-0.0058, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.4661, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000,  0.1842,  0.0000,  0.0000,  0.0000,  0.0000,  0.0374,  0.0095,
          0.0400],
        [ 0.0000, -0.1701,  0.0000,  0.0000,  0.0000,  0.0000, -0.0268, -0.0109,
         -0.0348],
        [ 0.0000,  0.0707,  0.0000,  0.0000,  0.0000,  0.0000,  0.0092,  0.0050,
          0.0140],
        [ 0.0000,  0.1638,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000, -0.2337,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.2398,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0530,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0546,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  1.7181,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0254],
        [ 0.0000,  0.0000, -1.5646,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0231],
        [ 0.0000,  0.0000,  0.4143,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0061]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.718053971105496.


======================================================================
ERROR: test_grad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.1074, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0828, -0.2976, -0.1672, -0.0506],
        [ 0.0109, -0.0725, -0.0287, -0.0220],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.2975547290104963.


======================================================================
ERROR: test_grad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0172, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.9999999999998899.


======================================================================
ERROR: test_grad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 839, in _test_batched_grad
    result = vmap(vjp)(torch.stack(grad_outputs))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_vmap_internals.py", line 323, in wrapped
    batched_outputs = func(*batched_inputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 822, in vjp
    results = grad(v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: different elements ...

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 845, in _test_batched_grad
    raise GradcheckError(
torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got: different elements ...

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

======================================================================
ERROR: test_grad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 1:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[ 0.1462, -0.1294, -0.0567],
         [ 0.1095,  0.1373, -0.0724],
         [-0.3246,  0.2874,  0.1258],
         [-0.2431, -0.3048,  0.1607],
         [-0.1667,  0.1476,  0.0646],
         [-0.1249, -0.1565,  0.0826],
         [ 0.2990, -0.2647, -0.1158],
         [ 0.2239,  0.2806, -0.1480]],

        [[-0.3660,  0.3240,  0.1418],
         [-0.2741, -0.3436,  0.1812],
         [-0.0540,  0.0478,  0.0209],
         [-0.0405, -0.0507,  0.0268],
         [ 0.1046, -0.0926, -0.0405],
         [ 0.0784,  0.0982, -0.0518],
         [-0.2099,  0.1858,  0.0813],
         [-0.1572, -0.1970,  0.1039]]], device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[-0.1048,  0.4599, -0.2744],
         [-0.3855,  0.0772,  0.2778],
         [ 2.3813,  1.1269, -0.6168],
         [ 0.0796, -0.0115, -0.0194],
         [-0.3472,  1.0993,  0.9243],
         [-0.1234,  0.1071, -0.1211],
         [ 0.0697,  0.0117, -0.1001],
         [-0.1723, -0.1079, -0.0092]],

        [[ 0.1105,  0.0312, -0.0515],
         [-0.1211,  0.0080,  0.0894],
         [-0.3165, -0.1062,  0.0453],
         [ 0.0353, -0.0054, -0.0102],
         [-0.0822,  0.2248,  0.1531],
         [-0.0726, -0.1272,  0.1090],
         [ 0.3493, -0.0133, -0.0859],
         [ 0.1867,  0.0381, -0.0175]]], device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_gradgrad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_gradgrad_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0124, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -8.9840e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  5.6229e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -7.2916e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -8.2905e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3774e-02,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.6065e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -2.3608e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1282e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2197e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -7.6638e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.3813e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0466e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-1.3469e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  1.7977e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -3.3166e-05, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -3.0720e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.1261e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.2001e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -1.1251e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  7.5586e-03,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8372e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -7.2916e-02, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -8.2905e-01, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.3774e-02,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -1.6065e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -2.3608e-04, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1282e-03,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2197e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -7.6638e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -1.3813e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.0466e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.03071995263513785.


======================================================================
ERROR: test_gradgrad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(-137736.1574, device='xpu:0', dtype=torch.float64)
analytical:tensor(1.0463, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0.


======================================================================
ERROR: test_gradgrad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0072, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-2.4667e-04, -2.9262e-06,  9.7687e-05,  1.0136e-05],
        [-2.9262e-06, -6.4589e-06,  7.2568e-06,  1.2266e-06],
        [ 9.7687e-05,  7.2568e-06,  1.9026e-02,  4.3509e-03],
        [ 1.0136e-05,  1.2266e-06,  4.3509e-03,  1.1600e-04]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 0.019026471923045102.


======================================================================
ERROR: test_gradgrad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[ 2.9811e+303, -1.0853e-314,  -0.0000e+00],
        [ 2.9811e+303, -1.0853e-314,  -0.0000e+00]], device='xpu:0',
       dtype=torch.float64)

Expected:
tensor([[-1.2338e-01, -3.2796e-01, -4.2049e-01],
        [-5.1143e-01, -5.7574e+02, -6.4517e+01]], device='xpu:0',
       dtype=torch.float64)

======================================================================
ERROR: test_gradgrad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0224, device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0304, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0291, -0.0146, -0.0107, -0.0028, -0.0018],
        [-0.0146, -0.0358, -0.0343, -0.0061,  0.0115],
        [-0.0107, -0.0343, -0.0186,  0.0034,  0.0173],
        [-0.0028, -0.0061,  0.0034, -0.0277,  0.0144],
        [-0.0018,  0.0115,  0.0173,  0.0144, -0.0319]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[ 0.0291, -0.0146, -0.0107, -0.0028, -0.0018],
        [-0.0146, -0.0358, -0.0343, -0.0061,  0.0115],
        [-0.0107, -0.0343, -0.0186,  0.0034,  0.0173],
        [-0.0028, -0.0061,  0.0034, -0.0277,  0.0144],
        [-0.0018,  0.0115,  0.0173,  0.0144, -0.0319]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 2.0459540867046044e-09.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_gradgrad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 2 with respect to input 0,
numerical:tensor(0.0633, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.1266, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.8295,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.8295,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ..., -0.9326,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.9326,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.9326]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.8295,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.8295,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.8295,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ..., -0.9326,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.9326,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.9326]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.9900544957813593.


======================================================================
ERROR: test_gradgrad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(nan, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0094, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[   -inf,     nan,     nan,     nan,     nan,     nan,    -inf,    -inf,
             inf],
        [-0.0034,  0.0043, -0.0039,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0043, -0.0054,  0.0046,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [-0.0039,  0.0046, -0.0030,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0149, -0.0485,  0.0346,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000, -0.0485,  0.0219, -0.0165,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0346, -0.0165,  0.0124,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0782, -0.0162,
          0.0098],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0162, -0.1083,
          0.0761]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000,  0.0023, -0.0017, -0.0017,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000, -0.0028,  0.0021,  0.0021,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0021, -0.0015, -0.0015,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0107,  0.0080,  0.0080,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0252, -0.0180, -0.0180,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0180,  0.0129,  0.0129,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0427],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0168],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0128]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: nan.


======================================================================
ERROR: test_gradgrad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(-3521.4703, device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0535, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000, -0.0667,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0667,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0667,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000, -0.0667,  0.0000,  0.0000,  0.0000]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.06666666666666667.


======================================================================
ERROR: test_gradgrad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-31670.2118, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0134, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0069, -0.0005,  0.0019, -0.0121,  0.0144],
        [-0.0005,  0.0226, -0.0018, -0.0058,  0.0075],
        [ 0.0019, -0.0018,  0.0022,  0.0003, -0.0018],
        [-0.0121, -0.0058,  0.0003, -0.0120,  0.0152],
        [ 0.0144,  0.0075, -0.0018,  0.0152, -0.0181]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[-0.0069, -0.0005,  0.0019, -0.0121,  0.0144],
        [-0.0005,  0.0226, -0.0018, -0.0058,  0.0075],
        [ 0.0019, -0.0018,  0.0022,  0.0003, -0.0018],
        [-0.0121, -0.0058,  0.0003, -0.0120,  0.0152],
        [ 0.0144,  0.0075, -0.0018,  0.0152, -0.0181]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 2.5165472830601665e-09.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_gradgrad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(0.3253, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0.6045, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.6045, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.604488936320829.


======================================================================
ERROR: test_gradgrad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.1872, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.7964,  0.0000,  0.7172,  0.0000],
        [ 0.0000, -0.7964,  0.0000,  0.7172],
        [ 0.0677,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0677,  0.0000,  0.0000]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 0.7963509767436471.


======================================================================
ERROR: test_gradgrad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(177059.0548, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.5242, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0000000000000009.


======================================================================
ERROR: test_gradgrad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0011, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 8.9602e-03,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  8.9701e-03,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  4.3419e-04,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.2156e-03,
          0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
         -2.6490e-02, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
         -0.0000e+00, -1.2594e-05]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.08559045995157465.


======================================================================
ERROR: test_gradgrad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_memory_format_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_memory_format_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_pickle_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_pickle_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
FAIL: test_memory_format_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 487, in test_memory_format
    self.assertEqual(outputs, desired_outputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 20 / 20 (100.0%)
Greatest absolute difference: 1.3981800792095733e+303 at index (0, 4, 0, 0) (up to 1e-05 allowed)
Greatest relative difference: 4.82646641830323e+303 at index (1, 4, 0, 1) (up to 1e-05 allowed)

======================================================================
FAIL: test_memory_format_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_ELU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 487, in test_memory_format
    self.assertEqual(outputs, desired_outputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 20 / 20 (100.0%)
Greatest absolute difference: 2.6241903058972156e+303 at index (1, 4, 0, 0) (up to 1e-05 allowed)
Greatest relative difference: 4.797788222399133e+303 at index (1, 1, 0, 0) (up to 1e-05 allowed)

======================================================================
FAIL: test_memory_format_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 90 / 90 (100.0%)
Greatest absolute difference: 2.5630046902039666e+37 at index (0, 0, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: 2.978033616349366e+36 at index (0, 2, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 18 / 18 (100.0%)
Greatest absolute difference: 1.1026946306228638 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 52.389708201325995 at index (2, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 216 / 216 (100.0%)
Greatest absolute difference: 6.428205487733342e+37 at index (0, 2, 5, 0) (up to 0.0001 allowed)
Greatest relative difference: 5.733838021399811e+37 at index (1, 1, 4, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 216 / 216 (100.0%)
Greatest absolute difference: inf at index (0, 0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 384 / 384 (100.0%)
Greatest absolute difference: 1.858106440961715e+27 at index (1, 0, 2, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 3, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 384 / 384 (100.0%)
Greatest absolute difference: 8.075291901847352e+19 at index (1, 0, 3, 2, 3) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 737.7173871994019 at index (2, 1) (up to 0.0001 allowed)
Greatest relative difference: 1.3283975851798304 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 1313.1748588870298 at index (5, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0251406397506622 at index (5, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 5.013473191312432e+36 at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: 6.005572702889043e+44 at index (0, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 12 / 24 (50.0%)
Greatest absolute difference: 8.009193248320521e+275 at index (0, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 4.077454730078587e+26 at index (1, 3, 1, 1) (up to 0.0001 allowed)
Greatest relative difference: 5.877173954756128 at index (0, 0, 2, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 31512.705078125 at index (0, 0, 1, 3) (up to 0.0001 allowed)
Greatest relative difference: 1.7199571533181795e+17 at index (0, 0, 0, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 3.3445172011852264 at index (0, 1, 2, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: 9.946171867176183 at index (0, 3, 0, 1, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 10.282354831695557 at index (1, 3, 2) (up to 0.0001 allowed)
Greatest relative difference: 49.06910326703406 at index (0, 1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 3, 1, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 2, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: nan at index (1, 0, 0, 0, 1) (up to 0.0001 allowed)
Greatest relative difference: nan at index (1, 0, 0, 0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ELU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 30 (100.0%)
Greatest absolute difference: 2.0629873900824828e+37 at index (1, 1, 1) (up to 0.0001 allowed)
Greatest relative difference: 6.236994938016e+18 at index (0, 1, 4) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 30 (100.0%)
Greatest absolute difference: 11.071927079603345 at index (1, 0, 1) (up to 0.0001 allowed)
Greatest relative difference: 2.057752352327914 at index (0, 1, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 5.4027838706970215 at index (0,) (up to 0.0001 allowed)
Greatest relative difference: 115.28290888226368 at index (4,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 4.060995169855529 at index (1,) (up to 0.0001 allowed)
Greatest relative difference: 106.67749964988789 at index (1,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 3 / 4 (75.0%)
Greatest absolute difference: 0.004154261434450746 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 43.18435780590257 at index (1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.26633664078631136 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0197026463918866 at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 510013.5108783096 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0000000826023472 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.016909129698536387 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: 174134.01980354806 at index (1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 7.69021469249221e+30 at index (0,) (up to 0.0001 allowed)
Greatest relative difference: 546513990.2708286 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.9908434220547235 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: 3.282085004553251 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 0.24785327911376953 at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 0.370769896316163 at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 3806140159.949472 at index (0,) (up to 0.0001 allowed)
Greatest relative difference: 1.000000000092163 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 1.119088448303512 at index (4,) (up to 0.0001 allowed)
Greatest relative difference: 48.191984841463686 at index (4,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.14285331219434738 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 3.328559570737787 at index (1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.11839070854838207 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 4.148120409510986 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.3355267037332553e+29 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.2310475004970276 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 33.683736698665285 at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 311, in test_non_contiguous_tensors
    self.assertEqual(param_grad, default_param_grad)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 60 / 60 (100.0%)
Greatest absolute difference: 3.339796132072061e+37 at index (0, 1, 1) (up to 1e-05 allowed)
Greatest relative difference: 1.327018392606348e+37 at index (0, 1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 78878.5078125 at index (1, 3, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 1, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 6.140486609782067e+147 at index (0, 3, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: nan at index (1, 3, 2, 1, 3) (up to 0.0001 allowed)
Greatest relative difference: nan at index (1, 3, 2, 1, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 1.207817799154894e+146 at index (0, 1, 2, 3, 1) (up to 0.0001 allowed)
Greatest relative difference: 1.0133266652030122e+33 at index (0, 1, 2, 3, 4) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 1.77879145830768e+38 at index (1, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0959700127420035e+19 at index (0, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 2.9733063963613297e+29 at index (0, 3, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.4245981550046845e+20 at index (1, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 3.873902204779462e+35 at index (1, 1, 0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: 3.2991096247879503e+36 at index (1, 0, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Linear_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 309, in test_non_contiguous_tensors
    self.assertEqual(input_kwargs_grad, default_input_kwargs_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 40 (75.0%)
Greatest absolute difference: 1.1633796194056012e+19 at index (3, 1) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 2) (up to 1e-05 allowed)

The failure occurred for item ['input']

======================================================================
FAIL: test_non_contiguous_tensors_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 309, in test_non_contiguous_tensors
    self.assertEqual(input_kwargs_grad, default_input_kwargs_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 40 (75.0%)
Greatest absolute difference: 0.3853164815191102 at index (3, 4) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item ['input']

======================================================================
FAIL: test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: 0.1328728199005127 at index (1, 2) (up to 0.0001 allowed)
Greatest relative difference: 9.116162605239461 at index (0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 15 / 150 (10.0%)
Greatest absolute difference: 0.13754217326641083 at index (0, 1) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 15 / 150 (10.0%)
Greatest absolute difference: 0.03927008803548947 at index (0, 7) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 7) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 10.27095617782027 at index (4,) (up to 0.0001 allowed)
Greatest relative difference: 465.9334646302008 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 5.366870600354898e+37 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 6 / 6 (100.0%)
Greatest absolute difference: 5.87372955039592e+302 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 0.09787271916866302 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.7344485296916675e+303 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ReLU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 1 / 4 (25.0%)
Greatest absolute difference: 0.7451989054679871 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: inf at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 6.708941189747792 at index (1,) (up to 0.0001 allowed)
Greatest relative difference: 8.0 at index (1,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 120 / 120 (100.0%)
Greatest absolute difference: 3.612528459506703e+33 at index (0, 2, 3, 3) (up to 0.0001 allowed)
Greatest relative difference: 8.303625424466295e+40 at index (1, 0, 3, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 119 / 120 (99.2%)
Greatest absolute difference: 62347.97761727546 at index (0, 2, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: 13134793967414.65 at index (0, 0, 3, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 23053848576.0 at index (0, 2, 3) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 12 / 12 (100.0%)
Greatest absolute difference: 17600199.995547462 at index (1, 3) (up to 0.0001 allowed)
Greatest relative difference: 1.0000000030217635 at index (0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_pickle_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 170, in test_pickle
    self.assertEqual(output, output_from_copy)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Absolute difference: 9.340488329047421 (up to 1e-05 allowed)
Relative difference: 0.9886135682944897 (up to 1e-05 allowed)

----------------------------------------------------------------------
Ran 918 tests in 181.830s

FAILED (failures=72, errors=189, skipped=238, expected failures=8)
Raised CalledProcessError: return code 1.