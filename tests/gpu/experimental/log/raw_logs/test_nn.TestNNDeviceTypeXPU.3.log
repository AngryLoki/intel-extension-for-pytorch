MESA: warning: Driver does not support the 0xbd5 PCI ID.
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
test_BatchNorm_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_Bilinear_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_CTCLoss_cudnn_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_CTCLoss_empty_target_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_Conv2d_backward_depthwise_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_Conv2d_backward_depthwise_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_Conv2d_depthwise_naive_groups_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_depthwise_naive_groups_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_depthwise_naive_groups_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_deterministic_cudnn_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_Conv2d_deterministic_cudnn_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_Conv2d_deterministic_cudnn_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_deterministic_cudnn_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_deterministic_cudnn_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_large_workspace_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_large_workspace_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_large_workspace_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv2d_naive_groups_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... ok
test_Conv2d_naive_groups_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_Conv2d_naive_groups_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_Conv2d_naive_groups_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_Conv2d_size_1_kernel_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_Conv3d_depthwise_naive_groups_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv3d_depthwise_naive_groups_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_Conv3d_depthwise_naive_groups_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ConvTranspose2d_large_output_padding_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ConvTranspose2d_large_output_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ConvTranspose2d_size_1_kernel_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_ConvTranspose3d_size_1_kernel_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_GRU_grad_and_gradgrad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /home/gta/xunsongh/pytorch/torch/csrc/autograd/engine.cpp:1059.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
FAIL
test_GroupNorm_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_GroupNorm_general_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_GroupNorm_numeric_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_GroupNorm_raises_error_if_one_value_per_group_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_InstanceNorm1d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_InstanceNorm2d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_InstanceNorm3d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_LSTM_grad_and_gradgrad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... FAIL
test_LayerNorm_general_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_LayerNorm_numeric_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_LocalResponseNorm_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_MarginLoss_empty_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_MarginLoss_empty_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_ReflectionPad2d_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ReflectionPad3d_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ReflectionPad_empty_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_ReflectionPad_empty_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_ReplicationPad1d_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_ReplicationPad2d_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_ReplicationPad3d_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_ReplicationPad_empty_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_ReplicationPad_empty_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_TransformerDecoderLayer_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_TransformerDecoder_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_TransformerEncoderLayer_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_TransformerEncoder_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_Transformer_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_Unfold_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_activations_bfloat16_cpu_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_activations_bfloat16_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_affine_2d_rotate0_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_affine_2d_rotate45_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_affine_2d_rotate90_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_affine_2d_rotateRandom_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_affine_3d_rotateRandom_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_batchnorm_affine_mixed_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_affine_mixed_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_affine_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_affine_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_eval_mixed_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_eval_mixed_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_eval_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_eval_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_grad_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_large_batch_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_large_batch_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_simple_average_mixed_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_simple_average_mixed_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_batchnorm_simple_average_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_simple_average_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_batchnorm_update_stats_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_clip_grad_norm_error_if_nonfinite_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_clip_grad_norm_multi_device_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_contig_wrong_stride_cudnn_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv1d_same_padding_backward_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_same_padding_backward_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_same_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_same_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_valid_padding_backward_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_valid_padding_backward_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_valid_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_valid_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv1d_vs_scipy_mode_same_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv1d_vs_scipy_mode_same_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_conv1d_vs_scipy_mode_valid_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv1d_vs_scipy_mode_valid_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_conv2d_no_grad_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv2d_same_padding_backward_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_same_padding_backward_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_same_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_same_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_valid_padding_backward_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_valid_padding_backward_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_valid_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_valid_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv2d_vs_scipy_mode_same_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv2d_vs_scipy_mode_same_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_conv2d_vs_scipy_mode_valid_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv2d_vs_scipy_mode_valid_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_conv3d_same_padding_backward_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_same_padding_backward_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_same_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_same_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_valid_padding_backward_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_valid_padding_backward_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_valid_padding_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_valid_padding_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv3d_vs_scipy_mode_same_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv3d_vs_scipy_mode_same_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_conv3d_vs_scipy_mode_valid_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv3d_vs_scipy_mode_valid_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_convTranspose_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_conv_backend_cuda_depthwise1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cuda_depthwise3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn1d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn2d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_cudnn3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_empty_batch1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_batch_channel3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_empty_channel3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_miopen1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen1d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen2d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen3d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_miopen_depthwise3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_mkldnn1d_cpu_input_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_cpu_input_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn1d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_cpu_input_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn2d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_cpu_input_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn3d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_batch_channel3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_mkldnn_empty_channel3d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow1d_dilated_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_dilated_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow1d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_dilated_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow2d_transposed_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_cpu_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cpu_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_backend_slow3d_cuda_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_cuda_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_backend_slow3d_dilated_has_bias_False_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_False_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_False_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_False_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_True_strided_False_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_True_strided_False_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_True_strided_True_contiguous_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_backend_slow3d_dilated_has_bias_True_strided_True_contiguous_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_conv_contiguous_for_oneDNN_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_cudnn_mismatch_memory_format_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_ndhwc_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_ndhwc_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_nhwc_support_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_nhwc_support_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_nhwc_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv_cudnn_nhwc_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_cudnn_nhwc_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_double_backward_groups_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_conv_double_backward_no_bias_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_conv_double_backward_stride_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_conv_double_backward_strided_with_3D_input_and_weight_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_conv_double_backward_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_empty_channel_xpu_xpu_complex64 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_conv_empty_channel_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
ok
test_conv_ic1_channels_last_for_oneDNN_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_large_nosplit_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_conv_noncontig_weights_and_bias_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_conv_noncontig_weights_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_conv_thnn_nhwc_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_thnn_nhwc_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_conv_transpose_with_output_size_and_no_batch_dim_ConvTranspose2d_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_conv_transpose_with_output_size_and_no_batch_dim_ConvTranspose3d_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_conv_transposed_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_convert_conv2d_weight_memory_format_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cross_entropy_label_smoothing_consistent_index_target_and_probs_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_label_smoothing_errors_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_label_smoothing_weight_ignore_indices_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_label_smoothing_with_probs_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_large_tensor_reduction_mean_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cross_entropy_large_tensor_reduction_none_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cross_entropy_large_tensor_reduction_sum_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cross_entropy_loss_index_target_unit_weights_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_one_hot_target_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_all_reductions_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_False_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_True_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_False_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_True_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_False_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_True_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cross_entropy_loss_prob_target_unit_weights_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_ctc_loss_cudnn_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_ctc_loss_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_cudnn_convolution_add_relu_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cudnn_convolution_add_relu_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cudnn_convolution_relu_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_cudnn_convolution_relu_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_device_mask_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_elu_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_elu_inplace_with_neg_alpha_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fold_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_glu_bfloat16_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_grid_sample_large_index_2d_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_grid_sample_large_index_2d_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_grid_sample_large_index_3d_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_grid_sample_large_index_3d_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_grid_sample_large_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_grid_sample_nan_inf_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_grid_sample_nan_inf_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_group_convTranspose_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_group_conv_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_groupnorm_nhwc_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_groupnorm_nhwc_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_gumbel_softmax_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_gumbel_softmax_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_gumbel_softmax_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_hardsigmoid_grad_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_hardswish_grad_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_hardswish_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_instancenorm_raises_error_for_single_spatial_element_during_training_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_instancenorm_raises_error_if_less_than_one_value_per_channel_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_invalid_reduction_strings_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_layernorm_half_precision_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_layernorm_weight_bias_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_leaky_relu_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_leaky_relu_inplace_with_neg_slope_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_leaky_relu_inplace_with_zero_slope_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_linear_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_log_softmax_big_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ok
test_log_softmax_big_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_logsigmoid_out_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_lstmcell_backward_only_one_output_grad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_masked_softmax_TxT_layout_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_masked_softmax_forward_with_nans_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_masked_softmax' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_masked_softmax' is only available for these backends: [CPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14484 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_masked_softmax_grad_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_masked_softmax' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_masked_softmax' is only available for these backends: [CPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14484 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_masked_softmax_transformer_layout_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_masked_softmax_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_masked_softmax' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_masked_softmax' is only available for these backends: [CPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:15910 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14484 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_mish_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_module_to_empty_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_module_to_empty_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_multi_margin_loss_errors_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_multihead_attention_dtype_batch_first_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attention_dtype_batch_first_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attention_dtype_batch_first_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attention_dtype_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attention_dtype_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attention_dtype_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_multihead_attn_fast_path_query_and_bias_have_different_dtypes_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_multihead_attn_fast_path_small_test_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_multihead_attn_in_proj_bias_none_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_multihead_attn_in_proj_weight_none_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_all_ignored_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_nll_loss_byte_target_matches_long_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_nll_loss_empty_tensor_reduction_mean_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_nll_loss_empty_tensor_reduction_none_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_nll_loss_empty_tensor_reduction_sum_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_invalid_target_dim_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_invalid_weights_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_large_tensor_reduction_mean_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_nll_loss_large_tensor_reduction_none_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_nll_loss_large_tensor_reduction_sum_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_nll_loss_mismatched_batch_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_out_of_bounds_ignore_index_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nll_loss_total_weight_is_zero_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_nn_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nn_scalars_reductions_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_nn_scalars_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_noncontig_conv_grad_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_noncontig_conv_grad_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_noncontig_conv_grad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_nonlinearity_propagate_nan_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_one_hot_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_overwrite_module_params_on_conversion_cpu_device_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_pad_xpu_xpu_complex128 (__main__.TestNNDeviceTypeXPU) ... skipped 'dtype not support on XPU'
test_pad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_prelu_backward_32bit_indexing_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_rnn_fused_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_rnn_fused_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_rnn_retain_variables_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_rnn_retain_variables_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_rnn_retain_variables_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_save_lstm_compatibility_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_silu_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_skip_init_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_smooth_l1_loss_bfloat16_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_smooth_l1_loss_vs_huber_loss_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_softmax_64bit_indexing_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_softmax_bfloat16_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_softmax_results_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... FAIL
test_softmax_results_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_softmax_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_softmax_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_softplus_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_softplus_low_threshold_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_softshrink_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_softshrink_negative_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_softshrink_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_threshold_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_to_complex_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py:975: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.
  warnings.warn(
ok
test_transformerencoderlayer_fast_path_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cpu'
test_transformerencoderlayer_gelu_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ok
test_transformerencoderlayer_gelu_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_transformerencoderlayer_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_transformerencoderlayer_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_transformerencoderlayer_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_triplet_margin_with_distance_loss_default_parity_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_triplet_margin_with_distance_loss_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_upsamplingBicubic2d_aa_correctness_memory_format_torch_channels_last_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bicubic2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bicubic2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:19962 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBicubic2d_aa_correctness_memory_format_torch_contiguous_format_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bicubic2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bicubic2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:19962 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBicubic2d_antialias_False_align_corners_False_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_upsamplingBicubic2d_antialias_False_align_corners_True_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_upsamplingBicubic2d_antialias_True_align_corners_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bicubic2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bicubic2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:19962 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBicubic2d_antialias_True_align_corners_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bicubic2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bicubic2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_0.cpp:19962 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBicubic2d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ok
test_upsamplingBilinear2d_aa_correctness_memory_format_torch_channels_last_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bilinear2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bilinear2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBilinear2d_aa_correctness_memory_format_torch_contiguous_format_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bilinear2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bilinear2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBilinear2d_antialias_False_align_corners_False_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_upsamplingBilinear2d_antialias_False_align_corners_True_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_upsamplingBilinear2d_antialias_True_align_corners_False_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bilinear2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bilinear2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingBilinear2d_antialias_True_align_corners_True_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_bilinear2d_aa.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_bilinear2d_aa.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingNearest1d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_upsamplingNearest1d_launch_config_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_upsamplingNearest1d_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_upsamplingNearest2d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_upsamplingNearest2d_launch_config_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_upsamplingNearest2d_launch_fail_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_upsamplingNearest2d_launch_rocm_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_upsamplingNearest2d_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_upsamplingNearest3d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... FAIL
test_upsamplingNearest3d_launch_config_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped 'not ready on XPU'
test_upsamplingNearest3d_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... ERROR
test_upsamplingNearestExact1d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_nearest_exact1d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_nearest_exact1d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_3.cpp:22330 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingNearestExact1d_rescale_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_nearest_exact1d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_nearest_exact1d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_3.cpp:22330 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_0.cpp:14883 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingNearestExact2d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_nearest_exact2d.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_nearest_exact2d.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_1.cpp:21945 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16890 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_upsamplingNearestExact3d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU) ... skipped "not implemented: Could not run 'aten::_upsample_nearest_exact3d.vec' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_upsample_nearest_exact3d.vec' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nQuantizedCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:929 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:16890 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_variable_sequence_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... ERROR
test_variable_sequence_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... ok
test_variable_sequence_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU) ... ok
test_warp_softmax_64bit_indexing_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'
test_warp_softmax_64bit_indexing_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU) ... skipped 'Only runs on cuda'

======================================================================
ERROR: test_BatchNorm_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10070, in test_BatchNorm_empty
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11279, in test_CTCLoss_no_batch_dim
    args = self._CTCLoss_gen_losses(device, input_length, vocab_size, target_length, reduction, use_module_form)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11256, in _CTCLoss_gen_losses
    has_cudnn = has_xpu and 'xpu' in device and self.has_cudnn()
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_Conv2d_naive_groups_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11464, in test_Conv2d_naive_groups
    output.backward(grad_output)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: so far only support float, bfloat16 and double convolution backward in XPU backend, your data type is Half

======================================================================
ERROR: test_InstanceNorm1d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9582, in test_InstanceNorm1d_general
    self._test_InstanceNorm_general(nn.InstanceNorm1d, input, device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 8777, in _test_InstanceNorm_general
    output = IN(input_var)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
RuntimeError: tensor does not have a device

======================================================================
ERROR: test_InstanceNorm2d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9592, in test_InstanceNorm2d_general
    self._test_InstanceNorm_general(nn.InstanceNorm2d, input, device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 8777, in _test_InstanceNorm_general
    output = IN(input_var)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
RuntimeError: tensor does not have a device

======================================================================
ERROR: test_InstanceNorm3d_general_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9603, in test_InstanceNorm3d_general
    self._test_InstanceNorm_general(nn.InstanceNorm3d, input, device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 8777, in _test_InstanceNorm_general
    output = IN(input_var)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
RuntimeError: tensor does not have a device

======================================================================
ERROR: test_LayerNorm_general_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9630, in test_LayerNorm_general
    self._test_LayerNorm_xpu_half(device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 8862, in _test_LayerNorm_xpu_half
    output.sum().backward()
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #3 'mean'

======================================================================
ERROR: test_batchnorm_affine_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11623, in test_batchnorm_affine
    self._test_batchnorm_affine(2, device, dtype)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11613, in _test_batchnorm_affine
    res2 = module(data)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: tensor does not have a device

======================================================================
ERROR: test_batchnorm_affine_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11623, in test_batchnorm_affine
    self._test_batchnorm_affine(2, device, dtype)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11613, in _test_batchnorm_affine
    res2 = module(data)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: tensor does not have a device

======================================================================
ERROR: test_batchnorm_eval_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11585, in test_batchnorm_eval
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_batchnorm_eval_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11585, in test_batchnorm_eval
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_batchnorm_grad_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11504, in test_batchnorm_grad
    self._test_batchnorm_grad(device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11501, in _test_batchnorm_grad
    _assertGradAndGradgradChecks(self, F.batch_norm, (input, running_mean, running_var, weight, bias, training, 0.1, 0.0001))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3351, in _assertGradAndGradgradChecks
    test_case.assertTrue(gradcheck(apply_fn, inputs, **kwargs))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_batchnorm_simple_average_xpu_xpu_bfloat16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11678, in test_batchnorm_simple_average
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_batchnorm_simple_average_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11678, in test_batchnorm_simple_average
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_batchnorm_update_stats_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11854, in test_batchnorm_update_stats
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_convTranspose_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10120, in test_convTranspose_empty
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_conv_double_backward_strided_with_3D_input_and_weight_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12168, in test_conv_double_backward_strided_with_3D_input_and_weight
    (grad_grad_output, grad_input, grad_weight) = torch.ops.aten._convolution_double_backward(ggI, ggW, ggB, gO, weight, input, stride, padding, dilation, transposed, output_padding, groups, output_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_ops.py", line 442, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_conv_transpose_with_output_size_and_no_batch_dim_ConvTranspose2d_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9484, in test_conv_transpose_with_output_size_and_no_batch_dim
    output = m(inp, output_size=output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_conv_transpose_with_output_size_and_no_batch_dim_ConvTranspose3d_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9484, in test_conv_transpose_with_output_size_and_no_batch_dim
    output = m(inp, output_size=output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_group_convTranspose_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10112, in test_group_convTranspose_empty
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_group_conv_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10104, in test_group_conv_empty
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_gumbel_softmax_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11103, in test_gumbel_softmax
    self._test_gumbel_softmax_grad(device, dtype)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11087, in _test_gumbel_softmax_grad
    y_soft.sum().backward()
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: "host_softmax_backward" not implemented for 'Half'

======================================================================
ERROR: test_instancenorm_raises_error_for_single_spatial_element_during_training_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9623, in test_instancenorm_raises_error_for_single_spatial_element_during_training
    m(input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_nll_loss_byte_target_matches_long_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12307, in test_nll_loss_byte_target_matches_long
    (result_byte, grad_byte) = compute_result_and_gradient(reduction, torch.uint8)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12302, in compute_result_and_gradient
    result = loss(prob, target.to(target_dtype))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2701, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: expected scalar type Long but found Byte

======================================================================
ERROR: test_rnn_retain_variables_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11123, in test_rnn_retain_variables
    self._test_rnn_retain_variables(device, dtype)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11110, in _test_rnn_retain_variables
    output[0].sum().backward(retain_graph=True)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: "tanh_backward_out" not implemented for 'Half'

======================================================================
ERROR: test_rnn_retain_variables_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11124, in test_rnn_retain_variables
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_rnn_retain_variables_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11124, in test_rnn_retain_variables
    if self.device_type == 'xpu' and self.has_cudnn():
AttributeError: 'TestNNDeviceTypeXPU' object has no attribute 'has_cudnn'

======================================================================
ERROR: test_threshold_inplace_overlap_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12673, in test_threshold_inplace_overlap
    F.threshold(x, 0.5, 0.5, inplace=True)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1425, in _threshold
    result = _VF.threshold_(input, threshold, value)
RuntimeError: unsupported operation: more than one element of the written-to tensor refers to a single memory location. Please clone() the tensor before performing the operation.

======================================================================
ERROR: test_transformerencoderlayer_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12865, in test_transformerencoderlayer
    _test(batch_first=batch_first, training=training, atol=atol, rtol=rtol)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12813, in _test
    result = model(encoder_input, src_key_padding_mask=mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_transformerencoderlayer_xpu_xpu_float32 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12865, in test_transformerencoderlayer
    _test(batch_first=batch_first, training=training, atol=atol, rtol=rtol)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12813, in _test
    result = model(encoder_input, src_key_padding_mask=mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_transformerencoderlayer_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12865, in test_transformerencoderlayer
    _test(batch_first=batch_first, training=training, atol=atol, rtol=rtol)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12795, in _test
    result = model(encoder_input)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_upsamplingBilinear2d_antialias_False_align_corners_False_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10610, in test_upsamplingBilinear2d
    out_t = F.interpolate(in_t, scale_factor=scale_factor, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3950, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_upsamplingBilinear2d_antialias_False_align_corners_True_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10620, in test_upsamplingBilinear2d
    gradcheck(lambda x: F.interpolate(x, out_size, **kwargs), [input], check_forward_ad=check_forward_ad, nondet_tol=nondet_tol)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.37882, device='xpu:0')
analytical:tensor(0.35553, device='xpu:0')

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[1.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        ...,
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 1.00000]],
       device='xpu:0')
Analytical:
tensor([[1.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.66667, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        ...,
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.66667, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 0.00000],
        [0.00000, 0.00000, 0.00000,  ..., 0.00000, 0.00000, 1.00000]],
       device='xpu:0')

The max per-element difference (slow mode) is: 1.0000000000000009.


======================================================================
ERROR: test_upsamplingNearest1d_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10382, in test_upsamplingNearest1d
    helper('nearest')
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10363, in helper
    out_t = m(in_t)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/upsampling.py", line 156, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3920, in interpolate
    return torch._C._nn.upsample_nearest1d(input, output_size, scale_factors)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_upsamplingNearest3d_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10543, in test_upsamplingNearest3d
    helper(torch.contiguous_format, 'nearest')
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10524, in helper
    out_t = m(in_t)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/upsampling.py", line 156, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3924, in interpolate
    return torch._C._nn.upsample_nearest3d(input, output_size, scale_factors)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_variable_sequence_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_cuda.py", line 144, in wrapped
    f(**kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11831, in test_variable_sequence
    check_lengths(seq_lens, enforce_sorted, use_default_hiddens, proj_size)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11817, in check_lengths
    seq_out.sum().backward()
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: "tanh_backward_out" not implemented for 'Half'

======================================================================
FAIL: test_GRU_grad_and_gradgrad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11174, in test_GRU_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11153, in _test_rnn_mod
    grad0.sum().backward()
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1889, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_GroupNorm_empty_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 9690, in test_GroupNorm_empty
    _test_module_empty_input(self, mod, inp)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/common_nn.py", line 6471, in _test_module_empty_input
    test_case.assertEqual(p.grad, torch.zeros_like(p.grad))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.29221912943913286 at index (0,) (up to 0.001 allowed)
Greatest relative difference: inf at index (0,) (up to 1e-07 allowed)

======================================================================
FAIL: test_LSTM_grad_and_gradgrad_xpu_xpu_float64 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11165, in test_LSTM_grad_and_gradgrad
    self._test_rnn_mod(mod, inp)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 11153, in _test_rnn_mod
    grad0.sum().backward()
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1889, in __exit__
    return super().__exit__(exc_type, exc_value, tb)
AssertionError: RuntimeError not raised

======================================================================
FAIL: test_nll_loss_all_ignored_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12288, in test_nll_loss_all_ignored
    helper([2, 3])
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12286, in helper
    self.assertEqual(F.nll_loss(input, target, ignore_index=0, reduction='mean').item(), float('nan'))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Absolute difference: nan (up to 0.001 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

======================================================================
FAIL: test_nll_loss_empty_tensor_reduction_mean_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12247, in test_nll_loss_empty_tensor_reduction_mean
    self._nll_loss_helper([0, 3], 'mean', nan, device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12233, in _nll_loss_helper
    self.assertEqual(output, expected, exact_dtype=False)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Absolute difference: nan (up to 0.001 allowed)
Relative difference: nan (up to 1e-07 allowed)

======================================================================
FAIL: test_nll_loss_empty_tensor_reduction_none_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12239, in test_nll_loss_empty_tensor_reduction_none
    self._nll_loss_helper([0, 3, 5, 7], 'none', torch.empty([0, 5, 7], device=device), device)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12233, in _nll_loss_helper
    self.assertEqual(output, expected, exact_dtype=False)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: The values for attribute 'shape' do not match: torch.Size([]) != torch.Size([0, 5, 7]).

======================================================================
FAIL: test_nll_loss_total_weight_is_zero_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12273, in test_nll_loss_total_weight_is_zero
    helper([2, 3])
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 12271, in helper
    self.assertEqual(F.nll_loss(input, target, weight, reduction='mean').item(), float('nan'))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Scalars are not close!

Absolute difference: nan (up to 0.001 allowed)
Relative difference: nan (up to 1.3e-06 allowed)

======================================================================
FAIL: test_nonlinearity_propagate_nan_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10333, in test_nonlinearity_propagate_nan
    test('relu')
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10329, in test
    self.assertTrue(math.isnan(fn(x, *args, **kwargs).item()))
AssertionError: False is not true

======================================================================
FAIL: test_softmax_results_xpu_xpu_float16 (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10815, in test_softmax_results
    self.assertEqual(output, ref_output)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 65568 / 65568 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.001 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1.3e-06 allowed)

======================================================================
FAIL: test_upsamplingNearest1d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10398, in test_upsamplingNearest1d_correctness
    helper(20, 11)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10397, in helper
    self.assertEqual(out_t, expected_out)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 10 / 11 (90.9%)
Greatest absolute difference: 1.0 at index (0, 0, 1) (up to 0.001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 1) (up to 1.3e-06 allowed)

======================================================================
FAIL: test_upsamplingNearest2d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10489, in test_upsamplingNearest2d_correctness
    helper(torch.contiguous_format, 20, 11)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10488, in helper
    self.assertEqual(out_t, expected_out)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 120 / 121 (99.2%)
Greatest absolute difference: 21.0 at index (0, 0, 1, 1) (up to 0.001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 1) (up to 1.3e-06 allowed)

======================================================================
FAIL: test_upsamplingNearest3d_correctness_xpu_xpu (__main__.TestNNDeviceTypeXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10569, in test_upsamplingNearest3d_correctness
    helper(torch.contiguous_format, 20, 11)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_nn.py", line 10568, in helper
    self.assertEqual(out_t, expected_out)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 1330 / 1331 (99.9%)
Greatest absolute difference: 421.0 at index (0, 0, 1, 1, 1) (up to 0.001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0, 1) (up to 1.3e-06 allowed)

----------------------------------------------------------------------
Ran 761 tests in 99.445s

FAILED (failures=12, errors=41, skipped=617)
Raised CalledProcessError: return code 1.