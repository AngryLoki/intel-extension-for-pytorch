MESA: warning: Driver does not support the 0xbd5 PCI ID.
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_proxy_tensor.py:123: UserWarning: Couldn't import torchvision. Some of our tests use it, try to install it with commands from pytorch.org, post-fixed with `--no-deps` to avoid overwriting the pytorch installation
  warnings.warn("Couldn't import torchvision. Some of our tests use it, try "
test_fake_H_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_T_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___getitem___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___radd___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___rand___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake___rdiv___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___rmatmul___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___rmod___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___rmul___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___ror___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake___rpow___xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
ok
test_fake___rsub___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake___rxor___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_abs_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_acos_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_acosh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addcdiv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addcmul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addmm_decomposed_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addmv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_addr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_all_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_allclose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_aminmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_angle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_any_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_arange_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_argmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_argmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_argsort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_argwhere_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_as_strided_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_as_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_asin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_asinh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atan2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atleast_1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atleast_2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_atleast_3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_H_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_T_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___getitem___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___radd___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rand___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rdiv___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rmatmul___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rmod___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rmul___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___ror___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rpow___xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_tensor.py:863: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(other, dtype=dtype, device=self.device) ** self
ok
test_fake_autocast___rsub___xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast___rxor___xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_abs_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_acos_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_acosh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addcdiv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addcmul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addmm_decomposed_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addmv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_addr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_all_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_allclose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_aminmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_autocast_angle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_any_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_arange_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_argmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_argmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_argsort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_argwhere_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_as_strided_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_as_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_asin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_asinh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atan2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atleast_1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atleast_2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_atleast_3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_baddbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bernoulli_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bfloat16_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bincount_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_and_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_left_shift_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_not_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_or_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_right_shift_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bitwise_xor_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_block_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bool_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_broadcast_shapes_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_broadcast_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_broadcast_to_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_bucketize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_byte_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cartesian_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cdist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ceil_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_chalf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_char_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cholesky_inverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_cholesky_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "not implemented: Could not run 'aten::linalg_cholesky_ex.L' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::linalg_cholesky_ex.L' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_1.cpp:21945 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_fake_autocast_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_chunk_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_clamp_max_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_clamp_min_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_clamp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_clone_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_column_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_combinations_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_conj_physical_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_constant_pad_nd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_contiguous_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_copysign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_corrcoef_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cos_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cosh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_count_nonzero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cov_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cummax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cummin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_cumulative_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_deg2rad_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diag_embed_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diagflat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diagonal_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diagonal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_diff_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_digamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_dist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_div_floor_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_div_no_rounding_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_div_trunc_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_double_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_dsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_dstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_einsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_empty_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_empty_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_eq_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_equal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_erf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_erfc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_erfinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_exp2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_expand_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_expand_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_expm1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_eye_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_fft_fft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_fft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_fftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_fftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_hfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_hfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_hfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ifft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ifft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ifftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ifftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ihfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ihfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_ihfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_irfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_irfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_irfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_rfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_rfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fft_rfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_autocast_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_flatten_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_flip_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_fliplr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_flipud_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_float_power_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_float_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_floor_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_floor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_fmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_fmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_fmod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_frac_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_frexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_full_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_gather_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_gcd_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ge_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_geqrf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_gradient_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_gt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_half_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_heaviside_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_histc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_histogram_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_histogramdd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_hsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_hstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_hypot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_igamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_igammac_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_imag_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_autocast_index_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_index_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_index_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_index_put_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_index_reduce_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_index_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_inner_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_int_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isclose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isfinite_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isinf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isnan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isneginf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isposinf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_isreal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_istft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_jiterator_2inputs_2outputs_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_autocast_jiterator_4inputs_with_extra_args_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_autocast_jiterator_binary_return_by_ref_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_autocast_jiterator_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_autocast_jiterator_unary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_autocast_kron_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_kthvalue_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lcm_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ldexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_le_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lerp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lgamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_cholesky_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_cond_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_det_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_det_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_eig_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_eigh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_eigvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_eigvalsh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_householder_product_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_inv_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_inv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_ldl_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_ldl_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_ldl_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "not implemented: Could not run 'aten::linalg_ldl_factor_ex.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::linalg_ldl_factor_ex.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_fake_autocast_linalg_lstsq_grad_oriented_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_lstsq_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_lu_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_lu_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_matrix_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_matrix_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_matrix_rank_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_matrix_rank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_multi_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_norm_subgradients_at_zero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_pinv_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_pinv_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/definitions/linalg.py:729: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at /home/gta/xunsongh/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  torch.rand(*batch, m, k, device=device, dtype=dtype)
ok
test_fake_autocast_linalg_pinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_slogdet_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_solve_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_solve_triangular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_svdvals_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_tensorinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_tensorsolve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_linalg_vander_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_vecdot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linalg_vector_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_linspace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log10_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log1p_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log_softmax_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_log_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logaddexp2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logcumsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logdet_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logical_and_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logical_not_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logical_or_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logical_xor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logspace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_long_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_lu_unpack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.
LU, pivots = torch.lu(A, compute_pivots)
should be replaced with
LU, pivots = torch.linalg.lu_factor(A, compute_pivots)
and
LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)
should be replaced with
LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at /home/gta/xunsongh/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)
  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))
FAIL
test_fake_autocast_mH_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mT_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_argmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_argmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_median_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_std_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_masked_var_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_matmul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_matrix_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_max_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_max_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_max_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_maximum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_median_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_meshgrid_list_of_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_meshgrid_variadic_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_min_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_min_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_min_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_minimum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_movedim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_msort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_multinomial_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_mv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_mvlgamma_mvlgamma_p_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_mvlgamma_mvlgamma_p_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_mvlgamma_mvlgamma_p_5_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nan_to_num_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nanmean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nanmedian_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nanquantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nansum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_narrow_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_narrow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_native_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_autocast_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... FAIL
test_fake_autocast_ne_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_new_empty_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_new_empty_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_new_full_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_new_ones_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_new_zeros_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nextafter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional__scaled_dot_product_attention_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_adaptive_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_binary_cross_entropy_with_logits_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_binary_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_celu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_conv1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_conv2d_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py:1068: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /home/gta/xunsongh/pytorch/aten/src/ATen/native/Convolution.cpp:895.)
  return self.op(*args, **kwargs)
ok
test_fake_autocast_nn_functional_conv_transpose1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_conv_transpose2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_conv_transpose3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_cosine_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_cosine_similarity_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_autocast_nn_functional_ctc_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nn_functional_dropout2d_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
ok
test_fake_autocast_nn_functional_dropout3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_dropout_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_elu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_embedding_bag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nn_functional_embedding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_feature_alpha_dropout_with_train_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_feature_alpha_dropout_without_train_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_fractional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_fractional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_gaussian_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_gelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_glu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_grid_sample_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_group_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_hardshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_hardsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_hardswish_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_hardtanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_hinge_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_huber_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_instance_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_area_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_bicubic_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_interpolate_trilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_kl_div_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
ok
test_fake_autocast_nn_functional_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_leaky_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_local_response_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_logsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_margin_ranking_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nn_functional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_max_unpool1d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_max_unpool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_autocast_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_autocast_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_autocast_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_autocast_nn_functional_mish_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_mse_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_multi_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_multilabel_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_multilabel_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nn_functional_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_one_hot_xpu_int64 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_nn_functional_pad_circular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pad_constant_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pad_reflect_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pad_replicate_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pairwise_distance_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pdist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pixel_shuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_pixel_unshuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_poisson_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_prelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_relu6_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_rrelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_selu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_silu_complex_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_autocast_nn_functional_silu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_smooth_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_softmin_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_softplus_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_softshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_softsign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_tanhshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_threshold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_triplet_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_triplet_margin_with_distance_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_nn_functional_upsample_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
ok
test_fake_autocast_nn_functional_upsample_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
ok
test_fake_autocast_nonzero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_norm_fro_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_norm_inf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_norm_nuc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_normal_number_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_normal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ones_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ones_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ormqr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_outer_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_pca_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_permute_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_pinverse_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polar_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polygamma_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polygamma_polygamma_n_1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polygamma_polygamma_n_2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polygamma_polygamma_n_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_polygamma_polygamma_n_4_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_positive_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_pow_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_put_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_quantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_rad2deg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_rand_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_randint_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_randn_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_randn_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_ravel_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_real_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_reciprocal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_remainder_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_renorm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_repeat_interleave_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_repeat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_reshape_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_reshape_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_resize__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_resize_as__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_resolve_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_resolve_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_roll_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_autocast_rot90_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_round_decimals_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_round_decimals_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_round_decimals_neg_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_round_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_rsqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_rsub_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_reduce_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_reduce_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_reduce_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_reduce_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_reduce_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_searchsorted_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py:1068: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/include/ATen/native/BucketizationUtils.h:35.)
  return self.op(*args, **kwargs)
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py:1068: UserWarning: torch.searchsorted(): boundary tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous boundary tensor if possible. This message will only appear once per program. (Triggered internally at /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/include/ATen/native/BucketizationUtils.h:41.)
  return self.op(*args, **kwargs)
ok
test_fake_autocast_segment_reduce_lengths_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_segment_reduce_offsets_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_select_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sgn_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_short_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_signbit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sinc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sinh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_slice_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_slice_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_softmax_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sparse_sampled_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_special_airy_ai_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_bessel_j0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_bessel_j1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_bessel_y0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_bessel_y1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_chebyshev_polynomial_t_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_chebyshev_polynomial_u_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_chebyshev_polynomial_v_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_chebyshev_polynomial_w_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_entr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_erfcx_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_hermite_polynomial_h_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_hermite_polynomial_he_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_i0e_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_i1e_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_laguerre_polynomial_l_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_legendre_polynomial_p_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_log_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_modified_bessel_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_modified_bessel_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_modified_bessel_k0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_modified_bessel_k1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_ndtri_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_polygamma_special_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_scaled_modified_bessel_k0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_scaled_modified_bessel_k1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_shifted_chebyshev_polynomial_t_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_shifted_chebyshev_polynomial_u_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_shifted_chebyshev_polynomial_v_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_shifted_chebyshev_polynomial_w_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_autocast_special_spherical_bessel_j0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_xlog1py_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_special_zeta_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_split_list_args_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_split_with_sizes_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_split_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_square_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_squeeze_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_std_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_std_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_stft_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at /home/gta/xunsongh/pytorch/aten/src/ATen/native/SpectralOps.cpp:801.)
  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]
ok
test_fake_autocast_sub_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sum_to_size_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_svd_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_symeig_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py:1068: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.
The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.
L, _ = torch.symeig(A, upper=upper)
should be replaced with
L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')
and
L, V = torch.symeig(A, eigenvectors=True)
should be replaced with
L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at /home/gta/xunsongh/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2794.)
  return self.op(*args, **kwargs)
ok
test_fake_autocast_t_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_take_along_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_take_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tensor_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_tensordot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tile_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_to_sparse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_autocast_to_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_topk_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_trace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_transpose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_trapz_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_triangular_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tril_indices_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_tril_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_triu_indices_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_triu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_true_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_trunc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unbind_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unflatten_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_uniform_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unique_consecutive_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unique_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_unsqueeze_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_var_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_var_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_vdot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_view_as_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_view_as_real_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_autocast_view_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_view_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_vsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_vstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_where_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_xlogy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_zero__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_zeros_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_autocast_zeros_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_baddbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bernoulli_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bfloat16_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bincount_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_and_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_left_shift_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_not_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_or_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_right_shift_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_bitwise_xor_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_block_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bmm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bool_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_broadcast_shapes_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_broadcast_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_broadcast_to_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_bucketize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_byte_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cartesian_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cdist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_ceil_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_chalf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_char_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cholesky_inverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_cholesky_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "not implemented: Could not run 'aten::linalg_cholesky_ex.L' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::linalg_cholesky_ex.L' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_1.cpp:21945 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_1.cpp:5089 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:16899 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_fake_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_chunk_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_clamp_max_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_clamp_min_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_clamp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_clone_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_column_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_combinations_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_conj_physical_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_constant_pad_nd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_contiguous_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_copysign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_corrcoef_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cos_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cosh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_count_nonzero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cov_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_crossref_backward_amp_H_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_T_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___getitem___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___radd___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rdiv___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rmatmul___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rmod___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rmul___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rpow___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp___rsub___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_abs_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_acos_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_acosh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addcdiv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addcmul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addmm_decomposed_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addmv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_addr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_angle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_as_strided_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_as_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_asin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_asinh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atan2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atan_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atleast_1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atleast_2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_atleast_3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_baddbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_bernoulli_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_bfloat16_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_block_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_bmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_broadcast_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_broadcast_to_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cartesian_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cdist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_ceil_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_chalf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cholesky_inverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cholesky_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_chunk_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_clamp_max_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_clamp_min_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_clamp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_clone_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_column_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_combinations_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_conj_physical_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_constant_pad_nd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_contiguous_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_copysign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_corrcoef_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cos_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cosh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cov_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cummax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cummin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_cumulative_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_deg2rad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diag_embed_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diagflat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diagonal_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diagonal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_diff_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_digamma_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_dist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_div_floor_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_div_no_rounding_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_div_trunc_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_double_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_dsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_dstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_einsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_erf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_erfc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_erfinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_exp2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_expand_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_expand_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_expm1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_fft_fft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_fft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_fftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_fftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_hfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_hfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_hfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ifft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ifft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ifftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ifftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ihfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ihfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_ihfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_irfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_irfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_irfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_rfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_rfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fft_rfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_amp_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_flatten_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_flip_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_fliplr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_flipud_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_float_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_float_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_floor_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_fmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_fmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_fmod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_frac_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_frexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_gather_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_gradient_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_half_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_hsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_hstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_hypot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_put_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_reduce_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_index_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_inner_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_istft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_kron_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_kthvalue_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_ldexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_lerp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_lgamma_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_cholesky_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_cond_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_det_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_det_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_eig_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_eigh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_eigvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_eigvalsh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_householder_product_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_inv_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_inv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lstsq_grad_oriented_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lstsq_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lu_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lu_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_matrix_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_matrix_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_multi_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_norm_subgradients_at_zero_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_pinv_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_linalg_pinv_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_linalg_pinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_linalg_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_slogdet_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_solve_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_solve_triangular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_svdvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_tensorinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_tensorsolve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_vander_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_vecdot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_linalg_vector_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log10_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log1p_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log_softmax_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_log_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logaddexp2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logcumsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logdet_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_lu_unpack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mH_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mT_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_median_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_std_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_masked_var_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_matmul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_matrix_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_max_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_max_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_max_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_maximum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_median_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_meshgrid_list_of_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_meshgrid_variadic_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_min_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_min_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_min_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_minimum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_movedim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_msort_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mvlgamma_mvlgamma_p_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mvlgamma_mvlgamma_p_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_mvlgamma_mvlgamma_p_5_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nan_to_num_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nanmean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nanmedian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nanquantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nansum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_narrow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_native_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional__scaled_dot_product_attention_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_adaptive_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_binary_cross_entropy_with_logits_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_binary_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_nn_functional_celu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_conv1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_conv2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_conv_transpose1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_conv_transpose2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_conv_transpose3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_cosine_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_cosine_similarity_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_ctc_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_nn_functional_dropout2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_dropout3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_dropout_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_elu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_embedding_bag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_embedding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_feature_alpha_dropout_with_train_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_feature_alpha_dropout_without_train_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_fractional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_fractional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_gaussian_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_gelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_glu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_grid_sample_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_group_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_hardshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_hardsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_hardswish_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_hardtanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_hinge_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_huber_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_instance_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_area_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_bicubic_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_interpolate_trilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_kl_div_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_leaky_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_local_response_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_logsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_margin_ranking_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool1d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_mish_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_mse_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_multi_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_multilabel_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_multilabel_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pad_circular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pad_constant_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pad_reflect_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pad_replicate_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pairwise_distance_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pdist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pixel_shuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_pixel_unshuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_poisson_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_prelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_relu6_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_rrelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_selu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_silu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_smooth_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_softmin_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_softplus_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_softshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_softsign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_tanhshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_threshold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_triplet_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_triplet_margin_with_distance_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_upsample_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_nn_functional_upsample_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_norm_fro_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_norm_inf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_norm_nuc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_normal_number_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_normal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_outer_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_pca_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_permute_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_pinverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_polar_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_polygamma_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_polygamma_polygamma_n_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_polygamma_polygamma_n_2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_polygamma_polygamma_n_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_polygamma_polygamma_n_4_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_positive_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_pow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_put_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_quantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_rad2deg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_ravel_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_real_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_reciprocal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_remainder_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_renorm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_repeat_interleave_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_repeat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_reshape_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_reshape_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_resolve_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_resolve_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_roll_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_crossref_backward_amp_rot90_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_round_decimals_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_round_decimals_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_round_decimals_neg_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_round_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_rsqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_rsub_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_reduce_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_reduce_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_reduce_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_reduce_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_reduce_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_segment_reduce_lengths_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_segment_reduce_offsets_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_select_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sgn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sinc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sinh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_slice_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_slice_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_softmax_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sort_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sparse_sampled_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_amp_special_entr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_erfcx_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_i0e_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_i1e_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_log_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_ndtri_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_polygamma_special_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_special_xlog1py_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_split_list_args_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_split_with_sizes_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_square_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_squeeze_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_std_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_std_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_stft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sub_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sum_to_size_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_svd_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_symeig_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_t_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_take_along_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_take_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tan_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tensor_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tensordot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_to_sparse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_to_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_topk_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_trace_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_transpose_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_trapz_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_triangular_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_tril_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_triu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_true_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_trunc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_unbind_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_unflatten_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_unsqueeze_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_var_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_var_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_vdot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_view_as_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_view_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_view_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_vsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_vstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_where_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_xlogy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_amp_zero__xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_H_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_T_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___getitem___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___radd___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rdiv___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rmatmul___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rmod___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rmul___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rpow___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp___rsub___xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_abs_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_acos_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_acosh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addcdiv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addcmul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addmm_decomposed_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addmv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_addr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_angle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_as_strided_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_as_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_asin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_asinh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atan2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atan_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atleast_1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atleast_2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_atleast_3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_baddbmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_bernoulli_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_bfloat16_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_block_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_bmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_broadcast_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_broadcast_to_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cartesian_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cdist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_ceil_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_chalf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cholesky_inverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cholesky_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_chunk_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_clamp_max_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_clamp_min_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_clamp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_clone_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_column_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_combinations_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_conj_physical_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_constant_pad_nd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_contiguous_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_copysign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_corrcoef_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cos_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cosh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cov_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cummax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cummin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_cumulative_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_deg2rad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diag_embed_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diagflat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diagonal_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diagonal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_diff_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_digamma_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_dist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_div_floor_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_div_no_rounding_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_div_trunc_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_double_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_dsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_dstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_einsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_erf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_erfc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_erfinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_exp2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_expand_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_expand_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_expm1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_fft_fft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_fft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_fftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_fftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_hfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_hfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_hfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ifft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ifft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ifftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ifftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ihfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ihfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_ihfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_irfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_irfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_irfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_rfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_rfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fft_rfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_crossref_backward_no_amp_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_flatten_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_flip_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_fliplr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_flipud_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_float_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_float_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_floor_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_fmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_fmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_fmod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_frac_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_frexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_gather_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_gradient_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_half_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_hsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_hstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_hypot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_put_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_reduce_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_index_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_inner_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_istft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_kron_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_kthvalue_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_ldexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_lerp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_lgamma_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_cholesky_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_cond_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_det_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_det_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_eig_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_eigh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_eigvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_eigvalsh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_householder_product_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_inv_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_inv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lstsq_grad_oriented_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lstsq_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lu_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lu_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_matrix_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_matrix_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_multi_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_norm_subgradients_at_zero_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_pinv_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_pinv_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_pinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_slogdet_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_solve_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_solve_triangular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_svdvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_tensorinv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_tensorsolve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_vander_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_vecdot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_linalg_vector_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log10_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log1p_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log_softmax_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_log_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logaddexp2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logcumsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logdet_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_lu_unpack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mH_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mT_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_median_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_std_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_masked_var_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_matmul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_matrix_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_max_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_max_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_max_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_maximum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_median_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_meshgrid_list_of_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_meshgrid_variadic_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_min_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_min_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_min_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_minimum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_movedim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_msort_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mul_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mv_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mvlgamma_mvlgamma_p_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mvlgamma_mvlgamma_p_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_mvlgamma_mvlgamma_p_5_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nan_to_num_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nanmean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nanmedian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nanquantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nansum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_narrow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_native_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional__scaled_dot_product_attention_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_adaptive_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_binary_cross_entropy_with_logits_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_binary_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_celu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_conv1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_conv2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_conv_transpose1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_conv_transpose2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_conv_transpose3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_cosine_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_cosine_similarity_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_ctc_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_crossref_backward_no_amp_nn_functional_dropout2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_dropout3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_dropout_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_elu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_embedding_bag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_embedding_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_feature_alpha_dropout_with_train_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_feature_alpha_dropout_without_train_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_fractional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_fractional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_gaussian_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_gelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_glu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_grid_sample_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_group_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_hardshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_hardsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_hardswish_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_hardtanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_hinge_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_huber_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_instance_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_area_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_bicubic_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_interpolate_trilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_kl_div_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_leaky_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_local_response_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_logsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_margin_ranking_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool1d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_mish_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_mse_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_multi_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_multilabel_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_multilabel_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pad_circular_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pad_constant_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pad_reflect_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pad_replicate_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pairwise_distance_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pdist_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pixel_shuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_pixel_unshuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_poisson_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_prelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_relu6_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_rrelu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_selu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_silu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_smooth_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_softmin_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_softplus_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_softshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_softsign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_tanhshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_threshold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_triplet_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_triplet_margin_with_distance_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_upsample_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_nn_functional_upsample_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_norm_fro_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_norm_inf_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_norm_nuc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_normal_number_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_normal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_outer_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_pca_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_permute_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_pinverse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polar_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polygamma_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polygamma_polygamma_n_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polygamma_polygamma_n_2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polygamma_polygamma_n_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_polygamma_polygamma_n_4_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_positive_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_pow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_put_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_quantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_rad2deg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_ravel_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_real_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_reciprocal_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_remainder_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_renorm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_repeat_interleave_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_repeat_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_reshape_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_reshape_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_resolve_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_resolve_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_roll_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_crossref_backward_no_amp_rot90_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_round_decimals_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_round_decimals_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_round_decimals_neg_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_round_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_rsqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_rsub_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_add_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_reduce_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_reduce_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_reduce_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_reduce_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_reduce_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_segment_reduce_lengths_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_segment_reduce_offsets_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_select_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_select_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sgn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sign_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sin_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sinc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sinh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_slice_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_slice_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_softmax_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sort_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sparse_sampled_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_entr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_erfcx_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_i0e_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_i1e_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_log_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_ndtri_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_polygamma_special_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_special_xlog1py_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_split_list_args_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_split_with_sizes_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_square_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_squeeze_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_std_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_std_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_stft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sub_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sum_to_size_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_svd_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_symeig_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_t_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_take_along_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_take_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tan_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tanh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tensor_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tensordot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_to_sparse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_to_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_topk_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_trace_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_transpose_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_trapz_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_triangular_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_tril_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_triu_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_true_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_trunc_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_unbind_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_unflatten_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_unsqueeze_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_var_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_var_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_vdot_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_view_as_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_view_as_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_view_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_vsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_vstack_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_where_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_xlogy_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_crossref_backward_no_amp_zero__xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_cummax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cummin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_cumulative_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_deg2rad_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diag_embed_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diag_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diagflat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diagonal_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diagonal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_diff_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_digamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_dist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_div_floor_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_div_no_rounding_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_div_trunc_rounding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_double_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_dsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_dstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_einsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_empty_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_empty_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_eq_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_equal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_erf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_erfc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_erfinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_exp2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_expand_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_expand_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_expm1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_eye_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_fft_fft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_fft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_fftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_fftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_hfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_hfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_hfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ifft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ifft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ifftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ifftshift_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ihfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ihfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_ihfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_irfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_irfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_irfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_rfft2_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_rfft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fft_rfftn_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "case has skip key and won't run on XPU"
test_fake_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_flatten_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_flip_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_fliplr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_flipud_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_float_power_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_float_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_floor_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_floor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_fmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_fmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_fmod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_frac_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_frexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_full_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_gather_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_gcd_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_ge_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_geqrf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_gradient_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_gt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_half_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_heaviside_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_histc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_histogram_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_histogramdd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_hsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_hstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_hypot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_igamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_igammac_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_imag_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_index_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_index_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_index_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_index_put_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_index_reduce_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_index_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_inner_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_int_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isclose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isfinite_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isinf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isnan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isneginf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isposinf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_isreal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_istft_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_jiterator_2inputs_2outputs_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_jiterator_4inputs_with_extra_args_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_jiterator_binary_return_by_ref_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_jiterator_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_jiterator_unary_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Only runs on cuda'
test_fake_kron_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_kthvalue_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lcm_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_ldexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_le_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lerp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lgamma_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_cholesky_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_cholesky_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_cond_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_cross_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_det_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_det_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_eig_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_eigh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_eigvals_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_eigvalsh_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_householder_product_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_inv_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_inv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_ldl_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_ldl_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_ldl_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "not implemented: Could not run 'aten::linalg_ldl_factor_ex.out' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::linalg_ldl_factor_ex.out' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nMeta: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterMeta.cpp:26815 [kernel]\nBackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterFunctionalization_2.cpp:20548 [kernel]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/ADInplaceOrViewType_0.cpp:4822 [kernel]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_0.cpp:16458 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_fake_linalg_lstsq_grad_oriented_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_lstsq_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_lu_factor_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_lu_factor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_matrix_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_matrix_power_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_matrix_rank_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_matrix_rank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_multi_dot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_norm_subgradients_at_zero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_pinv_hermitian_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_pinv_singular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_pinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_slogdet_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_solve_ex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_solve_triangular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_svdvals_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_tensorinv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_tensorsolve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_linalg_vander_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_vecdot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linalg_vector_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_linspace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log10_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log1p_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log_softmax_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_log_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logaddexp2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logcumsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logdet_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logical_and_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logical_not_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logical_or_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logical_xor_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logspace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_long_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lu_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_lu_unpack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_lu_xpu_float32 (__main__.TestFakeTensorXPU) ... FAIL
test_fake_mH_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mT_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_argmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_argmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_cumprod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_cumsum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_fill_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_log_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_logaddexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_logsumexp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_median_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_std_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_masked_var_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_matmul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_matrix_exp_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_max_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_max_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_max_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_maximum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_median_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_meshgrid_list_of_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_meshgrid_variadic_tensors_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_min_binary_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_min_reduction_no_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_min_reduction_with_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_minimum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mode_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_movedim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_msort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mul_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_multinomial_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_mv_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_mvlgamma_mvlgamma_p_1_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_mvlgamma_mvlgamma_p_3_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_mvlgamma_mvlgamma_p_5_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nan_to_num_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nanmean_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nanmedian_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nanquantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nansum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_narrow_copy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_narrow_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_native_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipped!'
test_fake_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... FAIL
test_fake_ne_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_new_empty_strided_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_new_empty_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_new_full_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_new_ones_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_new_zeros_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nextafter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional__scaled_dot_product_attention_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_adaptive_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_avg_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_avg_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_avg_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_batch_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_binary_cross_entropy_with_logits_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_binary_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_celu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_conv1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_conv2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_conv_transpose1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_conv_transpose2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_conv_transpose3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_cosine_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_cosine_similarity_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py:5540: DeprecationWarning: Sampling from a set deprecated
since Python 3.9 and will be removed in a subsequent version.
  target[0] = random.sample(set(range(num_classes)) - {kwargs["ignore_index"]}, 1)[0]
ERROR
test_fake_nn_functional_ctc_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nn_functional_dropout2d_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.
  warnings.warn("dropout2d: Received a 3D input to dropout2d and assuming that channel-wise "
ok
test_fake_nn_functional_dropout3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_dropout_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_elu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_embedding_bag_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nn_functional_embedding_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_feature_alpha_dropout_with_train_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_feature_alpha_dropout_without_train_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_fractional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_fractional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_gaussian_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_gelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_glu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_grid_sample_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_group_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_hardshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_hardsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_hardswish_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_hardtanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_hinge_embedding_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_huber_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_instance_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_area_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_bicubic_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_interpolate_trilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_kl_div_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:2916: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.
  warnings.warn(
ok
test_fake_nn_functional_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_leaky_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_linear_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_local_response_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_logsigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_margin_ranking_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_max_pool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nn_functional_max_pool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_max_pool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_max_unpool1d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_max_unpool1d_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU) ... ERROR
test_fake_nn_functional_mish_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_mse_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_multi_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_multilabel_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_multilabel_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nn_functional_normalize_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_one_hot_xpu_int64 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_nn_functional_pad_circular_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pad_constant_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pad_reflect_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pad_replicate_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pairwise_distance_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pdist_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pixel_shuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_pixel_unshuffle_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_poisson_nll_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_prelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_relu6_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_relu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_rrelu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_selu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_silu_complex_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_nn_functional_silu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_smooth_l1_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_soft_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_softmin_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_softmin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_softplus_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_softshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_softsign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_tanhshrink_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_threshold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_triplet_margin_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_triplet_margin_with_distance_loss_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_nn_functional_upsample_bilinear_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4070: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
ok
test_fake_nn_functional_upsample_nearest_xpu_float32 (__main__.TestFakeTensorXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py:4014: UserWarning: nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_nearest is deprecated. Use nn.functional.interpolate instead.")
ok
test_fake_nonzero_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_norm_fro_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_norm_inf_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_norm_nuc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_norm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_normal_number_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_normal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_ones_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_ones_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_ormqr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_outer_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_pca_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_permute_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_pinverse_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polar_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polygamma_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polygamma_polygamma_n_1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polygamma_polygamma_n_2_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polygamma_polygamma_n_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_polygamma_polygamma_n_4_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_positive_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_pow_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_put_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_qr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_quantile_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_rad2deg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_rand_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_randint_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_randn_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_randn_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_ravel_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_real_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_reciprocal_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_remainder_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_renorm_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_repeat_interleave_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_repeat_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_reshape_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_reshape_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_resize__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_resize_as__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_resolve_conj_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_resolve_neg_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_roll_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped "onlyNativeDeviceTypes: doesn't run on xpu"
test_fake_rot90_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_round_decimals_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_round_decimals_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_round_decimals_neg_3_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_round_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_rsqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_rsub_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_add_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_reduce_amax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_reduce_amin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_reduce_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_reduce_prod_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_reduce_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_searchsorted_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_segment_reduce_lengths_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_segment_reduce_offsets_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_select_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_select_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sgn_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_short_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sigmoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sign_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_signbit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sin_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sinc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sinh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_slice_scatter_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_slice_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_softmax_with_dtype_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_softmax_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sort_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sparse_sampled_addmm_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_special_airy_ai_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_bessel_j0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_bessel_j1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_bessel_y0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_bessel_y1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_chebyshev_polynomial_t_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_chebyshev_polynomial_u_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_chebyshev_polynomial_v_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_chebyshev_polynomial_w_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_entr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_erfcx_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_hermite_polynomial_h_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_hermite_polynomial_he_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_i0e_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_i1e_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_laguerre_polynomial_l_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_legendre_polynomial_p_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_log_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_modified_bessel_i0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_modified_bessel_i1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_modified_bessel_k0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_modified_bessel_k1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_ndtr_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_ndtri_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_polygamma_special_polygamma_n_0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_scaled_modified_bessel_k0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_scaled_modified_bessel_k1_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_shifted_chebyshev_polynomial_t_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_shifted_chebyshev_polynomial_u_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_shifted_chebyshev_polynomial_v_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_shifted_chebyshev_polynomial_w_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skipping - testing takes an unreasonably long time, #79528'
test_fake_special_spherical_bessel_j0_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_xlog1py_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_special_zeta_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_split_list_args_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_split_with_sizes_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_split_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sqrt_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_square_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_squeeze_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_stack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_std_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_std_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_stft_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sub_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sum_to_size_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_sum_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_svd_lowrank_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_svd_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_symeig_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_t_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_take_along_dim_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_take_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_tan_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_tanh_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_tensor_split_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_tensordot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_tile_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_to_sparse_xpu_float32 (__main__.TestFakeTensorXPU) ... skipped 'Skip failing test'
test_fake_to_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_topk_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_trace_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_transpose_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_trapezoid_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_trapz_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_triangular_solve_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_tril_indices_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_tril_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_triu_indices_xpu_int64 (__main__.TestFakeTensorXPU) ... ok
test_fake_triu_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_true_divide_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_trunc_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unbind_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unflatten_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unfold_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_uniform_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unique_consecutive_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unique_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_unsqueeze_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_var_mean_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_var_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_vdot_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_view_as_complex_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_view_as_real_xpu_complex64 (__main__.TestFakeTensorXPU) ... skipped 'dtype not support on XPU'
test_fake_view_as_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_view_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_vsplit_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_vstack_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_where_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_xlogy_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_zero__xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_zeros_like_xpu_float32 (__main__.TestFakeTensorXPU) ... ok
test_fake_zeros_xpu_float32 (__main__.TestFakeTensorXPU) ... ok

======================================================================
ERROR: test_fake_autocast_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 795, in __torch_dispatch__
    r = func(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_ops.py", line 257, in __call__
    return self._op(*args, **kwargs or {})
NotImplementedError: Could not run 'aten::nll_loss2d_forward' with arguments from the 'Meta' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::nll_loss2d_forward' is only available for these backends: [CPU, XPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].

CPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]
XPU: registered at /home/gta/xunsongh/ipex-gpu/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:10022 [kernel]
BackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]
Functionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]
Named: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]
Negative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]
AutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
Tracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]
AutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]
AutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]
AutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]
FuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/BatchRulesLoss.cpp:279 [kernel]
FuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]
Batched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]
VmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]
PythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]
PythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 879, in _test_fake_helper
    res_fake = op(input, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py", line 1068, in __call__
    return self.op(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/utils/_python_dispatch.py", line 101, in __torch_dispatch__
    return old.__torch_dispatch__(func, types, args, kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 800, in __torch_dispatch__
    return run_fallback_kernel(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 923, in run_fallback_kernel
    r = func(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_ops.py", line 257, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: bad optional access

======================================================================
ERROR: test_fake_autocast_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 64, in generator_context
    response = gen.send(request)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7646, in sample_inputs_max_unpool_grad
    for sample in sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 757, in max_pool2d_with_indices
    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: expected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[]

======================================================================
ERROR: test_fake_autocast_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 64, in generator_context
    response = gen.send(request)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 757, in max_pool2d_with_indices
    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: expected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[]

======================================================================
ERROR: test_fake_autocast_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 43, in generator_context
    response = gen.send(None)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7646, in sample_inputs_max_unpool_grad
    for sample in sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 843, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: could not create a descriptor for a pooling forward propagation primitive

======================================================================
ERROR: test_fake_autocast_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 43, in generator_context
    response = gen.send(None)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 843, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: could not create a descriptor for a pooling forward propagation primitive

======================================================================
ERROR: test_fake_nn_functional_cross_entropy_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 795, in __torch_dispatch__
    r = func(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_ops.py", line 257, in __call__
    return self._op(*args, **kwargs or {})
NotImplementedError: Could not run 'aten::nll_loss2d_forward' with arguments from the 'Meta' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::nll_loss2d_forward' is only available for these backends: [CPU, XPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].

CPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]
XPU: registered at /home/gta/xunsongh/ipex-gpu/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:10022 [kernel]
BackendSelect: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]
Python: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]
FuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]
Functionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]
Named: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]
Conjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]
Negative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]
ZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]
ADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]
AutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
AutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:14538 [autograd kernel]
Tracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:15586 [kernel]
AutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]
AutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]
AutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]
FuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/BatchRulesLoss.cpp:279 [kernel]
FuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]
Batched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]
VmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]
FuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]
PythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]
FuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]
PythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 879, in _test_fake_helper
    res_fake = op(input, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/opinfo/core.py", line 1068, in __call__
    return self.op(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/utils/_python_dispatch.py", line 101, in __torch_dispatch__
    return old.__torch_dispatch__(func, types, args, kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 800, in __torch_dispatch__
    return run_fallback_kernel(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_subclasses/fake_tensor.py", line 923, in run_fallback_kernel
    r = func(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_ops.py", line 257, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: bad optional access

======================================================================
ERROR: test_fake_nn_functional_max_unpool2d_grad_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 64, in generator_context
    response = gen.send(request)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7646, in sample_inputs_max_unpool_grad
    for sample in sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 757, in max_pool2d_with_indices
    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: expected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[]

======================================================================
ERROR: test_fake_nn_functional_max_unpool2d_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 64, in generator_context
    response = gen.send(request)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 757, in max_pool2d_with_indices
    return torch._C._nn.max_pool2d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: expected stride to be a single integer value or a list of 2 values to match the convolution dimensions, but got stride=[]

======================================================================
ERROR: test_fake_nn_functional_max_unpool3d_grad_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 43, in generator_context
    response = gen.send(None)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7646, in sample_inputs_max_unpool_grad
    for sample in sample_inputs_max_unpool(op_info, device, dtype, requires_grad, **kwargs):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 843, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: could not create a descriptor for a pooling forward propagation primitive

======================================================================
ERROR: test_fake_nn_functional_max_unpool3d_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 860, in _test_fake_helper
    for sample in samples:
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/grad_mode.py", line 43, in generator_context
    response = gen.send(None)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_methods_invocations.py", line 7630, in sample_inputs_max_unpool
    pool, indices = pool_method(sample.input, **sample.kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 483, in fn
    return if_true(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 843, in max_pool3d_with_indices
    return torch._C._nn.max_pool3d_with_indices(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: could not create a descriptor for a pooling forward propagation primitive

======================================================================
FAIL: test_fake_autocast_lu_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 886, in _test_fake_helper
    prims.utils.compare_tensor_meta(fake_out, real_out, check_strides)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_prims_common/__init__.py", line 123, in compare_tensor_meta
    raise AssertionError(msg)
AssertionError: Devices xpu:0 and cpu are not equal!

======================================================================
FAIL: test_fake_autocast_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 908, in test_fake_autocast
    self._test_fake_helper(device, dtype, op, context)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 886, in _test_fake_helper
    prims.utils.compare_tensor_meta(fake_out, real_out, check_strides)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_prims_common/__init__.py", line 108, in compare_tensor_meta
    raise AssertionError(msg)
AssertionError: Shapes torch.Size([1, 1, 1]) and torch.Size([1, 1]) are not equal!

======================================================================
FAIL: test_fake_lu_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 886, in _test_fake_helper
    prims.utils.compare_tensor_meta(fake_out, real_out, check_strides)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_prims_common/__init__.py", line 123, in compare_tensor_meta
    raise AssertionError(msg)
AssertionError: Devices xpu:0 and cpu are not equal!

======================================================================
FAIL: test_fake_native_layer_norm_xpu_float32 (__main__.TestFakeTensorXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 815, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 901, in test_fake
    self._test_fake_helper(device, dtype, op, contextlib.nullcontext)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_ops.py", line 886, in _test_fake_helper
    prims.utils.compare_tensor_meta(fake_out, real_out, check_strides)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_prims_common/__init__.py", line 108, in compare_tensor_meta
    raise AssertionError(msg)
AssertionError: Shapes torch.Size([1, 1, 1]) and torch.Size([1, 1]) are not equal!

----------------------------------------------------------------------
Ran 2218 tests in 212.283s

FAILED (failures=4, errors=10, skipped=1118)
Raised CalledProcessError: return code 1.