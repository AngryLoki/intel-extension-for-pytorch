MESA: warning: Driver does not support the 0xbd5 PCI ID.
No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'
test_check_inplace_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_check_inplace_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_cpu_gpu_parity_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_cpu_gpu_parity_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_cpu_gpu_parity_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_cpu_gpu_parity_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_factory_kwargs_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_factory_kwargs_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ok
test_factory_kwargs_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_factory_kwargs_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'not ready on XPU'
test_forward_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_forward_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_forward_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_forward_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_forward_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_grad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped "not implemented: Could not run 'aten::_efficientzerotensor' with arguments from the 'XPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_efficientzerotensor' is only available for these backends: [CPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30798 [kernel]\nBackendSelect: registered at /home/gta/xunsongh/pytorch/build/aten/src/ATen/RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:140 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:488 [backend fallback]\nFunctionalize: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:291 [backend fallback]\nNamed: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradCPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradCUDA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradHIP: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradXLA: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradMPS: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradIPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradXPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradHPU: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradVE: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradLazy: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradMeta: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse1: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse2: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradPrivateUse3: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nAutogradNestedTensor: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/VariableType_4.cpp:14624 [autograd kernel]\nTracer: registered at /home/gta/xunsongh/pytorch/torch/csrc/autograd/generated/TraceType_4.cpp:12871 [kernel]\nAutocastCPU: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:482 [backend fallback]\nAutocastXPU: fallthrough registered at /home/gta/xunsongh/ipex-gpu/csrc/gpu/aten/amp/autocast_mode.cpp:233 [backend fallback]\nAutocastCUDA: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nFuncTorchBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:743 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/BatchingRegistrations.cpp:1064 [backend fallback]\nVmapMode: fallthrough registered at /home/gta/xunsongh/pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:189 [backend fallback]\nPythonTLSSnapshot: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:484 [backend fallback]\nPythonDispatcher: registered at /home/gta/xunsongh/pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\n"
test_gradgrad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ERROR
test_gradgrad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_gradgrad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_BatchNorm2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_BatchNorm3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GRU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTM_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LSTM_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... /home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
ok
test_if_train_and_eval_modes_differ_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_MultiheadAttention_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_MultiheadAttention_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNN_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_RNN_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_memory_format_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_memory_format_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_memory_format_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... expected failure
test_memory_format_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_memory_format_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_memory_format_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_multiple_device_transfer_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_multiple_device_transfer_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Only runs on cuda'
test_non_contiguous_tensors_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_non_contiguous_tensors_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'Skipped!'
test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_non_contiguous_tensors_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... FAIL
test_non_contiguous_tensors_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... skipped 'not ready on XPU'
test_pickle_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_pickle_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_pickle_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_pickle_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ERROR
test_pickle_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ERROR
test_repr_ao_nn_quantized_MaxPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose1d_xpu_complex128 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_complex32 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_complex64 (__main__.TestModuleXPU) ... skipped 'dtype not support on XPU'
test_repr_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ELU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ELU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Embedding_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Embedding_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Linear_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Linear_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_ReLU_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_ReLU_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU) ... ok
test_repr_nn_Transformer_xpu_float32 (__main__.TestModuleXPU) ... ok
test_repr_nn_Transformer_xpu_float64 (__main__.TestModuleXPU) ... ok

======================================================================
ERROR: test_forward_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_forward_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_forward_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_forward_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_forward_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_forward_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_forward_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_forward_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 46, in test_forward
    outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_grad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0.6870, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.5000, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 3.6375,  3.7630, -2.8754,  2.8994,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 3.7571, -1.8752, -0.2516,  0.4656,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0921, -1.4426,  0.1159, -1.5115,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -4.1754, -3.9992,  2.5017, -2.3922,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.1296, -0.0986,  2.6508,  1.8550,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.9601,  1.5494, -1.8189,  0.9605,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0772, -0.0854,  0.0749, -0.0778,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.1351,  0.0789, -0.0357, -0.0514,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0379,  0.0325,  0.0269,  0.0455,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -1.9702, -1.4688,  0.1367,  0.0939,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  3.6255, -2.9874,  4.3366,  3.9971,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -3.6238,  0.5919, -3.0607, -0.5585,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          5.1768,  5.0564, -3.3459,  3.2521,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          2.3736, -0.5659, -2.5646, -1.5696,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          1.7988, -1.9536,  1.7399, -1.4277,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -1.8830, -1.2773, -0.1850,  0.4595,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  4.7227, -3.7446,  5.0780,  4.7643,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -4.2797,  0.5236, -3.5914, -0.8397,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.1337,  0.4009, -1.2397,  1.4694,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          5.2219, -3.7217,  3.9866,  4.0066,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -3.4753, -0.1264, -2.8430, -1.2485,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.1866,  0.5314, -0.9916,  1.1376],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  3.5558, -2.4746,  2.4827,  2.5485],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -2.1874, -0.1866, -1.7752, -0.8957]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 3.6375,  3.7630, -2.8754,  2.8994,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 3.7571, -1.8752, -0.2516,  0.4656,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0921, -1.4426,  0.1159, -1.5115,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -4.1754, -3.9992,  2.5017, -2.3922,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.1296, -0.0986,  2.6508,  1.8550,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000, -1.9601,  1.5494, -1.8189,  0.9605,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0772, -0.0854,  0.0749, -0.0778,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.1351,  0.0789, -0.0357, -0.0514,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0379,  0.0325,  0.0269,  0.0455,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -1.9702, -1.4688,  0.1367,  0.0939,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  3.6255, -2.9874,  4.3366,  3.9971,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -3.6238,  0.5919, -3.0607, -0.5585,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          5.1768,  5.0564, -3.3459,  3.2521,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          2.3736, -0.5659, -2.5646, -1.5696,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          1.7988, -1.9536,  1.7399, -1.4277,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -1.8830, -1.2773, -0.1850,  0.4595,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  4.7227, -3.7446,  5.0780,  4.7643,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -4.2797,  0.5236, -3.5914, -0.8397,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.1337,  0.4009, -1.2397,  1.4694,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          5.2219, -3.7217,  3.9866,  4.0066,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -3.4753, -0.1264, -2.8430, -1.2485,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.1866,  0.5314, -0.9916,  1.1376],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  3.5558, -2.4746,  2.4827,  2.5485],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000,  0.0000,  0.0000, -2.1874, -0.1866, -1.7752, -0.8957]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 3.90354415458205e-12.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_grad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0130, device='xpu:0', dtype=torch.float64)
analytical:tensor(6.6132, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.2719,  0.1587,  0.2693,  0.1984,  0.2216,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0566,  0.1852,  0.1385, -0.0424,  0.1780,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.1387, -0.1274, -0.0279,  0.2634,  0.1460,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0770,  0.1049, -0.0140, -0.2442,  0.2303,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2550, -0.1249,  0.1641, -0.0515,  0.1062,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1158,  0.0905, -0.2006, -0.2879,  0.1535,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2588, -0.1508,  0.0960,  0.0239,  0.2396,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0184,  0.1335, -0.0957,  0.0819, -0.0582,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1003,  0.0584,  0.1670, -0.1169, -0.2251,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0973, -0.1130, -0.1030,  0.1199, -0.1420,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1638, -0.1416,  0.0143, -0.0468, -0.0385,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0364,  0.0747,  0.0975, -0.2509, -0.0317,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2719,  0.1587,  0.2693,
          0.1984,  0.2216],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0566,  0.1852,  0.1385,
         -0.0424,  0.1780],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1387, -0.1274, -0.0279,
          0.2634,  0.1460],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0770,  0.1049, -0.0140,
         -0.2442,  0.2303],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2550, -0.1249,  0.1641,
         -0.0515,  0.1062],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1158,  0.0905, -0.2006,
         -0.2879,  0.1535],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2588, -0.1508,  0.0960,
          0.0239,  0.2396],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0184,  0.1335, -0.0957,
          0.0819, -0.0582],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1003,  0.0584,  0.1670,
         -0.1169, -0.2251],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0973, -0.1130, -0.1030,
          0.1199, -0.1420],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1638, -0.1416,  0.0143,
         -0.0468, -0.0385],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0364,  0.0747,  0.0975,
         -0.2509, -0.0317]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.2719,  0.1587,  0.2693,  0.1984,  0.2216,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0566,  0.1852,  0.1385, -0.0424,  0.1780,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.1387, -0.1274, -0.0279,  0.2634,  0.1460,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0770,  0.1049, -0.0140, -0.2442,  0.2303,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2550, -0.1249,  0.1641, -0.0515,  0.1062,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1158,  0.0905, -0.2006, -0.2879,  0.1535,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.2588, -0.1508,  0.0960,  0.0239,  0.2396,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0184,  0.1335, -0.0957,  0.0819, -0.0582,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1003,  0.0584,  0.1670, -0.1169, -0.2251,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [-0.0973, -0.1130, -0.1030,  0.1199, -0.1420,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.1638, -0.1416,  0.0143, -0.0468, -0.0385,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0364,  0.0747,  0.0975, -0.2509, -0.0317,  0.0000,  0.0000,  0.0000,
          0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2719,  0.1587,  0.2693,
          0.1984,  0.2216],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0566,  0.1852,  0.1385,
         -0.0424,  0.1780],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1387, -0.1274, -0.0279,
          0.2634,  0.1460],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0770,  0.1049, -0.0140,
         -0.2442,  0.2303],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2550, -0.1249,  0.1641,
         -0.0515,  0.1062],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1158,  0.0905, -0.2006,
         -0.2879,  0.1535],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2588, -0.1508,  0.0960,
          0.0239,  0.2396],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0184,  0.1335, -0.0957,
          0.0819, -0.0582],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1003,  0.0584,  0.1670,
         -0.1169, -0.2251],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0973, -0.1130, -0.1030,
          0.1199, -0.1420],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1638, -0.1416,  0.0143,
         -0.0468, -0.0385],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0364,  0.0747,  0.0975,
         -0.2509, -0.0317]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 3.552713678800501e-13.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_grad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0061, device='xpu:0', dtype=torch.float64)
analytical:tensor(2.9917, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.1570,  0.0000,  0.1145,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0327, -0.1570, -0.0245,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0801, -0.0327,  0.1520,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.1071, -0.0976, -0.0949],
        [ 0.0000,  0.0000,  0.0000,  ..., -0.0501, -0.0081, -0.0976],
        [ 0.0000,  0.0000,  0.0000,  ..., -0.0339,  0.0000, -0.0081]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0004,  0.0004,  0.0004,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0001,  0.0001,  0.0001,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0016, -0.0016, -0.0016,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [-0.0018, -0.0018, -0.0018,  ..., -0.0501, -0.0501, -0.0949],
        [-0.0017, -0.0017, -0.0017,  ..., -0.0339, -0.0339, -0.0976],
        [-0.0001, -0.0001, -0.0001,  ...,  0.0000,  0.0000, -0.0081]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.28699785470971406.


======================================================================
ERROR: test_grad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0715, device='xpu:0', dtype=torch.float64)
analytical:tensor(571.4054, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0906,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0189, -0.0906,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0462, -0.0189, -0.0906,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0624, -0.0627, -0.0023],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0624, -0.0627],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0624]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.2008,  0.0000,  0.2008,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0260,  0.0000,  0.0260,  ...,  0.0000,  0.0000,  0.0000],
        [-0.3063,  0.0000, -0.3063,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.8585,  0.0000,  0.8585,  ...,  0.0624, -0.0627, -0.0023],
        [ 0.4021,  0.0000,  0.4021,  ...,  0.0000,  0.0624, -0.0627],
        [-0.8195,  0.0000, -0.8195,  ...,  0.0000,  0.0000,  0.0624]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 2.0943133756517547.


======================================================================
ERROR: test_grad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_grad_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.4712, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[9.6868e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 3.8107e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8874e-02, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.1300e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4976e-02, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 6.5911e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5440e-04, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         3.5642e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 4.1302e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5655e-03, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         8.5137e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 3.5125e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3130e-01]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8874e-02, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.1300e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4976e-02, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 6.5911e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5440e-04, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         3.5642e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 4.1302e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5655e-03, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         8.5137e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 3.5125e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3130e-01]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.9999999999994458.


======================================================================
ERROR: test_grad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.8689, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0000000000000009.


======================================================================
ERROR: test_grad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0034, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0100,  0.0231,  0.0074,  0.0304],
        [-0.0201,  0.0030, -0.0261,  0.0052],
        [ 0.0000,  0.0000,  0.0102, -0.0006],
        [ 0.0000,  0.0000, -0.0070, -0.0009]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.03037148068896255.


======================================================================
ERROR: test_grad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0084, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0546,  0.0282, -0.0554,  0.0303],
        [ 0.0022,  0.0048,  0.0025,  0.0043],
        [ 0.0000,  0.0000,  0.0125,  0.0077],
        [ 0.0000,  0.0000, -0.0210,  0.0015]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.055387167024273376.


======================================================================
ERROR: test_grad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.2152, device='xpu:0', dtype=torch.float64)
analytical:tensor(-1.7827, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.7995],
        [ 0.8660],
        [-0.9924]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-3.5197],
        [ 3.8126],
        [-4.3691]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 3.376694475022907.


======================================================================
ERROR: test_grad_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0320, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.2405,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.0747,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  1.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[  0.0000, -10.5614,   0.0000, -10.5614],
        [ -0.0000,  11.4404,  -0.0000,  11.4404],
        [  0.0000, -13.1103,   0.0000, -13.1103],
        [  0.0000,   0.0000,   0.0000,   0.0000]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 13.110311596791444.


======================================================================
ERROR: test_grad_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0.0095, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.1758, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0417],
        [ 0.0417],
        [-0.0417],
        [-0.0417],
        [ 0.0417],
        [ 0.0417],
        [ 0.0417],
        [-0.0417],
        [ 0.0417],
        [-0.0417],
        [-0.0417],
        [ 0.0417],
        [ 0.0417],
        [ 0.0417],
        [ 0.0417],
        [ 0.0417],
        [-0.0417],
        [-0.0417],
        [ 0.0417],
        [-0.0417],
        [-0.0417],
        [-0.0417],
        [-0.0417],
        [-0.0417]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626],
        [-0.5626]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.6042228206857696.


======================================================================
ERROR: test_grad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 6,
numerical:tensor(-0.0448, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-1.5607e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -9.6286e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -2.2439e-08,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5102e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7469e-07,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          7.4363e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -8.2668e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.6143e-02,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7365e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4114e-08],
        [-4.8250e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -1.4138e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.2139e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6205e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1633e-06,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0509e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.7004e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  4.5348e-02,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5169e-01,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3424e-07],
        [ 1.5624e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  4.0570e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  3.2073e-11,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4333e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5446e-09,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.4135e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0635e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  3.7553e-03,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  9.3944e-05,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2133e-07],
        [-1.8908e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -1.6435e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.4771e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1189e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3966e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.9587e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -4.7398e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  1.4558e-01,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0505e-01,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.3395e-02]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-1.5607e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -9.6286e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00, -2.2439e-08,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5102e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.7469e-07,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          7.4363e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -8.2668e-05,  0.0000e+00, -8.2668e-05,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-4.8250e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -1.4138e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.2139e-05,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.6205e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.1633e-06,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.0509e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.7004e-04,  0.0000e+00, -1.7004e-04,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.5624e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  4.0570e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  3.2074e-11,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.4333e-02,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.5447e-09,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.4135e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  1.0635e-04,  0.0000e+00,  1.0635e-04,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.8908e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, -1.6435e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  2.4771e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.1189e-04,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3966e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.9587e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -4.7398e-02,  0.0000e+00, -4.7398e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.15168996028552817.


======================================================================
ERROR: test_grad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0035, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0044, -0.0040,  0.0056, -0.0056, -0.0038,  0.0070],
        [-0.0033, -0.0030,  0.0042, -0.0038, -0.0025,  0.0046],
        [ 0.0000,  0.0000,  0.0000, -0.0008, -0.0006,  0.0014],
        [ 0.0000,  0.0000,  0.0000, -0.0044, -0.0039,  0.0052]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.006984351709635184.


======================================================================
ERROR: test_grad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0007, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0100,  0.0088, -0.0131,  0.0130,  0.0081, -0.0119],
        [-0.0108, -0.0098,  0.0139, -0.0087, -0.0056,  0.0094],
        [ 0.0000,  0.0000,  0.0000,  0.0255,  0.0102, -0.0135],
        [ 0.0000,  0.0000,  0.0000,  0.0044,  0.0052, -0.0042]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0100,  0.0000, -0.0131,  0.0000,  0.0000],
        [ 0.0000, -0.0108,  0.0000,  0.0139,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.02609424148414239.


======================================================================
ERROR: test_grad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.1341, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0010, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-5.3657e-02,  6.7551e-02, -1.6012e-01,  8.7329e-02,  1.1725e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.9790e-01, -1.7783e-01, -1.6600e-01, -2.3316e-01, -2.8103e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.7195e-01,  2.8698e-01, -1.8026e-01, -1.6827e-01, -1.7741e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.8470e-01,  2.6193e-01, -1.6903e-01, -2.0246e-01,  2.4507e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 2.8133e-01, -1.6484e-01, -1.0555e-01, -2.1353e-01, -2.5212e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 3.3972e-02, -2.2265e-04,  1.1179e-01, -1.0233e-01, -2.7338e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.2869e-01,  8.1773e-02,  2.1524e-01,  1.1378e-01,  1.1329e-02,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-6.4629e-02,  4.3866e-02,  1.8052e-01, -1.1206e-01,  1.2739e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.9742e-01,  4.4466e-02, -4.6778e-02, -2.4178e-01, -2.0562e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-7.4221e-02,  2.2483e-01, -3.4274e-02,  1.3423e-01, -2.7038e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 2.3338e-01,  8.2562e-03, -1.3860e-01, -1.2294e-01,  2.0038e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.5689e-01, -9.9783e-02, -3.5836e-02,  9.1243e-02,  2.0502e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -5.3657e-02,  6.7551e-02, -1.6012e-01,  8.7329e-02,  1.1725e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.9790e-01, -1.7783e-01, -1.6600e-01, -2.3316e-01, -2.8103e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.7195e-01,  2.8698e-01, -1.8026e-01, -1.6827e-01, -1.7741e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.8470e-01,  2.6193e-01, -1.6903e-01, -2.0246e-01,  2.4507e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.8133e-01, -1.6484e-01, -1.0555e-01, -2.1353e-01, -2.5212e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          3.3972e-02, -2.2265e-04,  1.1179e-01, -1.0233e-01, -2.7338e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.2869e-01,  8.1773e-02,  2.1524e-01,  1.1378e-01,  1.1329e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -6.4629e-02,  4.3866e-02,  1.8052e-01, -1.1206e-01,  1.2739e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.9742e-01,  4.4466e-02, -4.6778e-02, -2.4178e-01, -2.0562e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -7.4221e-02,  2.2483e-01, -3.4274e-02,  1.3423e-01, -2.7038e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.3338e-01,  8.2562e-03, -1.3860e-01, -1.2294e-01,  2.0038e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.5689e-01, -9.9783e-02, -3.5836e-02,  9.1243e-02,  2.0502e-01]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-5.3657e-02,  6.7551e-02, -1.6012e-01,  8.7329e-02,  1.1725e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.9790e-01, -1.7783e-01, -1.6600e-01, -2.3316e-01, -2.8103e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.7195e-01,  2.8698e-01, -1.8026e-01, -1.6827e-01, -1.7741e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.8470e-01,  2.6193e-01, -1.6903e-01, -2.0246e-01,  2.4507e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 2.8133e-01, -1.6484e-01, -1.0555e-01, -2.1353e-01, -2.5212e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 3.3972e-02, -2.2265e-04,  1.1179e-01, -1.0233e-01, -2.7338e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.2869e-01,  8.1773e-02,  2.1524e-01,  1.1378e-01,  1.1329e-02,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-6.4629e-02,  4.3866e-02,  1.8052e-01, -1.1206e-01,  1.2739e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.9742e-01,  4.4466e-02, -4.6778e-02, -2.4178e-01, -2.0562e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-7.4221e-02,  2.2483e-01, -3.4274e-02,  1.3423e-01, -2.7038e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 2.3338e-01,  8.2562e-03, -1.3860e-01, -1.2294e-01,  2.0038e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.5689e-01, -9.9783e-02, -3.5836e-02,  9.1243e-02,  2.0502e-01,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -5.3657e-02,  6.7551e-02, -1.6012e-01,  8.7329e-02,  1.1725e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.9790e-01, -1.7783e-01, -1.6600e-01, -2.3316e-01, -2.8103e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.7195e-01,  2.8698e-01, -1.8026e-01, -1.6827e-01, -1.7741e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.8470e-01,  2.6193e-01, -1.6903e-01, -2.0246e-01,  2.4507e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.8133e-01, -1.6484e-01, -1.0555e-01, -2.1353e-01, -2.5212e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          3.3972e-02, -2.2265e-04,  1.1179e-01, -1.0233e-01, -2.7338e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.2869e-01,  8.1773e-02,  2.1524e-01,  1.1378e-01,  1.1329e-02],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -6.4629e-02,  4.3866e-02,  1.8052e-01, -1.1206e-01,  1.2739e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          1.9742e-01,  4.4466e-02, -4.6778e-02, -2.4178e-01, -2.0562e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -7.4221e-02,  2.2483e-01, -3.4274e-02,  1.3423e-01, -2.7038e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          2.3338e-01,  8.2562e-03, -1.3860e-01, -1.2294e-01,  2.0038e-01],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         -1.5689e-01, -9.9783e-02, -3.5836e-02,  9.1243e-02,  2.0502e-01]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.2211227584657536e-08.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_grad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0587, device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0895, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0895,  0.0000,  0.1169,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0733, -0.0895, -0.1523,  ...,  0.0000,  0.0000,  0.0000],
        [-0.1576,  0.0733, -0.1137,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0062, -0.0950,  0.0904],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0998,  0.0783, -0.0950],
        [ 0.0000,  0.0000,  0.0000,  ..., -0.0872,  0.0000,  0.0783]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.0018, -0.0895, -0.0895,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0028,  0.0733,  0.0733,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0011, -0.1576, -0.1576,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0007,  0.0000,  0.0000,  ..., -0.1346, -0.1346, -0.0950],
        [-0.0008,  0.0000,  0.0000,  ...,  0.0011,  0.0011,  0.0783],
        [ 0.0008,  0.0000,  0.0000,  ..., -0.1282, -0.1282,  0.0000]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.30679367484080444.


======================================================================
ERROR: test_grad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.0788, device='xpu:0', dtype=torch.float64)
analytical:tensor(3.0334, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0148,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0787,  0.0148,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0563,  0.0787,  0.0148,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0618, -0.0937, -0.0468],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0618, -0.0937],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0618]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0148,  0.0000,  0.0148,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0787,  0.0000,  0.0787,  ...,  0.0000,  0.0000,  0.0000],
        [-0.0563,  0.0000, -0.0563,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0618, -0.0937, -0.0468],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0618, -0.0937],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0618]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.15497598127821277.


======================================================================
ERROR: test_grad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[-1.4705e+00,  1.3233e+01,  1.3471e+01, -7.8232e+00, -6.0192e+00,
           6.1447e+00,  1.6348e+01, -2.0204e+00, -8.9886e-01, -1.7722e+00],
         [ 8.0434e+00,  9.3397e+00,  2.5107e-01, -3.9567e+00, -2.9967e+00,
           1.9015e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.9633e-01,
           1.6254e+00,  2.0100e+00,  6.3849e-02, -2.1874e+00,  2.9663e+00],
         [ 7.7898e-01, -2.6478e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],

        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
           0.0000e+00,  0.0000e+00,  0.0000e+00, -6.8001e-02,  6.9621e-02],
         [-5.8937e-02,  0.0000e+00,  0.0000e+00,  5.3911e-02, -5.2945e-03,
           9.4094e-02,  0.0000e+00,  0.0000e+00,  2.7606e-02, -1.1718e-02],
         [ 2.4715e-02,  4.2758e-02, -4.2714e-03,  6.1380e-02, -6.3840e-02,
          -7.0579e-02,  2.5402e-02, -5.5817e-03,  2.0324e-02, -4.3318e-02],
         [ 1.8047e-02,  7.0435e-03,  2.5035e-02,  5.6059e-02, -5.0952e-03,
          -8.6576e-02,  1.0367e-01, -7.9012e-02,  6.9331e-01,  1.2278e+00],
         [ 8.7639e-01,  4.7391e-01, -3.2908e-01,  3.1777e+00, -3.4375e+00,
           5.7641e-01, -3.7737e-01, -1.6333e+00,  7.7814e+03, -2.8905e+04]]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[ 1.4833e+00, -1.9709e+00,  1.3401e-01,  4.4803e+00,  2.9936e-01,
           2.9119e+00,  6.3635e+00,  3.1799e+00, -4.6012e+00,  6.5084e+00],
         [-1.6415e+01, -1.1991e+01, -1.1108e+01,  2.0097e+01, -9.3779e+00,
           8.1220e+00,  1.6193e+01,  1.0438e+00, -4.4893e+00, -3.7451e-01],
         [-5.6569e+00,  2.5475e-01, -3.2793e-01,  5.4028e+00, -9.6547e-01,
          -8.6761e+00,  5.5809e+00,  5.8654e+00, -6.3197e+00, -1.1656e+01],
         [-1.0098e+00,  1.9962e-01, -3.3415e+00, -5.9999e+00, -5.4316e-01,
           1.5713e+00, -1.0344e+01, -9.1310e+00,  9.3254e+00, -4.3363e+00],
         [ 3.3739e+01,  1.0268e+01,  6.7192e+00, -1.9551e+01,  2.1706e+01,
          -8.9460e+00, -1.5511e+01, -4.5860e+00, -4.4936e+00,  5.4413e+00],
         [-3.0350e+01, -1.4151e+01, -1.2747e+01,  2.5575e+01, -1.7661e+01,
           7.9865e+00,  1.9825e+01,  3.0328e+00, -1.9061e+00, -7.4309e+00],
         [-4.4431e+00, -1.5917e+01, -1.8293e+01,  2.0079e+01, -1.4705e+00,
           1.3233e+01,  1.3471e+01, -7.8232e+00, -6.0192e+00,  6.1447e+00],
         [ 1.6348e+01, -2.0204e+00, -8.9886e-01, -1.7722e+00,  8.0434e+00,
           9.3397e+00,  2.5107e-01, -3.9567e+00, -2.9967e+00,  1.9015e+01]],

        [[-7.7698e+01, -4.7289e+01, -5.5206e+01,  6.8671e+01, -4.1845e+01,
           2.7526e+01,  3.9565e+01, -1.7030e+01,  4.3976e+00, -2.9259e+01],
         [-9.1661e+04, -5.9650e+04, -2.2984e+05, -5.6893e+04,  2.7513e+03,
          -4.0064e+04, -2.5198e+05, -3.0279e+05,  1.9746e+05, -3.3265e+05],
         [ 6.6749e+03,  4.3476e+03,  1.6872e+04,  4.2551e+03, -2.4247e+02,
           2.9749e+03,  1.8593e+04,  2.2281e+04, -1.4537e+04,  2.4465e+04],
         [ 4.6383e+03,  3.0204e+03,  1.1661e+04,  2.9023e+03, -1.4857e+02,
           2.0390e+03,  1.2804e+04,  1.5373e+04, -1.0026e+04,  1.6885e+04],
         [ 3.0901e+04,  2.0110e+04,  7.7471e+04,  1.9168e+04, -9.2251e+02,
           1.3497e+04,  8.4924e+04,  1.0205e+05, -6.6555e+04,  1.1211e+05],
         [-5.6382e+01, -3.4728e+01, -6.8802e+01,  2.5652e+01, -2.1005e+01,
           6.3245e+00, -2.3592e+01, -6.1542e+01,  3.6442e+01, -7.4515e+01],
         [ 4.5492e+05,  2.9606e+05,  1.1413e+06,  2.8288e+05, -1.3846e+04,
           1.9910e+05,  1.2517e+06,  1.5038e+06, -9.8075e+05,  1.6520e+06],
         [ 3.9354e+01,  2.4511e+01,  2.7436e+01, -3.6050e+01,  2.1714e+01,
          -1.5587e+01, -2.2137e+01,  7.3869e+00, -1.3079e+00,  1.1774e+01]]],
       device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_grad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.0589, device='xpu:0', dtype=torch.float64)
analytical:tensor(-32.9307, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [-0.0667],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [-1.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.],
        [ 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.9333333333333407.


======================================================================
ERROR: test_grad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[-3.6687e+302,  3.6573e+302, -6.3140e+302,  3.8908e+302, -5.6957e+301],
        [-5.4737e+300, -1.2153e+300, -5.2992e+300, -6.1895e+300,  4.2607e+300]],
       device='xpu:0', dtype=torch.float64)

Expected:
tensor([[ 0.1736,  0.2727, -0.0299,  0.3583, -0.3281],
        [ 0.0319, -0.0092,  0.0268,  0.0086, -0.0130]], device='xpu:0',
       dtype=torch.float64)

======================================================================
ERROR: test_grad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(-0.0188, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0760, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.1467,  0.0459,  0.1700,  0.0000,  0.0541,  0.0000,  0.0000, -0.0126,
          0.0000],
        [-0.0472, -0.0066, -0.0420,  0.0000, -0.0163,  0.0000,  0.0000,  0.0038,
          0.0000],
        [-0.1124,  0.0099, -0.0605,  0.0000, -0.0352,  0.0000,  0.0000,  0.0082,
          0.0000],
        [-0.1030,  0.1638, -0.0936,  0.0000, -0.0776,  0.0000,  0.0000,  0.0181,
          0.0000],
        [-0.5757, -0.2337, -0.5017,  0.0000, -0.1600,  0.0000,  0.0000,  0.0374,
          0.0000],
        [ 0.0478,  0.2398,  0.4433,  0.0000,  0.0581,  0.0000,  0.0000, -0.0136,
          0.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000, -0.0659, -0.6214,  0.0000, -0.4274,  0.0000,  0.0000,  0.0464,
          0.0000],
        [ 0.0000,  0.0572, -0.3336,  0.0000, -0.2294,  0.0000,  0.0000, -0.0896,
          0.0000],
        [ 0.0000,  0.0000, -0.1712,  0.0000, -0.1178,  0.0000,  0.0000,  0.1084,
          0.0000],
        [ 0.0000,  0.0000,  3.8572,  0.0000,  0.9920,  0.0000,  0.0000,  0.4180,
          0.0000],
        [ 0.0000,  0.0000,  2.0706,  0.0000,  0.5325,  0.0000,  0.0000, -0.1003,
          0.0000],
        [ 0.0000,  0.0000,  1.0627,  0.0000,  0.2733,  0.0000,  0.0000, -0.1546,
          0.0000]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 3.9507812192019203.


======================================================================
ERROR: test_grad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-0.1363, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.4945, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0828, -0.2976, -0.0886,  0.0777],
        [ 0.0109, -0.0725, -0.0205, -0.0087],
        [ 0.0000,  0.0000, -0.1637, -0.2673],
        [ 0.0000,  0.0000, -0.0341, -0.0557]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.29755472901027424.


======================================================================
ERROR: test_grad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0.4289, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.9999999999998899.


======================================================================
ERROR: test_grad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 839, in _test_batched_grad
    result = vmap(vjp)(torch.stack(grad_outputs))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_vmap_internals.py", line 323, in wrapped
    batched_outputs = func(*batched_inputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 822, in vjp
    results = grad(v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: different elements ...

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 845, in _test_batched_grad
    raise GradcheckError(
torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got: different elements ...

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

======================================================================
ERROR: test_grad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_grad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 354, in test_grad
    self._test_gradients_helper(device, dtype, module_info, training, gradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3325, in gradcheck
    return torch.autograd.gradcheck(fn, inputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1427, in _gradcheck_helper
    func_out = func(*tupled_inputs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_gradgrad_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 1:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[[-0.1689,  0.1495,  0.0654],
         [-0.1265, -0.1586,  0.0836],
         [ 0.2320, -0.2054, -0.0899],
         [ 0.1738,  0.2178, -0.1149],
         [-0.0353,  0.0313,  0.0137],
         [-0.0265, -0.0332,  0.0175],
         [-0.1690,  0.1496,  0.0655],
         [-0.1265, -0.1586,  0.0837]],

        [[-0.1140,  0.1009,  0.0442],
         [-0.0854, -0.1070,  0.0564],
         [-0.3412,  0.3021,  0.1322],
         [-0.2556, -0.3203,  0.1690],
         [-0.1706,  0.1511,  0.0661],
         [-0.1278, -0.1602,  0.0845],
         [-0.0482,  0.0427,  0.0187],
         [-0.0361, -0.0453,  0.0239]]], device='xpu:0', dtype=torch.float64)

Expected:
tensor([[[-0.0519, -0.1027,  0.0847],
         [ 0.7674,  0.6427, -0.1762],
         [ 0.1639,  0.6657, -0.3350],
         [ 0.0775,  0.7139,  0.4458],
         [ 0.0067,  0.2964, -0.2178],
         [-0.6050,  2.5319, -1.6361],
         [ 0.1902, -0.4700,  0.1756],
         [-0.2547, -0.8514,  0.6096]],

        [[-0.1317, -0.0370,  0.0617],
         [ 0.3725,  0.2046, -0.0576],
         [-0.0721, -0.0435, -0.0196],
         [-0.0028,  0.0671,  0.0053],
         [-0.0514,  0.0267, -0.0108],
         [-0.0556, -0.3207,  0.0966],
         [-0.2927,  0.0421,  0.1244],
         [-0.0568, -0.1404,  0.0962]]], device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_gradgrad_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_gradgrad_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0174, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  7.6034e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.3939e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8236e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -1.4007e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00, -6.2328e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1804e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00, -5.9872e-02,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.4022e-02,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -8.2794e-04]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -1.5214e-02, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.4898e-02, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.4874e-02,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  4.7853e-01,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  7.8236e-04,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -1.4007e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -6.2328e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  2.1804e-04,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -5.9872e-02, -0.0000e+00, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -2.4022e-02, -0.0000e+00],
        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,
         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -8.2794e-04]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.2391476901868358.


======================================================================
ERROR: test_gradgrad_nn_Embedding_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(5.6674, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[ 0.0000e+00, 1.9763e-323,  0.0000e+00,  1.0000e+00,  1.0000e+00,
          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00, 2.4703e-323,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [4.9407e-324,  0.0000e+00, 4.9407e-324,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [4.9407e-324, 1.4822e-323, 4.9407e-324,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [9.8813e-324, 4.9407e-324, 9.8813e-324,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [1.4822e-323, 9.8813e-324, 1.4822e-323,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.7193e-01,  0.0000e+00,  2.7193e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,
          1.0000e+00,  1.0000e+00],
        [ 1.4490e-01,  0.0000e+00,  1.4490e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.9283e-01,  0.0000e+00,  4.9283e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 2.7486e-02,  0.0000e+00,  2.7486e-02,  1.0000e+00,  1.0000e+00,
          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 7.9966e-02,  0.0000e+00,  7.9966e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.9679e-02,  0.0000e+00,  5.9679e-02,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.4308e-01,  0.0000e+00,  1.4308e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.9336e-01,  0.0000e+00,  4.9336e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.1014e-01,  0.0000e+00,  5.1014e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 1.4308e-01,  0.0000e+00,  1.4308e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 4.9336e-01,  0.0000e+00,  4.9336e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 5.1014e-01,  0.0000e+00,  5.1014e-01,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1.0.


======================================================================
ERROR: test_gradgrad_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0099, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 1.3173e-02,  1.4127e-03,  3.0758e-03,  4.1166e-04],
        [ 1.4127e-03, -1.3674e-03,  4.1865e-04,  3.6348e-05],
        [ 3.0758e-03,  4.1865e-04,  1.8154e-02,  4.6265e-03],
        [ 4.1166e-04,  3.6348e-05,  4.6265e-03,  4.5943e-04]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 0.018154461174702367.


======================================================================
ERROR: test_gradgrad_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 851, in _test_batched_grad
    raise GradcheckError(_get_failed_batched_grad_test_msg(output_idx, input_idx, res, exp))
torch.autograd.gradcheck.GradcheckError: For output 0 and input 0:

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

Got:
tensor([[ 5.0048e+302, -1.8219e-315,  -0.0000e+00],
        [ 5.0048e+302, -1.8219e-315,  -0.0000e+00]], device='xpu:0',
       dtype=torch.float64)

Expected:
tensor([[-0.0685, -0.0282,  0.0148],
        [-0.0859, -0.1535, -2.8611]], device='xpu:0', dtype=torch.float64)

======================================================================
ERROR: test_gradgrad_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 839, in _test_batched_grad
    result = vmap(vjp)(torch.stack(grad_outputs))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_vmap_internals.py", line 323, in wrapped
    batched_outputs = func(*batched_inputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 822, in vjp
    results = grad(v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: different elements ...

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1446, in _gradcheck_helper
    _test_batched_grad(tupled_inputs, o, i)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 845, in _test_batched_grad
    raise GradcheckError(
torch.autograd.gradcheck.GradcheckError: While computing batched gradients, got: different elements ...

gradcheck or gradgradcheck failed while testing batched gradient computation.
This could have been invoked in a number of ways (via a test that calls
gradcheck/gradgradcheck directly or via an autogenerated test).

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `check_batched_grad=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `check_batched_grad=False` and/or `check_batched_gradgrad=False`.

If you're modifying an existing operator that supports batched grad computation,
or wish to make a new operator work with batched grad computation, please read
the following.

To compute batched grads (e.g., jacobians, hessians), we vmap over the backward
computation. The most common failure case is if there is a 'vmap-incompatible
operation' in the backward pass. Please see
NOTE: [How to write vmap-compatible backward formulas]
in the codebase for an explanation of how to fix this.

======================================================================
ERROR: test_gradgrad_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 533, in _check_analytical_jacobian_attributes
    vjps1 = _get_analytical_vjps_wrt_specific_output(vjp_fn, output.clone(), v)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 638, in _get_analytical_vjps_wrt_specific_output
    grad_inputs = vjp_fn(v.reshape(sample_output.shape))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 529, in vjp_fn
    return torch.autograd.grad(output, diff_input_list, grad_output,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/__init__.py", line 300, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 1e-12.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 330, in _test_gradients_helper
    m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 2 with respect to input 0,
numerical:tensor(0.3569, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.7138, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.3468,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.3468,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ..., -0.1137,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1137,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.1137]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.3468,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.3468,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.3468,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ..., -0.1137,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1137,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.1137]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.47319632282000784.


======================================================================
ERROR: test_gradgrad_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1309, in _fast_gradcheck
    analytical_vJu = _get_analytical_vJu_backward_mode(inputs, outputs, nondet_tol, check_grad_dtypes, all_v, all_u_dense)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 560, in _get_analytical_vJu_backward_mode
    all_vJ = _check_analytical_jacobian_attributes(inputs, output, nondet_tol, check_grad_dtypes,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 549, in _check_analytical_jacobian_attributes
    raise GradcheckError('Backward is not reentrant, i.e., running backward with '
torch.autograd.gradcheck.GradcheckError: Backward is not reentrant, i.e., running backward with same input and grad_output multiple times gives different values, although analytical gradient matches numerical gradient.The tolerance for nondeterminism was 0.0.

NOTE: If your op relies on non-deterministic operations i.e., it is listed here:
https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
this failure might be expected.

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck.
If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `nondet_tol=<tol>` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_nondet_tol=<tol>`.
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_nondet_tol=<tol>`


======================================================================
ERROR: test_gradgrad_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(nan, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0053, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[    nan,    -inf,     inf,     inf,     inf,    -inf,     inf,     inf,
            -inf],
        [ 0.0103, -0.0029,  0.0032,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [-0.0029,  0.0150, -0.0114,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0032, -0.0114,  0.0078,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0085, -0.0147,  0.0066,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000, -0.0147,  0.0097, -0.0036,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0066, -0.0036,  0.0042,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0085, -0.0097,
          0.0161],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0097,  0.0175,
         -0.0206]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[ 0.0000,  0.0000,  0.0224, -0.0158, -0.0158,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000, -0.0183,  0.0131,  0.0131,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0131, -0.0097, -0.0097,  0.0000,  0.0000,  0.0000,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0328, -0.0242, -0.0242,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0324,  0.0241,  0.0241,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0241, -0.0173, -0.0173,
          0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0197],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
          0.0233],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         -0.0180]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: nan.


======================================================================
ERROR: test_gradgrad_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(nan, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.0.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_gradgrad_nn_RNNCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(-885.7141, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0047, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.0023, -0.0028, -0.0321,  0.0183,  0.0244],
        [-0.0028, -0.0092,  0.0257, -0.0349, -0.0056],
        [-0.0321,  0.0257,  0.0442, -0.0344, -0.0613],
        [ 0.0183, -0.0349, -0.0344, -0.0006,  0.0687],
        [ 0.0244, -0.0056, -0.0613,  0.0687,  0.0427]], device='xpu:0',
       dtype=torch.float64)
Analytical:
tensor([[-0.0023, -0.0028, -0.0321,  0.0183,  0.0244],
        [-0.0028, -0.0092,  0.0257, -0.0349, -0.0056],
        [-0.0321,  0.0257,  0.0442, -0.0344, -0.0613],
        [ 0.0183, -0.0349, -0.0344, -0.0006,  0.0687],
        [ 0.0244, -0.0056, -0.0613,  0.0687,  0.0427]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 5.725847580795307e-09.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_gradgrad_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 1 with respect to input 0,
numerical:tensor(855559.3526, device='xpu:0', dtype=torch.float64)
analytical:tensor(0., device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[   0.0000,    0.0000, -138.5824,  752.3253, 1191.5724,   16.8492],
        [   0.0000,    0.0000, -138.5824,  752.3540, 1191.5681,   16.8620],
        [   0.0000,    0.0000, -138.5824,  752.3419, 1191.8626,   16.8567],
        [   0.0000,    0.0000, -138.5824,  752.4548, 1191.5699,   17.1493],
        [   0.0000,    0.0000, -138.5824,  752.3419, 1191.5699,   16.8567],
        [   0.0000,    0.0000, -138.5824,  752.3419, 1191.5699,   16.8567]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 1191.8625709084383.


======================================================================
ERROR: test_gradgrad_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0034, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[-0.0742,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.0742,  0.0000,  0.0000],
        [ 0.1227,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.1227,  0.0000,  0.0000]], device='xpu:0',
       dtype=torch.float64)

The max per-element difference (slow mode) is: 0.12271293017807068.


======================================================================
ERROR: test_gradgrad_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
numerical:tensor(0., device='xpu:0', dtype=torch.float64)
analytical:tensor(-0.0087, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]], device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.0.
Fast gradcheck failed but element-wise differences are small. This means that the
test might've passed in slow_mode!

If you are adding a new operator, please file an issue and then use one of the
workarounds. The workaround depends on how your test invokes gradcheck/gradgradcheck:

If the test
- manually invokes gradcheck/gradgradcheck, then call gradcheck/gradgradcheck
  with `fast_mode=False` as a keyword argument.
- is OpInfo-based (e.g., in test_ops_gradients.py), then modify the OpInfo for the test
  to have `gradcheck_fast_mode=False`
- is a Module test (e.g., in common_nn.py), then modify the corresponding
  module_test entry to have `gradcheck_fast_mode=False`

======================================================================
ERROR: test_gradgrad_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1574, in gradgradcheck
    return gradcheck(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1418, in gradcheck
    return _gradcheck_helper(**args)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1432, in _gradcheck_helper
    _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1075, in _gradcheck_real_imag
    gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1311, in _fast_gradcheck
    _check_analytical_numerical_equal(analytical_vJu, numerical_vJu, complex_indices,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1283, in _check_analytical_numerical_equal
    raise GradcheckError(_get_notallclose_msg(a, n, j, i, complex_indices, test_imag, is_forward_ad) + jacobians_str)
torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 1,
numerical:tensor(-1.2933e+08, device='xpu:0', dtype=torch.float64)
analytical:tensor(0.0367, device='xpu:0', dtype=torch.float64)

The above quantities relating the numerical and analytical jacobians are computed 
in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:

Numerical:
 tensor([[-0.1031,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0022],
        [ 0.1031,  0.0035,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0009,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0004,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0380,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0128]],
       device='xpu:0', dtype=torch.float64)
Analytical:
tensor([[0.2062, 0.2062, 0.2062,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0004, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0380, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0128]],
       device='xpu:0', dtype=torch.float64)

The max per-element difference (slow mode) is: 0.30935389529304647.


======================================================================
ERROR: test_gradgrad_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_gradgrad_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 358, in test_gradgrad
    self._test_gradients_helper(device, dtype, module_info, training, gradgradcheck)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 350, in _test_gradients_helper
    self.assertTrue(check(fn_to_gradcheck, flat_input, nondet_tol=gradcheck_nondet_tol))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 3345, in gradgradcheck
    return torch.autograd.gradgradcheck(fn, inputs, grad_outputs, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/autograd/gradcheck.py", line 1540, in gradgradcheck
    outputs = _differentiable_outputs(func(*tupled_inputs))
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 347, in fn_to_gradcheck
    output = m(*new_input_args, **new_kwargs, **other_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_TransformerEncoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_if_train_and_eval_modes_differ_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 505, in test_if_train_and_eval_modes_differ
    m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_memory_format_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_memory_format_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_memory_format_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_memory_format_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 478, in test_memory_format
    desired_outputs = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_AvgPool1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 547, in forward
    return F.avg_pool1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_non_contiguous_tensors_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_non_contiguous_tensors_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 277, in test_non_contiguous_tensors
    default_output = m(*input_args, **input_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_ao_nn_quantized_MaxPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 166, in forward
    return F.max_pool2d(input, self.kernel_size, self.stride,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/_jit_internal.py", line 485, in fn
    return if_false(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 782, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_AdaptiveAvgPool2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 1184, in forward
    return F.adaptive_avg_pool2d(input, self.output_size)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 1214, in adaptive_avg_pool2d
    return torch._C._nn.adaptive_avg_pool2d(input, _output_size)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_BatchNorm2d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm2d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm3d_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_BatchNorm3d_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: DPCPP batch_norm backend got unsupported type=Double

======================================================================
ERROR: test_pickle_nn_ConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_ConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_ConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_CrossEntropyLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_pickle_nn_CrossEntropyLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 1D target tensor expected, multi-target not supported

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 801, in forward
    return F.conv_transpose1d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 956, in forward
    return F.conv_transpose2d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_LazyConvTranspose3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1208, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 1108, in forward
    return F.conv_transpose3d(
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: self dim 1 must match batch1 dim 1

======================================================================
ERROR: test_pickle_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 647, in forward
    x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 660, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerDecoderLayer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 651, in forward
    x = self.norm1(x + self._sa_block(x, tgt_mask, tgt_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_TransformerEncoderLayer_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
ERROR: test_pickle_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 5158, in multi_head_attention_forward
    attn_output_weights = torch.baddbmm(attn_mask, q_scaled, k.transpose(-2, -1))
RuntimeError: matmul supports [mb, m, n] or [1, 1, 1] when bias dim is 3 ...

======================================================================
ERROR: test_pickle_nn_Transformer_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 435, in instantiated_test
    raise rte
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 164, in test_pickle
    output = m(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 535, in forward
    x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
RuntimeError: Double is not supported in oneDNN!

======================================================================
FAIL: test_memory_format_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 487, in test_memory_format
    self.assertEqual(outputs, desired_outputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 20 / 20 (100.0%)
Greatest absolute difference: 1.3981800792094244e+303 at index (1, 4, 0, 0) (up to 1e-05 allowed)
Greatest relative difference: 5.614210041798493e+303 at index (1, 4, 0, 0) (up to 1e-05 allowed)

======================================================================
FAIL: test_memory_format_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_ELU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_memory_format_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 487, in test_memory_format
    self.assertEqual(outputs, desired_outputs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 20 / 20 (100.0%)
Greatest absolute difference: 2.6760089487493594e+303 at index (0, 0, 0, 0) (up to 1e-05 allowed)
Greatest relative difference: 5.567315753833682e+303 at index (0, 2, 0, 1) (up to 1e-05 allowed)

======================================================================
FAIL: test_memory_format_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 1279, in wrap_fn
    return fn(self, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 488, in test_memory_format
    _check_out_mem_format(outputs, input_mem_format, module_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 465, in _check_out_mem_format
    return self._traverse_obj(output, inner_check_out_mem_format)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 217, in _traverse_obj
    return func(obj)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 460, in inner_check_out_mem_format
    self.assertTrue(output.is_contiguous(memory_format=torch.channels_last))
AssertionError: False is not true

======================================================================
FAIL: test_non_contiguous_tensors_nn_AdaptiveAvgPool2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 65 / 90 (72.2%)
Greatest absolute difference: nan at index (0, 1, 2, 4) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 1, 2, 4) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_AvgPool1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 16 / 18 (88.9%)
Greatest absolute difference: 7.060555423288037e+32 at index (1, 4) (up to 0.0001 allowed)
Greatest relative difference: 1.7800938695638449e+18 at index (2, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm2d_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 216 / 216 (100.0%)
Greatest absolute difference: 7.472859709467298e+35 at index (1, 2, 4, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm2d_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 216 / 216 (100.0%)
Greatest absolute difference: 2.1891310450080882e+38 at index (0, 0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: 82418578.32302375 at index (0, 1, 0, 4) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm3d_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 384 / 384 (100.0%)
Greatest absolute difference: 2.1829095454002138e+38 at index (0, 0, 0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 3, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_BatchNorm3d_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 384 / 384 (100.0%)
Greatest absolute difference: 1.0438461688114682e+20 at index (1, 2, 1, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Bilinear_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 616.8666381835938 at index (3, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.1980818042342205 at index (4, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Bilinear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 16 / 16 (100.0%)
Greatest absolute difference: 666.5062212358272 at index (2, 1) (up to 0.0001 allowed)
Greatest relative difference: 1.4767948380077787 at index (6, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 18 / 24 (75.0%)
Greatest absolute difference: 5.9131425509901516e+26 at index (0, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 0.7682248354003315 at index (1, 2, 0) (up to 0.0001 allowed)
Greatest relative difference: 425876935203.5446 at index (1, 3, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 2, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 88 / 96 (91.7%)
Greatest absolute difference: 456570304.77645034 at index (1, 0, 0, 3) (up to 0.0001 allowed)
Greatest relative difference: 2.17363560762904e+22 at index (0, 3, 2, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 1.4618437196513032e+38 at index (1, 3, 2, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Conv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 1.4044490983809555e+306 at index (1, 1, 1, 2, 1) (up to 0.0001 allowed)
Greatest relative difference: 5.66323995814596e+27 at index (0, 3, 0, 1, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 2, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 2, 1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ConvTranspose3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 1, 2, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 1, 2, 1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ELU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 30 (100.0%)
Greatest absolute difference: 1.4551027417182922 at index (0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: 90.71997575768242 at index (0, 1, 4) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ELU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 13 / 30 (43.3%)
Greatest absolute difference: 0.47252088772906087 at index (2, 1, 1) (up to 0.0001 allowed)
Greatest relative difference: 5076526677013083.0 at index (0, 0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRUCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: nan at index (0,) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRUCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 0.6588477777787115 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: 1.0671424894798203 at index (4,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 311, in test_non_contiguous_tensors
    self.assertEqual(param_grad, default_param_grad)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 10 / 12 (83.3%)
Greatest absolute difference: 0.762304037809372 at index (3, 0) (up to 1e-05 allowed)
Greatest relative difference: 3.006722044504938 at index (5, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 1.479690433038276 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.035820370582818 at index (0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.05623644031584263 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: 2.843743107494654 at index (0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GRU_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.0015399470849864242 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 9.480324326311422 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 3 / 3 (100.0%)
Greatest absolute difference: 1.2116662859916687 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: 1.6061488699731572 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_GaussianNLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 1 / 1 (100.0%)
Greatest absolute difference: 101.57871676260051 at index (0,) (up to 0.0001 allowed)
Greatest relative difference: 1.001314061080708 at index (0,) (up to 1e-05 allowed)

The failure occurred for item [2]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Hardswish_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 3.3369943856558465e+24 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Hardswish_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.9424436797686653 at index (2,) (up to 0.0001 allowed)
Greatest relative difference: inf at index (2,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_L1Loss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 4.166294435746185e+37 at index (1, 2, 2) (up to 0.0001 allowed)
Greatest relative difference: 1.2522979861600262e+38 at index (1, 2, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_L1Loss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 2.0969916368377807e+23 at index (1, 1, 0) (up to 0.0001 allowed)
Greatest relative difference: 6.844470870006576e+23 at index (1, 1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTMCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 0.16939648240804672 at index (0,) (up to 0.0001 allowed)
Greatest relative difference: 25.580900262210978 at index (3,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTMCell_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: 1.3502345449563404 at index (3,) (up to 0.0001 allowed)
Greatest relative difference: 229.84586148545665 at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.029325855895876884 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 0.7055235829390206 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.1550081473680251 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.481403408171739 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 6.097020175307989 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0030464930739738 at index (0, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LSTM_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 0.009598099351025135 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: 5.057448192918535 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 9.39235048136953e+18 at index (1, 3, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 2, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv1d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 4.691449056613091e+149 at index (0, 3, 1) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 51 / 96 (53.1%)
Greatest absolute difference: 8.436585532319433e+36 at index (1, 3, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 2, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv2d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 3.175474881994616 at index (0, 3, 2, 1) (up to 0.0001 allowed)
Greatest relative difference: inf at index (1, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 1.2556705921717365e+38 at index (1, 3, 2, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0, 2, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConv3d_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 314 / 480 (65.4%)
Greatest absolute difference: 196509467449.59464 at index (1, 1, 2, 1, 2) (up to 0.0001 allowed)
Greatest relative difference: 6.671956539748628e+32 at index (0, 1, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose1d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 3.6893488147419103e+19 at index (0, 0, 2) (up to 0.0001 allowed)
Greatest relative difference: 3.946495777274069e+18 at index (1, 2, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose2d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 96 / 96 (100.0%)
Greatest absolute difference: 9.904916314506544e+35 at index (0, 3, 2, 1) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 2, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_LazyConvTranspose3d_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_device_type.py", line 853, in dep_fn
    return fn(slf, *args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 480 / 480 (100.0%)
Greatest absolute difference: 1.1163418042668438e+36 at index (0, 0, 1, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 2, 0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Linear_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 309, in test_non_contiguous_tensors
    self.assertEqual(input_kwargs_grad, default_input_kwargs_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 40 / 40 (100.0%)
Greatest absolute difference: 3.1255977558036115e+35 at index (2, 1) (up to 0.0001 allowed)
Greatest relative difference: 3.466921377714361 at index (2, 9) (up to 1e-05 allowed)

The failure occurred for item ['input']

======================================================================
FAIL: test_non_contiguous_tensors_nn_Linear_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 309, in test_non_contiguous_tensors
    self.assertEqual(input_kwargs_grad, default_input_kwargs_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 30 / 40 (75.0%)
Greatest absolute difference: 1.3748993620664989e+281 at index (2, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.5623172594346301e+27 at index (1, 7) (up to 1e-05 allowed)

The failure occurred for item ['input']

======================================================================
FAIL: test_non_contiguous_tensors_nn_MultiheadAttention_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 311, in test_non_contiguous_tensors
    self.assertEqual(param_grad, default_param_grad)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 6 / 9 (66.7%)
Greatest absolute difference: 0.14391803741455078 at index (1,) (up to 1e-05 allowed)
Greatest relative difference: 3.250304036869733 at index (0,) (up to 1e-05 allowed)

The failure occurred for item [1]

======================================================================
FAIL: test_non_contiguous_tensors_nn_MultiheadAttention_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 9 / 9 (100.0%)
Greatest absolute difference: nan at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_NLLLoss_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 15 / 150 (10.0%)
Greatest absolute difference: 0.4686567485332489 at index (0, 3) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_NLLLoss_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 15 / 150 (10.0%)
Greatest absolute difference: 0.08394813827980317 at index (0, 8) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 8) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNNCell_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 5 / 5 (100.0%)
Greatest absolute difference: nan at index (1,) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 5.366870600354898e+37 at index (0, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_eval_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.734448531211979e+303 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (1, 1) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 6 (66.7%)
Greatest absolute difference: 1.5371889923487374e+37 at index (2, 1) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_RNN_train_mode_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.7344485296916675e+303 at index (1, 0) (up to 0.0001 allowed)
Greatest relative difference: 1.0 at index (1, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ReLU_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 2 / 4 (50.0%)
Greatest absolute difference: 1.3825058937072754 at index (1,) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_ReLU_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 4 / 4 (100.0%)
Greatest absolute difference: 7.727634620577693 at index (3,) (up to 0.0001 allowed)
Greatest relative difference: 8.0 at index (1,) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Sigmoid_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 120 / 120 (100.0%)
Greatest absolute difference: 5.448246532387257e+33 at index (0, 1, 3, 1) (up to 0.0001 allowed)
Greatest relative difference: 5.232592449485857e+37 at index (0, 2, 0, 2) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Sigmoid_xpu_float64 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 120 / 120 (100.0%)
Greatest absolute difference: 54270.50785009438 at index (1, 1, 3, 0) (up to 0.0001 allowed)
Greatest relative difference: 4.9036648858762e+16 at index (0, 0, 3, 3) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerDecoderLayer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerEncoderLayer_eval_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: 23367018496.0 at index (1, 1, 1) (up to 0.0001 allowed)
Greatest relative difference: inf at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_TransformerEncoderLayer_train_mode_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 24 / 24 (100.0%)
Greatest absolute difference: nan at index (0, 0, 0) (up to 0.0001 allowed)
Greatest relative difference: nan at index (0, 0, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

======================================================================
FAIL: test_non_contiguous_tensors_nn_Transformer_xpu_float32 (__main__.TestModuleXPU)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2004, in wrapper
    method(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/common/pytorch_test_base.py", line 430, in instantiated_test
    result = test(self, **param_kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_modules.py", line 112, in test_wrapper
    return test(*args, **kwargs)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 1061, in wrapper
    fn(*args, **kwargs)
  File "/home/gta/xunsongh/ipex-gpu/tests/gpu/experimental/test/test_modules.py", line 308, in test_non_contiguous_tensors
    self.assertEqual(input_args_grad, default_input_args_grad, atol=0.0001, rtol=0)
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_internal/common_utils.py", line 2468, in assertEqual
    assert_equal(
  File "/home/gta/miniconda3/envs/xunsongh/lib/python3.9/site-packages/torch/testing/_comparison.py", line 1093, in assert_equal
    raise error_metas[0].to_error(msg)
AssertionError: Tensor-likes are not close!

Mismatched elements: 12 / 12 (100.0%)
Greatest absolute difference: 19690756.00425032 at index (2, 3) (up to 0.0001 allowed)
Greatest relative difference: 1.0000000013600712 at index (2, 0) (up to 1e-05 allowed)

The failure occurred for item [0]

----------------------------------------------------------------------
Ran 918 tests in 182.655s

FAILED (failures=71, errors=189, skipped=238, expected failures=8)
Raised CalledProcessError: return code 1.