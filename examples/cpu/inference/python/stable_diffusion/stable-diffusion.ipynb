{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b672435-e0d8-4246-b228-ed7f73e153ca",
   "metadata": {},
   "source": [
    "#  Stable Diffusion Demo on Intel® Xeon® 4th generation Scalable Processor with Intel® Extension for PyTorch*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc14077-cda3-468a-abac-2f7ef8abcdac",
   "metadata": {},
   "source": [
    "### Intel® Xeon® 4th generation Scalable Processor have Intel® AMX® Instruction Set Architecture which allow faster matrix multiplications for BFloat16 & int8 datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f101b-a128-4649-951a-b25795816930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "import copy\n",
    "\n",
    "# We have provided this file in the source-code\n",
    "from quantization_modules import load_int8_model, convert_to_fp32model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b6617-c6b6-4b08-b8c3-48ef806c05aa",
   "metadata": {},
   "source": [
    "### Trying to run Stable Diffusion with PyTorch* Float32 in eager mode would probably hang up this process.\n",
    "\n",
    "#### We are using a patched diffusers branch, built with instructions at https://github.com/intel/intel-extension-for-pytorch/tree/dev_demo/examples/cpu/inference/python/stable_diffusion, so run this cell with a different kernel, and then switch back to the kernel used for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8bffc7-e151-416e-b97e-5db5ed4f2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "\n",
    "output = pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf3b1f-1181-4dbc-ad95-5de28137ab3a",
   "metadata": {},
   "source": [
    "#### If the above cell is taking too long to run, you might want to restart the kernel, and skip it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265b080-5209-4e56-a3f4-0889c0c00d93",
   "metadata": {},
   "source": [
    "## First, we'll eyeball performance with FP32, by using Intel Extension for PyTorch* to prepack weights, ensure auto-channels-last, etc\n",
    "\n",
    "https://intel.github.io/intel-extension-for-pytorch/latest/tutorials/api_doc.html#ipex.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f4b45c-0e7d-4534-8526-417db6dc0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "# sample input that represents the shape of the input tensors that'd be fed to the model\n",
    "input = torch.randn(2, 4, 64, 64).to(memory_format=torch.channels_last), torch.tensor(921), torch.randn(2, 77, 768)\n",
    "\n",
    "# These are the 3 main components of Stable Diffusion \n",
    "pipe.text_encoder = ipex.optimize(pipe.text_encoder.eval(), inplace=True)\n",
    "pipe.unet = ipex.optimize(pipe.unet.eval(), inplace=True)\n",
    "pipe.vae = ipex.optimize(pipe.vae.eval(), inplace=True)\n",
    "\n",
    "#JIT-tracing\n",
    "\n",
    "with torch.no_grad():\n",
    "    pipe.unet = torch.jit.trace(pipe.unet, input, strict=False)\n",
    "    pipe.unet = torch.jit.freeze(pipe.unet)\n",
    "    pipe.unet(*input)\n",
    "    pipe.unet(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59975060-5b78-4f68-bd51-8ad930af5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a077e1a-9929-432a-a1ec-59c0ec379244",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae2b18-8fb0-49d7-8c47-4bf5af3289b0",
   "metadata": {},
   "source": [
    "## Now, let's look at performance with Automatic Mixed Precision (BFloat16 datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131676b7-ea4c-433a-a7ce-5bc0cd144b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "\n",
    "pipe.text_encoder = ipex.optimize(pipe.text_encoder.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "pipe.unet = ipex.optimize(pipe.unet.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "pipe.vae = ipex.optimize(pipe.vae.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "\n",
    "# sample input that represents the shape of the input tensors that'd be fed to the model\n",
    "input = torch.randn(2, 4, 64, 64).to(memory_format=torch.channels_last), torch.tensor(921), torch.randn(2, 77, 768)\n",
    "#JIT-tracing\n",
    "with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "    pipe.unet = torch.jit.trace(pipe.unet, input, strict=False)\n",
    "    pipe.unet = torch.jit.freeze(pipe.unet)\n",
    "    pipe.unet(*input)\n",
    "    pipe.unet(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b19d0-6cad-42f4-9e1e-6d934e09d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "    output = pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89f6b1-3786-4973-8c26-f8a85d2fb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a27fb-e757-4912-975f-b3c3d2a6a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU], record_shapes=True) as p:\n",
    "    with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "        pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images\n",
    "output = p.key_averages().table(sort_by=\"self_cpu_time_total\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644a8fd-dc95-4273-97c4-942f4c21ce45",
   "metadata": {},
   "source": [
    "## Even Stable Diffusion v2.1 performs well with Intel Extension for PyTorch* with BFloat16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c927a-8176-45e6-83b6-d5b3ac78846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\")\n",
    "\n",
    "pipe.text_encoder = ipex.optimize(pipe.text_encoder.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "pipe.unet = ipex.optimize(pipe.unet.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "pipe.vae = ipex.optimize(pipe.vae.eval(), dtype=torch.bfloat16, inplace=True)\n",
    "\n",
    "# sample input that represents the shape of the input tensors that'd be fed to the model\n",
    "input = torch.randn(2, 4, 64, 64).to(memory_format=torch.channels_last), torch.tensor(921), torch.randn(2, 77, 1024)\n",
    "#JIT-tracing\n",
    "with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "    pipe.unet = torch.jit.trace(pipe.unet, input, strict=False)\n",
    "    pipe.unet = torch.jit.freeze(pipe.unet)\n",
    "    pipe.unet(*input)\n",
    "    pipe.unet(*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa9767-982e-446b-bf35-589a674d81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "    result = pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584705a8-a9b8-4716-a044-ccb8f65226d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.profiler.profile(activities=[torch.profiler.ProfilerActivity.CPU], record_shapes=True) as p:\n",
    "    with torch.cpu.amp.autocast(dtype=torch.bfloat16), torch.no_grad():\n",
    "        pipe(\"a photo of an astronaut riding a horse on mars\", generator=torch.manual_seed(13)).images\n",
    "output = p.key_averages().table(sort_by=\"self_cpu_time_total\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05db08-6dd5-4086-9307-27ac0c968daa",
   "metadata": {},
   "source": [
    "Currently, we haven't optimized Stable Diffusion for int8 static quantization with JIT/graph mode, but you can play around with eager mode int8 by quantizing Stable Diffusion with QAT by following instructions at https://github.com/intel/intel-extension-for-transformers/blob/main/examples/huggingface/pytorch/text-to-image/quantization/qat/README.md.\n",
    "\n",
    "Please note that in that case, you should install diffusers 0.16 via conda/pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad945896-8376-47c5-ab2f-62f204d1c29c",
   "metadata": {},
   "source": [
    "\\* Other names & brands may be claimed as the property of others\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_diffusion",
   "language": "python",
   "name": "stable_diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
